[{"content":"class MyWill extends Wind { // TODO } \n","href":"/","title":"Home"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/posts/","title":"Posts"},{"content":"","href":"/categories/programming-basic/","title":"programming basic"},{"content":"","href":"/tags/python/","title":"python"},{"content":"写了一个脚本，想挂后台运行，又想避免重复运行，需要检测后台是否有已经运行的脚本。实现目标：python脚本只运行一次，第二次运行时直接退出。\n在linux上比较合适的做法是创建一个systemd控制的service，有时候就临时用一用，还有考虑跨设备运行的时候也有点麻烦。\n找了两个比较简单的方案。\n1. 使用tendo import tendo.singleton single = tendo.singleton.SingleInstance() # 测试代码 import time while(True): print(\u0026#34;test\u0026#34;) time.sleep(2) 2. 使用pidfile from pid import PidFile # 会对with中的代码块加锁 with PidFile(): import time while(True): print(\u0026#34;test\u0026#34;) time.sleep(2) 或者\nfrom pid.decorator import pidfile @pidfile def main(): # 被pidfile标签装饰的函数只能运行一次 # running code 基本原理 最常见的基本操作都差不多，在运行到需要只能执行一次的代码时，在某个路径下创建一个pidfile的文件，第二次执行时如果检测到路径下有pidfile就报错跳过执行。代码执行完成后删除pidfile。\n为了避免pidfile在某些特殊情况下退出未执行，通过atexit等库处理退出时的情况。\n类似的做法还有创建一个linux的socket，退出时删除。以及基于ps等linux脚本命令查看运行的进程名。\n参考链接 https://stackoverflow.com/questions/788411/check-to-see-if-python-script-is-running/7758075#7758075\nhttps://pythonhosted.org/tendo/\nhttps://pypi.org/project/pid/\n","href":"/posts/technical/python_prevent_python_script_running_more_than_once/","title":"python脚本避免被多次执行"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/tags/iot/","title":"IoT"},{"content":"","href":"/categories/iot/","title":"IoT"},{"content":"MQTT为了物联网的消息传递而设计，业余时间弄了个报警器，之前用长轮询的实现感觉略麻烦，测试了一下MQTT的实现。\n个人感觉使用比较简单，对网络问题的处理也比较完善，但是某些方面的灵活性略微不足，而且中文资料相对较少。\n简单使用 服务端用mosquitto，客户端用python-paho-mqtt。\n服务端 安装mosquitto，然后systemctl start mosquitto启动对应的服务。\n公网环境下建议将配置文件中的默认端口1883改为其它端口，避免被直接扫描。\n一些安全方面的设置也建议加上。\n客户端 subscriber\n#!/bin/python import paho.mqtt.subscribe as subscribe # 当调用这个函数时，程序会堵塞在这里，直到有一条消息发送到 topics/topic1 主题 msg = subscribe.simple(\u0026#34;topics/topic1\u0026#34;, hostname=\u0026#34;your ip\u0026#34;, port=yourport, retained=False, client_id=\u0026#34;youid\u0026#34;, clean_session=False, qos=1) print(f\u0026#34;{msg.topic}{msg.payload}\u0026#34;) hostname和port需要改为正确的参数。\n其中，网络环境好并且不需要离线接收消息时，可以不设置clean_session、client_id、qos三个参数。\npublisher\n发送一条消息\n#!/bin/python import paho.mqtt.publish as publish publish.single(\u0026#34;topics/topic1\u0026#34;, \u0026#34;a message\u0026#34;, hostname=\u0026#34;your ip\u0026#34;, port=yourport, qos=1) 其它 MQTT 几个基本概念 通常由3部分构成：subscriber订阅客户端、publisher发布消息客户端、Server服务器。\n主题topic，类似一连串消息的标识符。\nMessage，具体的消息，对应于每个topic。\npublisher向服务器指定主题发送消息。\nsubscriber连接服务器并且指定主题，当publisher向订阅的主题推送消息后，服务器会推送到对应的subscriber。\nretained消息 MQTT使用了一个retained消息机制，用于保存主题的状态。publisher可以向主题发送retained消息，在subscriber获取retained消息时（获取参数中retained=True）服务端会返回最后一条retained消息，每一次都会返回而非普通消息的那种只读取一次。ratained消息更像是一种保存消息的状态，用在主题状态的设置，如开门的感应器，ratained消息用于标记门是否打开。\n在python的paho库中，publisher的retained参数默认是False，而subscriber的retained参数默认为True，这个有点小坑。\nQoS（Quality of Service）与离线消息 在subscriber和publisher中都可以指定，定义消息的可靠性级别，服务器会取两个客户端中较低的级别作为主题消息对应的处理级别。\nQoS0，At most once，至多一次； QoS1，At least once，至少一次； QoS2，Exactly once，确保只有一次。\n使用默认参数时，如果subscriber掉线，publisher发送的消息会丢失。\n要想subscriber在离线后重新连接，还能收到publisher的消息，需要下面的设置：\n publisher与subscriber的QoS级别都设置为0以上； subscriber的clean_session设置为False； subscriber设置固定的client_id.  存储消息历史记录 这个翻了一下网上的资料，感觉略不靠谱。MQTT的设计中没有考虑消息在服务端的存储，通常采用下面的几个方案：\n 使用另一个subscriber获取消息并存储； 使用EMQ等支持插件的服务端，通过插件处理消息。 换kafka\u0026hellip;  ","href":"/posts/technical/mqtt_simple_use/","title":"MQTT服务搭建和简单使用"},{"content":"","href":"/tags/gis/","title":"GIS"},{"content":"","href":"/categories/gis/","title":"GIS"},{"content":"","href":"/tags/hadoop/","title":"hadoop"},{"content":"  MathJax = { tex: { inlineMath: [[\"$\", \"$\"]], }, displayMath: [ [\"$$\", \"$$\"], [\"\\[\\[\", \"\\]\\]\"], ], svg: { fontCache: \"global\", }, };    最近需要使用R树做一下空间索引，在GeoSpark中使用了JTS库中实现的STR树，一开始以为是R-tree的一个变种，细看发现只是R树的构建（packing）方式之一。\nSTR是Sort-Tile-Recursive的缩写，是一种R-tree的packing算法。具体的介绍可以看作者的论文 https://www.cs.odu.edu/%7Emln/ltrs-pdfs/icase-1997-14.pdf ，CSDN上有个主要内容的翻译 https://blog.csdn.net/qq_41775852/article/details/105405918。\nR树常见构建过程 通常R树是针对动态有增删的数据，因此构建过程可以将所有的数据逐个插入到R树中。这种情况可能会存在一些缺点：\n (a) high load time (b) sub-optimal spac eutilization (c) poor R-tree structure requiring the retrieval of anunduly large number of nodes in order to satisfy a query.  因此，常用packing的方式自底向上的构建R树，主要流程如下：\n 假设一共有r个矩形需要被索引，每个叶子结点中存储的矩形数量为n。首先将所有的矩形分成r/n（此处取上界）个组；（分组方式通过下面的packing算法） 将各个分组写入硬盘的pages，并计算每个分组内所有矩形的MBR以及分组对应的page-id； 对分组的MBR递归的执行上面的步骤，直到根节点。  在第1步中，将需要被索引的矩形分成r/n个组，论文中介绍了常见的Nearest-X(NX)、HilbertSort(HS)以及论文提出的Sort-Tile-Recursive(STR)。\nSTR算法 STR的算法本身并不复杂，以2维空间为例。对矩形的分组只考虑每个矩形的中心点，STR的基本思想是将所有的矩形以“tile”的方式分配到r/n（取上界）个分组中，此处的tile和网格类似。\n首先，对矩形按x坐标排序，然后划分成 $\\sqrt{r/n}$ 个slice。然后对slice内的矩形按y坐标排序，进一步划分成 $\\sqrt{r/n}$ 份。\n对于更高维的空间，可以按这种方式接着划分。\n总结 这个算法就是这样做一个简单的划分，正如论文的标题 《STR: A Simple and Efficient Algorithm for R-Tree Packing》，有种方法对于一篇论文来讲太简单了的感觉。文章内还做了些对比实验，表明针对不同的空间数据分布情况最好选择对应合适的方法，STR的packing算法并不是适合所有的场景。\n简单点来看，也就是将空间中的矩形划分到了一个x、y方向相等的网格的分组中，当数据为长宽差距较大的矩形范围分布时，做一个xy方向的分组数量相同应该不是最好的方案。\n","href":"/posts/technical/str_tree_rtree_construction/","title":"STR树 —— R-tree的构建方案之一"},{"content":"","href":"/categories/cloud-computing/","title":"cloud computing"},{"content":"SpatialHadoop已经长期没有更新，MapReduce框架的效率也略低，虽然不太适合直接用，但代码的实现机制可以参考。最近准备重新了解一下HDFS上的空间索引问题，在两年前（没想到距离上次运行SpatialHadoop都两年了..）的基本使用的基础上（一个简单使用的记录），记录一下空间索引机制的处理方式。后面重点关注在Hadoop上的任务提交、并行索引构建、索引的存储与读取这几个方面。\n相比GeoSpark的代码，没有Spark现成的算子可以复用并且要处理文件方面的问题，逻辑上的处理稍复杂一点。\n空间分析任务的提交 SpatialHadoop提供了一个脚本，用于基本的空间处理，如下面的代码生成测试数据。\nsbin/shadoop generate test.rects size:1.gb shape:rect mbr:0,0,1000000,1000000 -overwrite shadoop脚本做的操作不多，直接通过Hadoop的运行命令运行了edu.umn.cs.spatialHadoop.operations.Main类，在类中的Main函数中处理输入参数。\nbin=`dirname \u0026#34;$0\u0026#34;` bin=`cd \u0026#34;$bin\u0026#34; \u0026gt; /dev/null; pwd` # Call Hadoop with the operations.Main as the main class . \u0026#34;$bin\u0026#34;/hadoop edu.umn.cs.spatialHadoop.operations.Main $@ 在Main函数中使用了Hadoop的ProgramDriver运行具体的类对象。首先从配置文件 spatial-operations.yaml 中读取支持的类，然后利用反射机制，读取对应类注释的shortName标签，通过shortName决定参数传递的具体的类。\npublic static void main(String[] args) { int exitCode = -1; ProgramDriver pgd = new ProgramDriver(); try { // 这个位置加载配置文件，配置文件spatial-operations.yaml中包含了支持的完整类名  Yaml yaml = new Yaml(); List\u0026lt;String\u0026gt; ops = yaml.load(SpatialSite.class.getResourceAsStream(\u0026#34;/spatial-operations.yaml\u0026#34;)); // 通过反射的机制，提取类对应的源码中的annotation里的shortName，运行时会通过shortname执行对应的类 \t// 用在上面的生成随机数据中就是通过generate执行edu.umn.cs.spatialHadoop.operations.RandomSpatialGenerator。  for (String op : ops) { Class\u0026lt;?\u0026gt; opClass = Class.forName(op); OperationMetadata opMetadata = opClass.getAnnotation(OperationMetadata.class); pgd.addClass(opMetadata.shortName(), opClass, opMetadata.description()); } pgd.driver(args); // 这个函数中调用具体的类执行任务  exitCode = 0; } catch(Throwable e){ e.printStackTrace(); } System.exit(exitCode); } 二级空间索引机制 bin/shadoop index \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; shape:\u0026lt;input format\u0026gt; sindex:\u0026lt;index\u0026gt; blocksize:\u0026lt;size\u0026gt; -overwrite # 示例 shadoop index test.rects test.grid sindex:grid shape:rect 按照上面提到的机制，会调用Indexer类的Main函数，然后在 index(inputPaths, outputPath, params); 函数的调用提交任务。\npublic static Job index(Path[] inPaths, Path outPath, OperationsParams params) throws IOException, InterruptedException, ClassNotFoundException { // initiallize主要指定local index对象以及构建全局索引  // 索引的方式从params中读取具体的类  // 全局索引的构建可以直接基于原数据或采样后的数据  // 在这里Partitioner和global index是指向的同一个对象  // 对于网格索引，初始化过程只是调用GridPartitioner的构造函数计算了网格大小等基本数据  Partitioner p = initializeIndexers(inPaths, outPath, params); 引 if (OperationsParams.isLocal(new JobConf(params), inPaths)) { indexLocal(inPaths, outPath, p, params); return null; } else { // 提交MapReduce任务  Job job = indexMapReduce(inPaths, outPath, p, params); return job; } } // MR任务的主要配置如下 static Job indexMapReduce(Path[] inPaths, Path outPath, Partitioner partitioner, OperationsParams paramss) throws IOException, InterruptedException, ClassNotFoundException { // ...  // Set mapper and reducer  Shape shape = OperationsParams.getShape(conf, \u0026#34;shape\u0026#34;); job.setMapperClass(PartitionerMap.class); job.setMapOutputKeyClass(IntWritable.class); job.setMapOutputValueClass(shape.getClass()); job.setReducerClass(PartitionerReduce.class); // Set input and output  job.setInputFormatClass(SpatialInputFormat3.class); SpatialInputFormat3.setInputPaths(job, inPaths); job.setOutputFormatClass(IndexOutputFormat.class); IndexOutputFormat.setOutputPath(job, outPath); //... } Hadoop对文件的输入主要通过InputFormat，常见的方式继承FileInputFormat后用类似TextFileInputFormat的方式处理中间的一些细节，如getSplits函数将输入文件切分成多个InputSplit，createRecord函数为每个InputSplit创建一个RecordReader对象读取具体的数据，然后在Map任务中通过RecordReader将InputSplit解析成key-value的形式。\n对于文件输入的处理，通过SpatialInputFormat3划分数据（为啥后面有个3，没有看到1和2..），继承了FileInputFormat。InputSplit的划分比较常规，基于splitSize将文件划分成多个InputSplit，然后会根据数据本地性做一次合并以降低task的数量。在createRecordReader中，根据InputSplit中文件的后缀判断是否为已经有localIndex的文件，如果有则返回LocalIndexRecordReader，否则返回配置文件中设置的对应后缀的RecordReader（默认为SpatialRecordReader3）。\nRecordReader用于解析整个InputSplit，使用的key-value形式直接为\u0026lt;Partition, Iterable\u0026gt;的形式，key对应整个InputSplit，value为解析后的数据迭代器，其中V表示空间数据的类型，继承shape。\n对于没有索引过的文件，直接按行读取文件后，将每行的text转为具体的Shape。\nprotected boolean nextShape(V s) throws IOException { do { if (!nextLine(tempLine)) return false; s.fromText(tempLine); } while (!isMatched(s)); return true; } map过程的逻辑比较常规，遍历所有的shape，分别判断每个shape与哪些partition相交，以\u0026lt;partitionID, shape\u0026gt;的key-value形式送到reduce过程处理。\n// 去除了些异常处理的语句 @Override protected void map(Rectangle key, Iterable\u0026lt;? extends Shape\u0026gt; shapes, final Context context) throws IOException, InterruptedException { final IntWritable partitionID = new IntWritable(); for (final Shape shape : shapes) { Rectangle shapeMBR = shape.getMBR(); if (disjoint) { // 这个位置用了个套娃，更方便传类成员  partitioner.overlapPartitions(shape, new ResultCollector\u0026lt;Integer\u0026gt;() { @Override public void collect(Integer r) { partitionID.set(r); context.write(partitionID, shape); } }); } else { partitionID.set(partitioner.overlapPartition(shape)); if (partitionID.get() \u0026gt;= 0) context.write(partitionID, shape); } context.progress(); } } @Override public void overlapPartitions(Shape shape, ResultCollector\u0026lt;Integer\u0026gt; matcher) { if (shape == null) return; Rectangle shapeMBR = shape.getMBR(); if (shapeMBR == null) return; int col1, col2, row1, row2; col1 = (int)Math.floor((shapeMBR.x1 - x) / tileWidth); col2 = (int)Math.ceil((shapeMBR.x2 - x) / tileWidth); row1 = (int)Math.floor((shapeMBR.y1 - y) / tileHeight); row2 = (int)Math.ceil((shapeMBR.y2 - y) / tileHeight); if (col1 \u0026lt; 0) col1 = 0; if (row1 \u0026lt; 0) row1 = 0; for (int col = col1; col \u0026lt; col2; col++) for (int row = row1; row \u0026lt; row2; row++) matcher.collect(getCellNumber(col, row)); } reduce过程直接以partition_id和对应的shape创建输出流，将对应的数据按行写入到输出流。对于不带索引的文件，直接写入到最终的结果中；带索引的文件会在getOrCreateDataOutput函数中得到一个临时文件的输出流，在写入结束后又把整个文件读到内存中构建局部索引（这一写一读外加文本解析的开销？），最后将结果文件写入到HDFS。\nLocalIndex接口被实现的类只有RRStarLocalIndex，本地索引貌似只支持R*树。\n@Override protected void reduce(IntWritable partitionID, Iterable\u0026lt;Shape\u0026gt; shapes, Context context) throws IOException, InterruptedException { LOG.info(\u0026#34;Working on partition #\u0026#34;+partitionID); for (Shape shape : shapes) { context.write(partitionID, shape); context.progress(); } // Indicate end of partition to close the file  // 在OutputFormat中，发现小于0的id号之后表示数据写入完毕可以关闭输出流  context.write(new IntWritable(-partitionID.get()-1), null); LOG.info(\u0026#34;Done with partition #\u0026#34;+partitionID); } // IndexOutputFormat中，将数据写到对应的文件 // 看到这里可能会奇怪，LocalIndex去哪了，文件没有被索引。这里有个貌似不太高效的处理， // 需要构建本地索引的文件首先被写入到临时文件，当写入结束（closePartiton函数中）后 // 创建了新的线程对临时文件构建本地空间索引后上传 @Override public void write(IntWritable partitionID, S value) throws IOException { int id = partitionID.get(); if (id \u0026lt; 0) { // An indicator to close a partition  int partitionToClose = -id - 1; this.closePartition(partitionToClose); } else { // An actual object that we need to write  // 通过ConcurrentHashMap存id对应的OutputStream  OutputStream output = getOrCreateDataOutput(id); tempText.clear(); value.toText(tempText); byte[] bytes = tempText.getBytes(); output.write(bytes, 0, tempText.getLength()); output.write(NEW_LINE); // 并没有使用二进制的形式存，而是按行存的数据  Partition partition = partitionsInfo.get(id); partition.recordCount++; partition.size += tempText.getLength() + NEW_LINE.length; partition.expand(value); if (shape == null) shape = (S) value.clone(); } } private OutputStream getOrCreateDataOutput(int id) throws IOException { OutputStream out = partitionsOutput.get(id); if (out == null) { // First time to write in this partition. Store its information  Partition partition = new Partition(); if (localIndexClass == null) { // No local index needed. Write to the final file directly  Path path = getPartitionFile(id); out = outFS.create(path); partition.filename = path.getName(); } else { // Write to a temporary file that will later get indexed  File tempFile = File.createTempFile(String.format(\u0026#34;part-%05d\u0026#34;, id), \u0026#34;lindex\u0026#34;); out = new BufferedOutputStream(new FileOutputStream(tempFile)); tempFiles.put(id, tempFile); } partition.cellId = id; // Set the rectangle to the opposite universe so that we can keep  // expanding it to get the MBR of this partition  partition.set(Double.MAX_VALUE, Double.MAX_VALUE, -Double.MAX_VALUE, -Double.MAX_VALUE); // Store in the hashtables for further user  partitionsOutput.put(id, out); partitionsInfo.put(id, partition); } return out; } // 省略了一些异常处理 private void closePartition(final int id) { final Partition partitionInfo = partitionsInfo.get(id); final OutputStream outStream = partitionsOutput.get(id); final File tempFile = tempFiles.get(id); Thread closeThread = new Thread() { @Override public void run() { try { outStream.close(); if (localIndexClass != null) { // Build a local index for that file  try { LocalIndex\u0026lt;S\u0026gt; localIndex = localIndexClass.newInstance(); localIndex.setup(conf); Path indexedFilePath = getPartitionFile(id); partitionInfo.filename = indexedFilePath.getName(); // 这个函数的逻辑见后面 \t// 将tempFile读到内存后解析，通过所有行数据的MBR构建R*树，然后写入HDFS上的索引文件 \tlocalIndex.buildLocalIndex(tempFile, indexedFilePath, shape); // Temporary file no longer needed  tempFile.delete(); } } if (disjoint) { // If data is replicated, we need to shrink down the size of the  // partition to keep partitions disjoint  partitionInfo.set(partitionInfo.getIntersection(partitioner.getPartition(id))); } Text partitionText = partitionInfo.toText(new Text()); synchronized (masterFile) { // Write partition information to the master file  masterFile.write(partitionText.getBytes(), 0, partitionText.getLength()); masterFile.write(NEW_LINE); } } 空间索引文件的组织形式 R*树存储到文件的过程。实现中并没有像常规的R树，做一套支持动态添加删除功能的访问，而只是实现了一套类似序列化的存储方式。R树的实现并没有使用树的指针形式，而是用的数组。因此序列化过程重点分成3部分：\n 写入具体的空间数据 写入对空间数据索引的r树 写入元数据  这个元数据放文件末尾的方式略微有点非主流。可以参考单元测试中的LocalIndexRecordReaderTest，涉及了对空间文件构建索引后存入文件，然后调用LocalIndexRecordReader读取文件。\n/** * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt; * Data Entries: First, all data entries are written in an order that is consistent * with the R-tree structure. This order will guarantee that all data entries * under any node (from the root to leaves) will be adjacent in that order. * \u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt; * Tree structure: This part contains the structure of the tree represented * by its nodes. The nodes are stored in a level order traversal. This guarantees * that the root will always be the first node and that all siblings will be * stored consecutively. Each node contains the following information: * (1) (n) Number of children as a 32-bit integer, * (2) n Pairs of (child offset, MBR=(x1, y1, x2, y2). The child offset is * the offset of the beginning of the child data (node or data entry) in the * tree where 0 is the offset of the first data entry. * \u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt; * Tree footer: This section contains some meta data about the tree as * follows. All integers are 32-bits. * (1) MBR of the root as (x1, y1, x2, y2), * (2) Number of data entries, * (3) Number of non-leaf nodes, * (4) Number of leaf nodes, * (5) Tree structure offset: offset of the beginning of the tree structure section * (6) Footer offset: offset of the beginning of the footer as a 32-bit integer. * (7) Tree size: Total tree size in bytes including data+structure+footer * \u0026lt;/li\u0026gt; * * \u0026lt;/ul\u0026gt; * @param out * @throws IOException */ public void write(DataOutput out, Serializer ser) throws IOException { // Tree data: write the data entries in the tree order  // Since we write the data first, we will have to traverse the tree twice  // first time to visit and write the data entries in the tree order,  // and second time to visit and write the tree nodes in the tree order.  Deque\u0026lt;Integer\u0026gt; nodesToVisit = new ArrayDeque\u0026lt;Integer\u0026gt;(); nodesToVisit.add(root); int[] objectOffsets = new int[numOfDataEntries() + numOfNodes()]; // Keep track of the offset of each data object from the beginning of the  // data section  int dataOffset = 0; // Keep track of the offset of each node from the beginning of the tree  // structure section  // 看起来是一波广度优先遍历，按层处理结点  int nodeOffset = 0; while (!nodesToVisit.isEmpty()) { int node = nodesToVisit.removeFirst(); // The node is supposed to be written in this order.  // Measure its offset and accumulate its size  objectOffsets[node] = nodeOffset; nodeOffset += 4 + (4 + 8 * 4) * Node_size(node); if (isLeaf.get(node)) { // Leaf node, write the data entries in order  for (int child : children.get(node)) { objectOffsets[child] = dataOffset; if (ser != null) dataOffset += ser.serialize(out, child); } } else { // Internal node, recursively traverse its children  for (int child : children.get(node)) nodesToVisit.addLast(child); } } // Update node offsets as they are written after the data entries  for (int i = 0; i \u0026lt; numNodes; i++) objectOffsets[i + numEntries] += dataOffset; // Tree structure: Write the nodes in tree order  nodesToVisit.add(root); while (!nodesToVisit.isEmpty()) { int node = nodesToVisit.removeFirst(); // (1) Number of children  out.writeInt(Node_size(node)); for (int child : children.get(node)) { // (2) Write the offset of the child  out.writeInt(objectOffsets[child]); // (3) Write the MBR of each child  out.writeDouble(x1s[child]); out.writeDouble(y1s[child]); out.writeDouble(x2s[child]); out.writeDouble(y2s[child]); } // If node is internal, add its children to the nodes to be visited  if (!isLeaf.get(node)) { for (int child : children.get(node)) nodesToVisit.addLast(child); } } // Tree footer  int footerOffset = dataOffset + nodeOffset; // (1) MBR of the root  out.writeDouble(x1s[root]); out.writeDouble(y1s[root]); out.writeDouble(x2s[root]); out.writeDouble(y2s[root]); // (2) Number of data entries  out.writeInt(numOfDataEntries()); // (3) Number of non-leaf nodes  out.writeInt((int) (numOfNodes() - isLeaf.countOnes())); // (4) Number of leaf nodes  out.writeInt((int) isLeaf.countOnes()); // (5) Offset of the tree structure section  out.writeInt(dataOffset); // (6) Offset of the footer  out.writeInt(footerOffset); // (7) Size of the entire tree  int footerSize = 4 * 8 + 6 * 4; out.writeInt(footerOffset + footerSize); } 以数组形式组织的R树，在读取时直接按文件顺序读取到数组中即可。对于元数据文件放在了文件尾，LocalIndexRecordReader用了一个这样的操作，seek到文件末尾的位置读取数据：\nin.seek(indexEnd - 4); int indexSize = in.readInt(); long indexStart = indexEnd - indexSize - 4; // ... in.seek(indexStart); localIndex.read(in, indexStart, indexEnd, stockShape); // 读取并构建R树（相当于反序列化） ","href":"/posts/technical/spatialhadoop_operation_code_analysis/","title":"SpatialHadoop二级空间索引机制源码分析"},{"content":"","href":"/tags/geospark/","title":"GeoSpark"},{"content":"GeoSpark GeoSpark是基于Spark的空间数据处理开源库，在RDD模型的基础上添加了空间数据操作，以底层的SpatialRDD为基础设计了空间分析、空间SQL、空间数据可视化等组件。详细信息可以参考作者博客 https://jiayuasu.github.io/ 以及项目主页 http://sedona.apache.org。GeoSpark一开始是Spark的一个第三方组件，之后改名为sedona提交到apache基金会，当前（2020.11）正处于孵化阶段。\n在空间数据的索引与并行访问上，没有像SpatialHadoop那样直接基于HDFS构建针对文件的索引，而是将数据读到RDD中在内存中后进行分区和索引构建操作，索引后的数据可以持久化到硬盘避免下一次的读取，内存的大小一定程度上限制了单次能够处理的数据总量。\n最近通过Spark提高SpatialHadoop在设计上的效率，看了一眼GeoSpark在常见的空间处理上的逻辑，针对空间数据读取、索引、划分几个方面的逻辑记个笔记。\n主要代码逻辑 GeoSpark的代码大多直接用的java编写，调用了Spark的java API，整体的逻辑比我想象的要简单。代码注释、缩进、命名等貌似都略有非主流的地方。\n示例代码主要参考官网教程 http://sedona.apache.org/tutorial/rdd/ 与github仓库源码。\n读取csv文件并创建PointRDD  官方示例 Suppose we have a checkin.csv CSV file at Path /Download/checkin.csv as follows:\n-88.331492,32.324142,hotel -88.175933,32.360763,gas -88.388954,32.357073,bar -88.221102,32.35078,restaurant\nThis file has three columns and corresponding offsets(Column IDs) are 0, 1, 2. Use the following code to create a PointRDD\n  val pointRDDInputLocation = \u0026#34;/Download/checkin.csv\u0026#34; val pointRDDOffset = 0 // The point long/lat starts from Column 0 val pointRDDSplitter = FileDataSplitter.CSV val carryOtherAttributes = true // Carry Column 2 (hotel, gas, bar...) var objectRDD = new PointRDD(sc, pointRDDInputLocation, pointRDDOffset, pointRDDSplitter, carryOtherAttributes)  通过继承SpatialRDD的PointRDD处理点数据，对于csv格式的文件：\n 通过sparkContext.textFile读取text文件； mapPartition分行处理，由PointFormatMapper将文本的每一行解析成点的对象。  RangeQuery范围查询 查询PointRDD中一个范围内的点，GeoSpark对索引过的数据与不带索引的数据做了两种实现。\n// 不带索引查询 val rangeQueryWindow = new Envelope(-90.01, -80.01, 30.01, 40.01) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery.SpatialRangeQuery(spatialRDD, rangeQueryWindow, considerBoundaryIntersection, usingIndex) 对于没有空间索引的点数据，直接基于filter算子，在RangeFilter类中判断点是否在范围内。\n// 构建空间索引并利用索引查询 val rangeQueryWindow = new Envelope(-90.01, -80.01, 30.01, 40.01) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD.buildIndex(IndexType.QUADTREE, buildOnSpatialPartitionedRDD) val usingIndex = true var queryResult = RangeQuery.SpatialRangeQuery(spatialRDD, rangeQueryWindow, considerBoundaryIntersection, usingIndex) 对于有空间索引的点数据（如四叉树索引），首先对每个partition构建索引，在mapPartition算子中将所有的点插入到STR-tree或Quad-tree，结果存入indexedRawRDD。范围查询中以partition为单位多indexedRawRDD做mapPartition操作。\nSpatialPartitioning空间划分 前面的空间索引构建和分析都是基于Spark在读取数据时根据数据文件的位置直接做的RDD划分，当有需要邻近数据在同一个partition增加邻域查询效率时，可以考虑使用空间划分对数据重新分区。\nobjectRDD.spatialPartitioning(GridType.KDBTREE) queryWindowRDD.spatialPartitioning(objectRDD.getPartitioner) GeoSpark提供了KDB-tree、R-tree、维诺图等多种划分方式，总体上的逻辑差不多。为了降低总体的计算量，GeoSpark并没有直接在元数据上进行空间划分，而是通过采样的方式首先提取一定比例的数据构建空间划分。然后用了三个Spark算子，flatMapToPair将rawSpatialRDD中的每条数据转成（分区id，空间对象）的形式，partitionBy将数据按照分区id重新划分，最后mapPartitions将（分区id，空间对象）提取为空间对象。\n具体源码分析 读取csv文件并创建PointRDD PointRDD是一个java写的类，其构造函数如下。主要逻辑通过sparkContext.textFile读取text文件，然后mapPartition分行处理，由PointFormatMapper将文本的每一行解析成点的对象，从每一行的数据中根据分隔符splitter和标记坐标位置的Offset得到坐标和额外注释。\n/** * Instantiates a new point RDD. * * @param sparkContext the spark context * @param InputLocation the input location * @param Offset the offset * @param splitter the splitter，行分隔符，如csv中的\u0026#39;,\u0026#39; * @param carryInputData the carry input data，是否存储坐标以外的数据（boolean类型，这个注释略迷） * @param partitions the partitions，分区数据（命名为numOfPartitions更好？） * @param newLevel the new level （newStorageLevel） * @param sourceEpsgCRSCode the source epsg CRS code * @param targetEpsgCode the target epsg code */ public PointRDD(JavaSparkContext sparkContext, String InputLocation, Integer Offset, FileDataSplitter splitter, boolean carryInputData, Integer partitions, StorageLevel newLevel, String sourceEpsgCRSCode, String targetEpsgCode) { JavaRDD rawTextRDD = partitions != null ? sparkContext.textFile(InputLocation, partitions) : sparkContext .textFile(InputLocation); if (Offset != null) { this.setRawSpatialRDD( // 上面的textFile函数已经得到了一个以line为单位的RDD  // mapPartitions函数对每个partition内部的line进行处理  // 将每行解析成具体的几何对象  // 实现的逻辑在FormatMapper类中，PointFormatMapper只是传了几个参数，感觉像个FormatMapperFactory \t// mapPartitions在scala里是传入一个函数，在java里传入一个包含call函数的对象。  rawTextRDD.mapPartitions(new PointFormatMapper(Offset, splitter, carryInputData))); } else { this.setRawSpatialRDD(rawTextRDD.mapPartitions(new PointFormatMapper(splitter, carryInputData))); } if (sourceEpsgCRSCode != null \u0026amp;\u0026amp; targetEpsgCode != null) { this.CRSTransform(sourceEpsgCRSCode, targetEpsgCode); } if (newLevel != null) { this.analyze(newLevel); } if (splitter.equals(FileDataSplitter.GEOJSON)) { this.fieldNames = FormatMapper.readGeoJsonPropertyNames(rawTextRDD.take(1).get(0).toString()); } } PointFormatMapper的点文本解析过程。PointFormatMapper的实现略奇怪，继承了FormatMapper，只是改了几个构造函数，感觉只是个初始化的工厂。具体的实现跳到FormatMapper中的call函数。\npublic class PointFormatMapper extends FormatMapper { public PointFormatMapper(FileDataSplitter Splitter, boolean carryInputData) { super(0, 1, Splitter, carryInputData, GeometryType.POINT); } //... } // FormatMapper类  @Override public Iterator\u0026lt;T\u0026gt; call(Iterator\u0026lt;String\u0026gt; stringIterator) throws Exception { List\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); while (stringIterator.hasNext()) { String line = stringIterator.next(); // 解析每一行，得到一个Geometry对象  addGeometry(readGeometry(line), result); } return result.iterator(); } public Geometry readGeometry(String line) throws ParseException { //...  geometry = createGeometry(readCoordinates(line), geometryType); // ... } 其中readCoordinates(line)从行中获取一个或多个点的坐标（返回Coordinate[]），createGeometry根据坐标和类型创建具体的Geometry对象。\nprivate Geometry createGeometry(Coordinate[] coordinates, GeometryType geometryType) { GeometryFactory geometryFactory = new GeometryFactory(); Geometry geometry = null; switch (geometryType) { case POINT: geometry = geometryFactory.createPoint(coordinates[0]); break; case POLYGON: geometry = geometryFactory.createPolygon(coordinates); break; // ... geometryFactory.createPoint先把Coordinate[]转成CoordinateSequence，然后得到一个Point对象，每个对象需要占用的额外空间略大。Point类继承了Geometry类，除去static对象就已经有包围盒、创建工厂对象、空间参考系id、辅助数据。Point类在此基础上添加了CoordinateSequence类成员存储具体的坐标。按照之前的测试，如果点坐标只包含(x,y)信息，会占用很多的额外存储空间（JVM对象的额外占用以及上面多余的对象变量），仅存一个坐标数组的效率会更高。\npublic abstract class Geometry implements Cloneable, Comparable, Serializable { /** * The bounding box of this \u0026lt;code\u0026gt;Geometry\u0026lt;/code\u0026gt;. */ protected Envelope envelope; /** * The {@link GeometryFactory} used to create this Geometry */ protected final GeometryFactory factory; /** * The ID of the Spatial Reference System used by this \u0026lt;code\u0026gt;Geometry\u0026lt;/code\u0026gt; */ protected int SRID; /** * An object reference which can be used to carry ancillary data defined * by the client. */ private Object userData = \u0026#34;\u0026#34;; /** * Creates a new \u0026lt;code\u0026gt;Geometry\u0026lt;/code\u0026gt; via the specified GeometryFactory. * * @param factory */ public Geometry(GeometryFactory factory) { this.factory = factory; this.SRID = factory.getSRID(); } RangeQuery范围查询 GeoSpark实现代码\nval rangeQueryWindow = new Envelope(-90.01, -80.01, 30.01, 40.01) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery.SpatialRangeQuery(spatialRDD, rangeQueryWindow, considerBoundaryIntersection, usingIndex) RangeQuery分带索引的查询和不带索引查询两种形式，在SparkRangeQuery中传参。\npublic static \u0026lt;U extends Geometry, T extends Geometry\u0026gt; JavaRDD\u0026lt;T\u0026gt; SpatialRangeQuery(SpatialRDD\u0026lt;T\u0026gt; spatialRDD, U originalQueryGeometry, boolean considerBoundaryIntersection, boolean useIndex) throws Exception { U queryGeometry = originalQueryGeometry; if (spatialRDD.getCRStransformation()) { // 坐标系转换  queryGeometry = CRSTransformation.Transform(spatialRDD.getSourceEpsgCode(), spatialRDD.getTargetEpgsgCode(), originalQueryGeometry); } if (useIndex == true) { if (spatialRDD.indexedRawRDD == null) { throw new Exception(\u0026#34;[RangeQuery][SpatialRangeQuery] Index doesn\u0026#39;t exist. Please build index on rawSpatialRDD.\u0026#34;); } return spatialRDD.indexedRawRDD.mapPartitions(new RangeFilterUsingIndex(queryGeometry, considerBoundaryIntersection, true)); } else { return spatialRDD.getRawSpatialRDD().filter(new RangeFilter(queryGeometry, considerBoundaryIntersection, true)); } } public Boolean call(T geometry) { if (leftCoveredByRight) { return match(geometry, queryGeometry); } else { return match(queryGeometry, queryGeometry); } } public boolean match(Geometry spatialObject, Geometry queryWindow) { if (considerBoundaryIntersection) { if (queryWindow.intersects(spatialObject)) { return true; } } else { if (queryWindow.covers(spatialObject)) { return true; } } return false; } 要使用带空间索引的查询，首先需要构建索引，然后查询时标记使用索引，下面的代码以四叉树索引为例。\nval rangeQueryWindow = new Envelope(-90.01, -80.01, 30.01, 40.01) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD.buildIndex(IndexType.QUADTREE, buildOnSpatialPartitionedRDD) val usingIndex = true var queryResult = RangeQuery.SpatialRangeQuery(spatialRDD, rangeQueryWindow, considerBoundaryIntersection, usingIndex) 针对有索引的数据，用mapPartition算子处理spatialRDD.indexedRawRDD中的每一条数据，每一条数据具体对应了一个treeIndex。通过treeIndex.query(Envelope searchEnv)函数得到一个List存储的结果，然后依次遍历List中的数据是否符合要求。\n// ... if (useIndex == true) { if (spatialRDD.indexedRawRDD == null) { throw new Exception(\u0026#34;[RangeQuery][SpatialRangeQuery] Index doesn\u0026#39;t exist. Please build index on rawSpatialRDD.\u0026#34;); } return spatialRDD.indexedRawRDD.mapPartitions(new RangeFilterUsingIndex(queryGeometry, considerBoundaryIntersection, true)); } else { return spatialRDD.getRawSpatialRDD().filter(new RangeFilter(queryGeometry, considerBoundaryIntersection, true)); } // ...  @Override public Iterator\u0026lt;T\u0026gt; call(Iterator\u0026lt;SpatialIndex\u0026gt; treeIndexes) throws Exception { assert treeIndexes.hasNext() == true; SpatialIndex treeIndex = treeIndexes.next(); List\u0026lt;T\u0026gt; results = new ArrayList\u0026lt;T\u0026gt;(); List\u0026lt;T\u0026gt; tempResults = treeIndex.query(this.queryGeometry.getEnvelopeInternal()); for (T tempResult : tempResults) { if (leftCoveredByRight) { if (match(tempResult, queryGeometry)) { results.add(tempResult); } } else { if (match(queryGeometry, tempResult)) { results.add(tempResult); } } } return results.iterator(); } 索引的构建通过buildIndex函数，貌似比想象的简单，还是以partition为单位构建索引，通过mapPartition算子对每个partition中的空间数据构建索引，\n/** * Builds the index. * * @param indexType the index type * @param buildIndexOnSpatialPartitionedRDD the build index on spatial partitioned RDD * @throws Exception the exception */ public void buildIndex(final IndexType indexType, boolean buildIndexOnSpatialPartitionedRDD) throws Exception { if (buildIndexOnSpatialPartitionedRDD == false) { //This index is built on top of unpartitioned SRDD  this.indexedRawRDD = this.rawSpatialRDD.mapPartitions(new IndexBuilder(indexType)); } else { if (this.spatialPartitionedRDD == null) { throw new Exception(\u0026#34;[AbstractSpatialRDD][buildIndex] spatialPartitionedRDD is null. Please do spatial partitioning before build index.\u0026#34;); } this.indexedRDD = this.spatialPartitionedRDD.mapPartitions(new IndexBuilder(indexType)); } } 在IndexBuilder中，只支持R-tree和四叉树两种索引方式。\n@Override public Iterator\u0026lt;SpatialIndex\u0026gt; call(Iterator\u0026lt;T\u0026gt; objectIterator) throws Exception { SpatialIndex spatialIndex; if (indexType == IndexType.RTREE) { spatialIndex = new STRtree(); } else { spatialIndex = new Quadtree(); } while (objectIterator.hasNext()) { T spatialObject = objectIterator.next(); spatialIndex.insert(spatialObject.getEnvelopeInternal(), spatialObject); } Set\u0026lt;SpatialIndex\u0026gt; result = new HashSet(); // 这啥操作  spatialIndex.query(new Envelope(0.0, 0.0, 0.0, 0.0)); result.add(spatialIndex); return result.iterator(); } SpatialPartitioning空间划分 objectRDD.spatialPartitioning(GridType.KDBTREE) queryWindowRDD.spatialPartitioning(objectRDD.getPartitioner) public boolean spatialPartitioning(GridType gridType) throws Exception { int numPartitions = this.rawSpatialRDD.rdd().partitions().length; // 基于RDD的分区数量构建空间划分  spatialPartitioning(gridType, numPartitions); return true; } public void spatialPartitioning(GridType gridType, int numPartitions) throws Exception { // 并非直接针对元数据做划分，而是针对采样后的数据  int sampleNumberOfRecords = RDDSampleUtils.getSampleNumbers(numPartitions, this.approximateTotalCount, this.sampleNumber); // 采样的比例  final double fraction = SamplingUtils.computeFractionForSampleSize(sampleNumberOfRecords, approximateTotalCount, false); // 这个samples变量存储的是一堆外包围盒，取名叫sampleEnvelopes更好，外包围盒用于后面的Partitioning类的构建  List\u0026lt;Envelope\u0026gt; samples = this.rawSpatialRDD.sample(false, fraction) // sample函数是RDD自带的算子  .map(new Function\u0026lt;T, Envelope\u0026gt;() { @Override public Envelope call(T geometry) throws Exception { return geometry.getEnvelopeInternal(); } }) .collect(); // 外包围盒扩宽一点  final Envelope paddedBoundary = new Envelope( boundaryEnvelope.getMinX(), boundaryEnvelope.getMaxX() + 0.01, boundaryEnvelope.getMinY(), boundaryEnvelope.getMaxY() + 0.01); switch (gridType) { //...  case QUADTREE: { QuadtreePartitioning quadtreePartitioning = new QuadtreePartitioning(samples, paddedBoundary, numPartitions); partitionTree = quadtreePartitioning.getPartitionTree(); partitioner = new QuadTreePartitioner(partitionTree); break; } case KDBTREE: { final KDBTree tree = new KDBTree(samples.size() / numPartitions, numPartitions, paddedBoundary); for (final Envelope sample : samples) { tree.insert(sample); } tree.assignLeafIds(); partitioner = new KDBTreePartitioner(tree); break; } default: throw new Exception(\u0026#34;[AbstractSpatialRDD][spatialPartitioning] Unsupported spatial partitioning method.\u0026#34;); } this.spatialPartitionedRDD = partition(partitioner); } // 首先flatMapToPair使用partitioner计算每个spatialObject的partition_id，转成(partition_id, spatialObject)的形式 // 然后partitionBy根据partition_id重划分 // 最后mapPartitons将（partition_id, spatialObject）的二元组转成spatialObject // 感觉几个算子用得略奇怪 private JavaRDD\u0026lt;T\u0026gt; partition(final SpatialPartitioner partitioner) { return this.rawSpatialRDD.flatMapToPair( new PairFlatMapFunction\u0026lt;T, Integer, T\u0026gt;() { @Override public Iterator\u0026lt;Tuple2\u0026lt;Integer, T\u0026gt;\u0026gt; call(T spatialObject) throws Exception { return partitioner.placeObject(spatialObject); // 返回二元组（spatialObject所在的partition的id, spatialObject）  } } ).partitionBy(partitioner) // rdd默认的函数，根据key值（上面的partition_id）分配具体的partition  .mapPartitions(new FlatMapFunction\u0026lt;Iterator\u0026lt;Tuple2\u0026lt;Integer, T\u0026gt;\u0026gt;, T\u0026gt;() { @Override public Iterator\u0026lt;T\u0026gt; call(final Iterator\u0026lt;Tuple2\u0026lt;Integer, T\u0026gt;\u0026gt; tuple2Iterator) throws Exception { return new Iterator\u0026lt;T\u0026gt;() { @Override public boolean hasNext() { return tuple2Iterator.hasNext(); } @Override public T next() { return tuple2Iterator.next()._2(); } @Override public void remove() { throw new UnsupportedOperationException(); } }; } }, true); } ","href":"/posts/technical/geospark_range_query_code_analysis/","title":"GeoSpark范围查询源码分析"},{"content":"","href":"/tags/spark/","title":"Spark"},{"content":"","href":"/tags/java/","title":"java"},{"content":"系统的看一下Java支持的数据结构，记一下从数据结构到java实现的一些基础笔记。以下内容主要参考《java核心技术》与jdk11源码。\n用于保存对象的数据结构一般称作容器类，也称作泛型集合（generic collection，由于容易和Collection接口混淆，因此有些书直接叫做容器类container library）。主要分为Collection和Map两种，Collection用于存储独立的元素，而Map用于存储“键值对”对象。\n一些细节 在查找元素、查找位置、移除等操作中，判断对象是否相同的方式是调用equal函数。\nretainAll(Collection\u0026lt;?\u0026gt; c)求两个集合的交集。\n实现时接口与实现分离。使用时用满足需要的接口（如队列使用Queue），针对具体的场景new合适的实现。当需要自行实现对应的功能，为了降低实现接口中过多函数的复杂程度，可以直接扩展对应的Abastract类（如AbstractQueue），这种抽象接口加抽象类的方式在集合设计中经常遇到。\n集合类只能容纳对象句柄。集合在存储基本类型时，会通过封装器（Integer等）将基本类型转换成普通类，因此在处理效率上不如数组（直接存储基本类型）。\n迭代器 Iterator public interface Iterator\u0026lt;E\u0026gt;{ E next(); boolean hasNext(); void remove(); } // 并没有一个函数直接返回迭代器指向位置的值  public interface Iterable\u0026lt;E\u0026gt;{ Iterator\u0026lt;E\u0026gt; iterator(); } for each循环可以针对任何实现了Iterable的对象（由编译器直接翻译成Iterator对应的代码）。for (String e: c){\u0026hellip;}\nCollection接口实现了Iterable接口，可以返回遍历元素的迭代器。\n通过迭代器，能够用一套代码访问不同的容器类。\n和C++的迭代器指向具体位置的设计不同，java的迭代器指向的位置可以看作是两个元素的中间。当调用next时，迭代器会跳过下一个元素，并返回被跳过元素的引用。不能像C++那样直接取当前位置的元素。对于remove函数，删除的是上一次next函数返回的位置（由于经常需要通过此位置的值判断是否删除）。也因此，每次调用remove函数前必须调用一次next方法，因此连续调用两次remove会出错。\nList ArrayList相当于dynamic array，随机访问快，随机插入慢。类似的实现还有Vector，相当于一个线程安全的ArrayList。\nLinkedList，双向链表，随机访问慢，随机插入快。LinkedList比较特殊，除了List接口还是了双端队列的Deque接口。\nLinkedList无法获取到node的指针，但可以通过获取ListIterator控制前后的位置（相对于Iterator，添加了previous等向前访问的函数）。\nLikedList并没有缓存指针的位置，因此get(n)等随机访问和修改的操作效率不高。\npublic class LinkedList\u0026lt;E\u0026gt; extends AbstractSequentialList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, Deque\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable Map 《java核心技术》中将Map的介绍放在了Set之后，但是Hashset的实现直接使用了HashMap，此处先写写Map的实现。\nHashMap （下面的默认参数取自openjdk11源码）\n实现常量时间的数据get和put。\nHashMap用hashcode结合链表的实现。使用了桶（bucket）机制，将hashcode取余后放入一个链表，当一个桶中的数据达到8个时，会通过treeifyBin函数将链表的形式转成红黑树存储以加快检索效率。\n在构造函数中设置了两个参数。threshold（默认为16）和loadFactor（默认为0.75），初始化时桶的数量会用threshold，往后threshold会等于 桶的数量×loadFactor。添加元素时，HashMap中的元素个数达到threshold时会调用resize让桶的数量翻倍，此时会遍历先前的所有元素添加到扩容之后的数组中（rehash过程）。\n通过一个名为table的数组存储桶的节点，默认情况下的初始化桶的个数为16，每次会增加为之前的2倍，最大为Int型的最大值。\ntransient Node\u0026lt;K,V\u0026gt;[] table; static class Node\u0026lt;K,V\u0026gt; implements Entry\u0026lt;K,V\u0026gt; { final int hash; final K key; V value; Node\u0026lt;K,V\u0026gt; next; // ... } resize过程使用的头插入（新的table数组中插入的元素插入到链表头部，避免遍历到尾部的开销）。\n当一个桶中的数据达到TREEIFY_THRESHOLD（8）个，并且桶的数量超过MIN_TREEIFY_CAPACITY（64）时，会在treeifyBin函数中将每个桶中的数据从链表转换成红黑树。\n通过hashCode()函数得到hash值，通过equal()函数判断对象是否相等。\n并发访问中，HashMap的实现中并没有考虑多线程的问题，在多线程结构化（structurally）修改HashMap时可能会出问题（结构化主要指添加和删除，修改某个key对应的值不算结构化修改）。\nTreeMap 基于红黑树实现的Map，对于获取键值、插入、删除的操作时间复杂度为log(n)。put时将数据插入红黑树，get时从树中取数据。\n由于数据存储在红黑树有序排列，获得排序后的数据较快。\n将key-value键值对做为节点插入到红黑树中，由于需要排序，通过Comparator\u0026lt;? super K\u0026gt;接口让插入的键值可比较。\nstatic final class Entry\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { K key; V value; Entry\u0026lt;K,V\u0026gt; left; Entry\u0026lt;K,V\u0026gt; right; Entry\u0026lt;K,V\u0026gt; parent; boolean color = BLACK; // ... } 当类默认的比较函数不能满足需要时，可以另外定义新的comparator传入TreeMap。\npublic TreeMap(Comparator\u0026lt;? super K\u0026gt; comparator) { this.comparator = comparator; } EnumMap 用于枚举类型 所有的key必须是同一个enum类型中。内部通过数组的方式表达。每个类型对应数组中的一个元素。\nput时直接获取key对应的enum位置，直接对数组中的此位置赋值。\nprivate transient K[] keyUniverse; private transient Object[] vals; public V put(K key, V value) { typeCheck(key); int index = key.ordinal(); Object oldValue = vals[index]; vals[index] = maskNull(value); if (oldValue == null) size++; return unmaskNull(oldValue); } 在put函数中，直接获取key对应的enum索引位置\nLinkedHashMap实现原理 LinkedHashMap通过一个额外的双向链表链接所有的元素，通过构造函数中的参数accessOrder决定记录元素添加顺序还是元素访问顺序。\n可以用来copy一个map，使新的map中的元素顺序与被赋值的map顺序相同（如下）。也适用于LRU cache类似的场景。\nvoid foo(Map m) { Map copy = new LinkedHashMap(m); // ... } 源码实现 总体逻辑为，每次添加新的元素，都回加入到链表的尾部。每次访问节点时，如果accessOrder为true（链表按照访问顺序），则将当前访问的节点放到链表尾部；当accessOrder为false（链表按照插入顺序），则不对链表操作。\n通过两个指针可以获得所有元素的链表。\n// The head (eldest) of the doubly linked list. transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; // The tail (youngest) of the doubly linked list. transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; jdk11的实现上略微有点跳，不同于jdk8直接重写了关键函数，jdk11通过多态的形式插入了一些和HashMap不同的操作。\n想象中的让链表记录元素插入顺序的方式，直接在put新的元素后，直接将新的元素加入到链表（记录元素访问顺序在get函数中类似）。jdk11在实现时，在HashMap类中定义了三个空函数用于在LinkedHashMap中实现：\n// Callbacks to allow LinkedHashMap post-actions void afterNodeAccess(Node\u0026lt;K,V\u0026gt; p) { } void afterNodeInsertion(boolean evict) { } void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; p) { } 三个函数分别在Node的访问、插入、删除三种情况后被调用，在HashMap中为空函数，LinkedHashMap中具体实现。 但是，链表的插入顺序并没有直接放在afterNodeInsertion函数中，而是重写了创建新节点的newNode函数：\nNode\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { Entry\u0026lt;K,V\u0026gt; p = new Entry\u0026lt;\u0026gt;(hash, key, value, e); linkNodeLast(p); // 将p节点通过tail指针添加到链表尾部  return p; } 其它Map WeakHashMap 值不用后会被回收，利用了GC机制中的标记。\nIdentityHashMap 用==而非equals比较键值。\nSet 接口和Colection基本相同，除了java9加了几个针对不可变集合的函数。\npublic interface Set\u0026lt;E\u0026gt; extends Collection\u0026lt;E\u0026gt; {...} Set的内部很多都直接使用上面的Map实现，如HashSet内部直接使用了HashMap做为存储，在添加元素时，将加入的元素作为key，用一个常量作为value。\nprivate transient HashMap\u0026lt;E,Object\u0026gt; map; private static final Object PRESENT = new Object(); public boolean add(E e) { return map.put(e, PRESENT)==null; } LinkedHashSet 记录了插入的顺序。\nTreeSet使用了TreeMap，通过红黑树适用于需要排序的数据。\nEnumSet包含枚举类型\nQueue ArrayDeque and LinkedList Deque(double-ended queue）双端队列，发音为|deck|。\n常见的队列主要有ArrayDeque（数组实现的双端循环队列）和 LinkedList（链表实现的双端队列），其中LinkedList虽然名字是List，但实现了Queue的函数，定义如下）。\n通常情况下ArrayDeque的数组型实现效率会高于LinkedList的指针型实现。\npublic class LinkedList\u0026lt;E\u0026gt; extends AbstractSequentialList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, Deque\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable{ //... } 双端循环队列的addFirst函数实现如下\n// 其中Deque表示“double end queue”，发音为deck public interface Deque\u0026lt;E\u0026gt; extends Queue\u0026lt;E\u0026gt; {...} // ArrayDeque使用的是循环队列 // addFirst函数会向队列头部加入一个新的元素 // 当头部为0时，会通过dec函数将head指针移到数组尾部对应的位置 public void addFirst(E e) { if (e == null) throw new NullPointerException(); final Object[] es = elements; es[head = dec(head, es.length)] = e; if (head == tail) grow(1); } static final int dec(int i, int modulus) { if (--i \u0026lt; 0) i = modulus - 1; return i; } PriorityQueue 通过一个数组形式的堆实现最小优先队列，transient Object[] queue;，默认将最小值放在堆顶，peek()函数返回堆中最小值。没有直接的更改顺序的方式，如果需要将最大值放在堆顶需要传入Comparator接口的实现。\n满足堆的性质，poll()函数返回队列中的最小值或者最大值O(log(n))。\nStack public class Stack\u0026lt;E\u0026gt; extends Vector\u0026lt;E\u0026gt; {...} public class Vector\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable {} LIFO (后进先出）\n源码中的一些操作 位操作 用按位与操作提高取余效率 仅针对取余数为2^n次方的数。\n对2取余实质上就是取2进制的最后一位，对4取余实质上是取2进制数的最后两位。\n如 5 % 2 = （2进制）101 \u0026amp; 001。\n2^n - 1 = （2进制的n个1）11\u0026hellip;.1\nhash % n 等于 (n - 1) \u0026amp; hash\n移位表示2^n 1 \u0026laquo; 4 // 相当于2^4\n当数组为2的倍数时，向左移m位相当于乘2的m次方\n4 \u0026laquo; m // 相当于 4*(2^m)\n移位表示乘2和除2 22 \u0026raquo; 1 // 除以二 22 \u0026laquo; 1 // 乘2 22 \u0026raquo;\u0026gt; 1 // 忽略符号位除以2\n通过-1向右移位\u0026raquo;\u0026gt; 对于8位的byte，-1 的源码为 10000001，因此可以通过\u0026raquo;\u0026gt;得到一个00010000的2^n的数。\n在HashMap中，hash桶的数量只能为2^n。下面的函数能够获取最小的n使2^n \u0026gt; cap。\n/** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) { int n = -1 \u0026gt;\u0026gt;\u0026gt; Integer.numberOfLeadingZeros(cap - 1); return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } ","href":"/posts/technical/java_data_structure/","title":"Java数据结构笔记"},{"content":"","href":"/tags/linux/","title":"linux"},{"content":"","href":"/categories/linux-desktop/","title":"linux desktop"},{"content":"windows和linux的双系统偶尔需要切换，设置一个默认启动项没看到直接的资料。\n修改配置文件 /boot/efi/EFI/refind/refind.conf（linux下），相关的项都有说明，但是这个和常规差距略大。\n默认启动项的设置在default_selection 项，可以设置为如下：\ndefault_selection \u0026quot;+,Microsoft,vmlinuz\u0026quot;\nMicrosoft表示windows系统，vmlinuz表示linux系统，+号表示选择上一次打开的选项。\n","href":"/posts/technical/refind_set_default_to_last_start_item/","title":"REFInd默认启动上次的启动项"},{"content":"问题 manjaro 在笔记本上启动时卡住（manjaro-awesome + refind引导），停在\nTLP System startup/shutdown\nTLP 提供优秀的 Linux 高级电源管理功能（详见arch wiki），不知道为什么在启动后卡主。\n解决 没有太研究，一般启动卡住的问题和内核参数、驱动等关系比较大，具体的不太好找，可以试试下面的三种方案。\n方案一：换内核（可能是硬件的驱动问题导致，对新一点的设备换新内核可能会有效）。\n方案二：关闭TLP服务的开机启动， systemctl disable tlp.service 。\n方案三：将refind引导改为grub引导（难道启动的时候两者的内核参数不一致？）\n","href":"/posts/technical/startup_stuck_in_tlp_service/","title":"系统启动时卡在 'TLP System startup/shutdown' "},{"content":"虽然是linux版出厂自带deepin专业版，但是随后发的一键win10装机U盘一声不坑的把deepin格式化了，售后还只在线下才提供安装包\u0026hellip;\n笔记本参数 Magicbook 14 (2019)\n AMD R5 3500U 8G + 512G  内核 不同的内核在这个笔记本的表现差距略大。当前（2020年-4月）测试过的内核里，只有linux56运行比较平稳。LTS的414/419直接开机黑屏，好像有一个是由于TLP服务的问题，systemctl disable tlp可以解决，TLP提供了电源管理功能，禁止了不知道影响有多大。LTS的linux54在睡眠时仍能听到风扇转动，无法正常睡眠。\n当前的linux56的主要问题（其它内核也存在）：\n 指纹识别不能用 麦克风禁音键不能用 风扇无法控制 (好像没有现成的驱动）  Huawei-WMI 相当于华为为自己的笔记本添加的驱动程序，具体介绍可以参考下面的链接。\nhttps://github.com/aymanbagabas/Huawei-WMI\n主要的Features：\n  Function hotkeys, implemented in v1.0 Micmute LED, implemented in v2.0. Updated in v3.0 to work with newer laptops. Battery protection, implemented in v3.0. Updated in v3.3 to use battery charge API. Fn-lock, implemented v3.0.   NOTE: Version v2.0 is the one in mainline kernel \u0026gt;= 5.0, this repository is used for testing and development purposes. v3.3 has been merged in kernel 5.5\n电池保护与Fn锁 参考某些理论，锂电池在不用的时候保存为一半的电量对电池的损耗最少。因此，如果笔记本一直插电使用，最好让电池在50%左右时只使用电源的电，而不继续充电，ThinkPad、Surface等笔记本都提供了类似的电源保护功能，huawei-wmi在新的版本里也加入了电池的充电保护（默认是关闭状态）。\nFn锁似乎是个解决强迫症的设置，默认是在Fn键灯亮的时候是F1-F12，而在不亮的时候才是对应的功能键。Fn锁可以将这个改成Fn灯不亮的时候是F1-F12。\n这两项设置一般通过下面的matebook-applet设置，在AUR里可以直接安装，里面有使用说明。如果不需要这两个功能可以不折腾。\nhttps://github.com/nekr0z/matebook-applet\n使用起来略麻烦，这个applet使用之前需要修改目录/sys/devices/platform/huawei-wmi/的权限，sudo chmod -R 777 /sys/devices/platform/huawei-wmi，然后命令行运行matebook-applet，通知栏里会出现能够改变这两项的图标。如果此目录没有执行命令的用户的权限，则可以查看当前状态而不能修改。\n但是，这个目录是动态创建的，重新开机之后权限会还原为root权限。https://github.com/nekr0z/matebook-applet#huawei-wmi-driver里有个现成的脚本，使用如下。大概是新建了两个service，动态修改huawei-wmi文件夹的用户组，并将当前用户添加到修改的用户组中以获得权限。这个applet设置一次后重启会保留之前的设置，用得不多感觉折腾的必要不大，要调整的时候改一下权限就行。\n$ git clone https://github.com/qu1x/huawei-wmi.git $ cd huawei-wmi/generic $ sudo make install 貌似主要是改变了huawei-wmi里的fn_lock_state和charge_control_thresholds 两个文件的访问权限，但是这两个文件无法直接修改，不知道matebook-applet是调用的api还是其它的修改方式。\n不知道这些是不是华为官方写的，实现的几种语言里都没有中文，这种权限的问题也略不优雅。\n开机时 Failed to start Load/Save Screen Backlight Brightness of backlight:acpi_video0 启动显示错误信息Failed to start Load/Save Screen Backlight Brightness of backlight:acpi_video0，虽然不影响（其实系统使用了systemd-backlight@backlight:amdgpu_b10来补充了)。\nsudo systemctl mask systemd-backlight@backlight:acpi_video0\n这个服务反正也启动不了，可以直接屏蔽了\n此处参照 https://blog.csdn.net/grsharp/article/details/105735792\n一些其它的参考链接 https://github.com/nekr0z/linux-on-huawei-matebook-13-2019\nhttps://github.com/zer0nka/linux-on-huawei-matebook-d-14-amd\n","href":"/posts/technical/manjaro_magicbook_install_and_configuration/","title":"华为笔记本magicbook14 AMD安装Manjaro Linux的一些踩坑配置"},{"content":"","href":"/categories/linux/","title":"linux"},{"content":"重新编译内核可以修改编译时的参数，使内核在运行时更高效的支持本地硬件。Manjaro团队在gitlab上放了Manjaro内核的编译文件，稍加修改即可使用自己的选项编译。\n主要参考论坛中Manjaro团队的philm的回答 https://forum.manjaro.org/t/how-to-compile-the-mainline-kernel-the-manjaro-way/51700/35\nGitlab 仓库 philm提到了manjaro在gitlab上编译内核的仓库。https://gitlab.manjaro.org/packages/core/linux56.git 后面使用不同的linux版本号。\n仓库文件介绍 仓库中不同后缀文件的作用\n  files ending with .patch should be clear. These are adjustments we think will fit for our distro best. files starting with config are our modified settings on how we configure the kernel on our end. files starting with linux are specific files to post configure the system. They are used either by pacman or mkinitcpio, which configures the initramfs image. files ending with .hook are used by pacman to pre- or post-configure the kernel.   主要的脚本文件为PKGBUILD，指定了包中包含的文件，需要执行的操作等。\n内核编译参数的设置在config.x86_64文件中，需要改变的参数可以在这里修改。（PKGBUILD中新建了.config文件并将config.x86_64文件的内如cat进入）\n主要编译过程  So here is a quick tutorial to compile your own kernel on Manjaro:\nfirst you have to clone our package repo for linux417 via git clone https://gitlab.manjaro.org/packages/core/linux417.git\nthen change into that directory and execute makepkg -s. This will compile the kernel as I had configured it. You may want to stop the time.\nIf you however want to use our tools, you may install manjaro-tools-pkg and only change into the directory where you cloned the git-repo. No need to change into the linux417 folder. You simply may use then buildpkg -p linux417. This will create a new chroot on which the package gets compiled in a separate system to avoid any issues with other systems. Only used if you want to redistribute your package to somebody else.\n 大概流程为：\n git clone对应的仓库 修改编译参数config.x86_64 makepkg编译内核  国内可能存在git下载代码非常慢的问题，可以通过网页端或其它镜像站下载代码文件到指定目录，然后修改PKGBUILD文件，将source=(后的链接替换成下载后的文件名。如果内核代码或其它文件（config.x86_64）修改过，还需要将sha256sums=(后的对应位置改为'SKIP'或者计算后的值。\n为了避免编译器版本等造成的环境问题，manjaro还提供了manjaro-tool-pkg，在仓库所在的目录运行buildpkg -p linux56会新安装一个新的环境然后chroot使用独立的环境构建。\n最好给新编译的内核一个重新的命名，否则在安装时会覆盖同名称的官方内核。需要改命令的地方不止在PKGBUILD，具体在哪也懒得找了\u0026hellip;\n [optional] give your kernel a different name so it can be easily installed alongside existing ones. For that, you have to replace every instance of -MANJARO with a name of your choice, this in every file, not only in PKGBUILD! You could use a simple ‘find and replace’ in your text editor, or use the sed command, e.g. sed -i -e \u0026ldquo;s|-MANJARO|-CUSTOM|\u0026rdquo; PKGBUILD. You also have to edit various other names, like\n 修改内核参数 zcat /proc/config.gz \u0026gt; .config  导出当前内核的配置。\n在linux内核代码目录通过make可以得到内核的设置参数或设置界面：\n make localmodconfig 获取当前的内核参数，这种方法能够得到一个非常精简的内核，但没有加载过的内核模块都不会被编译。（在我的笔记本上内核大小成了之前的25%，但是睡眠出问题） make nconfig: 新的命令行 ncurses 界面 make xconfig: 用户友好的图形界面，需要安装 packagekit-qt4[断开的链接：package not found]。建议没有经验的用户使用此方法。 make gconfig: 和 xconfig 类似的图形界面，使用 gtk.  运行后会生成一个新的.config文件，将文件覆盖config.x86_64后，直接makepkg即可。\n一些内核参数可以参考gentoo的wiki：\nhttps://wiki.gentoo.org/wiki/Handbook:X86/Installation/Kernel\n","href":"/posts/technical/manjaro_kernel_compile/","title":"Manjaro内核编译"},{"content":"在将ArrayList等Collection转为数组时，函数的返回值并不是泛型类型的数组，而是Object[]。刚好最近翻了一遍《java核心技术》，以及参考《Think in Java》，写写为什么没有直接返回对应类型的数组，以及Java泛型中类型擦除的处理方式。\n主要涉及：\n ArrayList的toArray函数使用 为什么不直接定义函数 T[] toArray() 泛型数组的创建的两种常用方法 在泛型中创建具体的类实例  (部分代码没有运行过）\nArrayList的toArray函数使用 将ArrayList转为数组，提供了两个函数\nObject[] toArray(); \u0026lt;T\u0026gt; T[] toArray(T[] a); // 后面考虑一个Integer类型的ArrayList ArrayList\u0026lt;Integer\u0026gt; aa = new ArrayList\u0026lt;\u0026gt;(); aa.add(1); aa.add(3); Object[] toArray(); 第一个函数是直接将ArrayList转换成Object的数组，可以用Object[] bb = aa.toArray()，在具体使用时对每个对象进行强制类型转换，如System.out.println((Integer)bb[1])。（java不支持数组之间的强制类型转换）\nT[] toArray(T[] a); 第二个函数能够直接得到T类型的数组，当传入的T[] a能放下ArrayList时，会将ArrayList中的内容复制到a中（a的size较大时会a[size]=null）。否则，将构建一个新的数组并返回。具体实现如下:\npublic \u0026lt;T\u0026gt; T[] toArray(T[] a) { if (a.length \u0026lt; size) // Make a new array of a\u0026#39;s runtime type, but my contents:  return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length \u0026gt; size) a[size] = null; return a; } 对于第二个函数，可以考虑将一个大小一致的T[]数组传入toArray()函数（为了数组复用），或者直接Integer[] ArrayAA = aa.toArray(new Integer[0]);。\n为什么不直接定义函数 T[] toArray(); 通常，直观上更直接的返回数组的方式应该是T[] toArray()，为什么JDK定义了一个不怎么好用的返回Object数组的函数。\n数组之间虽然占用空间大小相同，但是不能强制改变类型（由于数组也是类，而数组类之间没有继承关系）。以object[] a; ...; (Integer[])a强制转换一个数组类型时，会在编译器产生警告，运行时抛出异常。因此对于泛型数组，无法以(T[]) array的形式，将擦除Object类型的数组强转为T[]类型。\n主要和jdk向前兼容以及泛型的类型擦除有关，个人认为主要应该还是由于类型擦除机制导致了返回T[] toArray()的实现困难。\n泛型的类型擦除 泛型是从SE 5才开始引入，为了不破坏现有的类型机制，用了一种类型擦除的机制，相比C++使类型擦除时的考虑更为复杂。\n虚拟机并不支持泛型，而是将泛型类编译成了一个类型擦除（erased）的类，将类型变量转换成一个原始类型（raw type）。原始类型在默认类型变量时会被转换成Object，在类型变量有限定时（如 ）会被转换成限定的类。在运行时获取到的T类型都是擦除后的类型。\npublic class Pair\u0026lt;T\u0026gt; { private T first; private T second; public Pair(T first, T second){ this.first = first; this.second = second; } } // 会被替换成 public class Pair { private Object first; private Object second; public Pair(Object first, Object second){ this.first = first; this.second = second; System.out.println(this.first.getClass()); // 不管T类型如何，得到的都是Object  } } //当类型为Pair\u0026lt;T extends Comparable\u0026gt;时，T会被替换为Comparable 这和C++的处理方式很不一样，C++中每个模板的实例化都会产生不同的具体类型，相当于对与每一种类型都会编译出一套独立的代码，会有“模板代码膨胀”。而在java中，使用了模板的类作为一个通用类进行了编译，传入不同的泛型参数也只会运行在同一个类上，模板的类型使用擦除后的类型进行编译。\n在使用到具体的对象时，编译器会添加一个强制类型的转换指定，将Object或限定的类型强转为具体的类型。如对于类成员函数 public T getFirst()，由于类型擦除后函数会变为public Object getFirst()，当泛型T为整型时，编译器调用 Int a = pair1.getFirst()会添加一个强制类型转换指令给虚拟机。而在没有具体类型时，一直使用擦除后的类型进行处理。\n泛型方法不涉及类型擦除 public \u0026lt;T\u0026gt; void f(T x){ System.out.println(x.getClass().getName()); } f.(\u0026#34;\u0026#34;); // java.lang.String f.(1); // java.lang.Integer 对于泛型方法，使用的是类型推断机制，当调用方法时，通过参数判断T的类型，而非擦除为Object。\n\u0026lt;T\u0026gt; T[] toArray(T[] a); 函数就是通过这一方式，在调用toArray函数时通过参数类型得到泛型的类型，然后通过反射创建数组。\n类型擦除导致的结果 由于类型的擦除，在使用时需要一直注意类型变量的类型并非T，编译期无法得到关于T类型的具体信息，在运行时的类型并不会替换为具体的类型，而是在需要的地方执行强制类型转换。 在运行时会出现下面的情况：\n 类型List和List的类型在擦除后相同。 同上 instanceOf 也无法使用。 T a = new T(); 编译器会报错，因为类型在编译期不存在，而且编译阶段无法确定在T中是否存在默认的无参构造函数。 同上，无法使用 T[] a = new T[10]。  外加数组类之间无继承关系导致无法将Object[]的数组强转为T[]。\n因此，java中直接设计T[] toArray()类型的函数需要额外的传入类型。\n泛型数组的创建的两种常用方法 虽然无法直接创建T类型的对象，但可以利用反射机制间接的创建T类型的对象。对于创建泛型数组，一般的方案是使用ArrayList。如果某些情况下需要自己实现，可以使用和ArrayList类似的方式。\n1、JDK通过创建Object[]的数组放对象，在取对象时进行类型转换，此时toArray函数通过泛型函数的参数获取类型。\n// 数组仍使用Object类型 private Object[] array = new Object[size]; // 在get函数中强制类型转换 public T get(int index){ return (T)array[index]; } // 转换成数组 public T[] toArray(T[] a){ // 此处a只用于获取类型  // 更严谨的实现参考上面的JDK代码  return (T[]) Arrays.copyOf(elementData, size, a.getClass()); } 2、或者传入具体的类型，由于传入的具体类型可以创建具体类型数组，因此可以直接实现T[] toArray()。可能是传入类型的方式不太优雅，JDK并没有使用这种形式。\nclass GenericArray{ private T[] array; // 构造函数直接传入类型，数组的强制类型转换会产生编译警告，此处直接用标签忽略  @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public GenericArray(Class\u0026lt;T\u0026gt; type, int size){ array = (T[]) Array.newInstance(type, size); } public T[] toArray(){ return array; } } 在泛型中创建具体的类实例 和上面的情况类似，要想在泛型类中创建具体的类型，也就是需要在类中能够得到T.class，通常需要使用两种方式：\n 将T.class通过函数或其它方式传入类中，通过反射机制创建。 泛型函数能够从参数的类型中获取T.class。  后面简单介绍构造函数包装后传入的方式。\n通过构造函数传入类型后创建类实例 对于T a = new T();，由于类型擦除无法创建，但可以通过在运行时传入类变量来实现创建，将类型通过构造函数传入。在有类型后，通过反射机制（newInstance）构建新的类。\npublic class ClassAsFactory\u0026lt;T\u0026gt;{ Class\u0026lt;T\u0026gt; kind; public ClassAsFactory(Class\u0026lt;T\u0026gt; kind){ this.kind = kind; } // 构建时传入 String.class  public static void main(String[] argvs){ ClassAsFactory\u0026lt;String\u0026gt; gClass = new ClassAsFactory\u0026lt;String\u0026gt;(String.class); } } 但是对于这段代码，编译器无法检查构造函数是否存在等问题，一般更建议使用显示类型工厂，在构造函数中传入new过具体类型的工厂类：\nInterface FactoryI\u0026lt;T\u0026gt;{ T create(); } // 在工厂类中传入具体的对象 Class IntegerFactory implements FactoryI\u0026lt;Integer\u0026gt;{ public Integer Create() { return new Interger(0);} } Class Foo2\u0026lt;T\u0026gt; { private T x; // 类型F用来限制参数为工厂类  public \u0026lt;F extends FactoryI\u0026lt;T\u0026gt;\u0026gt; Foo2(F factory){ x = factory.create(); } public static void main(String[] argvs){ new Foo2\u0026lt;Integer\u0026gt;(new IntegerFactory()); } 此时，具体工厂类由于针对具体的类型，编译期间可以对创建过程进行检查。\n《Think in Java》里还提到一种模板方法设计模式，没有太大的本质上的区别。\n","href":"/posts/technical/java_toarray_return_and_generic_type_erase/","title":"java从toArray返回Object[]到泛型的类型擦除"},{"content":"起因：EFI分区被删除导致引导问题。\n症状：\n  通过安装其它系统的方式。正好想试试其它的linux发行版，就在另一个分区装了deepin，完成后硬盘没有发现UEFI引导；然后又尝试装了openSUSE，仍没在硬盘发现UEFI引导。（失败）\n  通过live cd重新在efi分区安装grub。（wiki推荐的一般方式，仍失败）\n  通过live cd安装refind。（仍不行）\n  安装的系统可以通过manjaro live cd直接boot。\n  安装win10可以发现UEFI的引导方式（只启动win10，安装grub也只启动win10）\n  引导的问题网上的解决方案很多，对于一些新的电脑UEFI的方式应该很好修复，但一些比较老的电脑可能出现各种坑问题，用legacy的引导还是稳定一点。\nUEFI的引导通过grub的各种安装尝试都无法被主板识别，一直检测不到硬盘UEFI的启动项。怀疑主板并不支持linux grub2写入的UEFI引导信息，只支持windows的。最后通过安装win10，用refind覆盖win10的efi启动条目解决问题。\n最常规的修复方式 通过live cd 将系统烧入U盘，启动U盘进入系统后修复。涉及两种方式：\n 通过boot-repair grub-install 命令安装  还有通过grub命令行的方式，不常用没折腾。\n建议烧入的系统为ubuntu和manjaro。deepin的live cd在我的电脑上有显示的bug，而且添加ppa有一点坑。openSUSE上的grub命令和debian系arch系不怎么一样。ubuntu的主要优点在于可以通过安装boot-repair进行一键修复，manjaro和arch的live cd提供了直接的manjaro-chroot以及arch-chroot，进入后直接安装grub就行，而且manjaro的live cd支持直接引导启动efi分区中的系统。\n在下面的两种操作之前，最好通过gparted等软件新建一个efi分区（fat32,一般几十兆，openSUSE建议不小于500M，带efi标签）。\n基于ubuntu的boot-repair 网上的资料多操作也不复杂，主要注意U盘从UEFI模式启动。\nsudo add-apt-repository ppa:yannubuntu/boot-repair -y sudo apt-get update sudo apt-get install boot-repair -y sudo boot-repair grub-install 命令安装 使用manjaro live cd，其它的系统可能需要安装grub2、efibootmgr、grub-efi-amd64、os-prober等包。\n以下需要root权限，sudo -i或命令前加sudo\n1、 查看要引导系统的分区和efi分区的编号（fdisk -l） 2、 挂载引导系统的分区（一般 mount /dev/sda4 /mnt） 3、 挂载efi分区到系统分区的/boot/efi目录（`mount /dev/sda2 /mnt/boot/efi） 4、 chroot到硬盘系统分区\n对于ubuntu\nmount --bind /dev/ /mnt/dev mount --bind /proc /mnt/proc mount --bind /sys /mnt/sys chroot /mnt 对于manjaro直接\nmanjaro-chroot /mnt 5、 安装grub\ngrub-install --target=x86_64-efi /dev/sda2 # target默认是x86_64-efi grub-grub-mkconfig -o /boot/grub/grub.cfg update-grub 各种操作和问题 上面的操作在一般较新的电脑上就能启动了。\nrefind 引导程序 可以在启动时动态检查和引导所有硬盘里efi分区里的配置，还可以设置各种主题。grub每次只能识别efi分区EFI目录下的某一个写好的配置。\n安装后直接运行refind-install脚本即可，也可以指定efi分区。\n安装完仍默认启动win10 UEFI支持一种安全模式，win10会独占UEFI，双系统时需要在win10中关闭安全启动。（没碰到，具体资料可搜）。\n其次，修改efi的引导顺序，进入win10后，使用bcdedit命令\nbcdedit /enum # 查看引导 bcdedit /default {12277df3-07da-11e8-a54c-9f200771404e} # 设置默认项 # 如果上面的设置默认没有用，可以暴力修改windows的引导文件到其它的引导文件 # refind可以改为其它的系统 bcdedit /set {bootmgr} path \\EFI\\refind\\refind_x64.efi 上面的命令在cmd里没问题，最近在powershell里跑挂了，可能是命令解析规则不同，简单的操作还是cmd吧。\nwin10启动几次就让grub引导消失的问题 win10会默认修改UEFI的引导顺序。\n好像是win10 系统配置-\u0026gt;常规 里的最后一个勾，用了上面的方式后，没怎么遇到这个问题。\n启动时仍没有UEFI引导选项的问题 一般上面的操作能解决绝大多数电脑的，我的2代i3电脑开机f12的启动菜单中，怎么安装linux都出现不了UEFI菜单，但安装windows能，于是一般先装windows再改默认引导\u0026hellip;\n一次windows的UEFI在装完系统第一次启动后也不显示无法选择，在BIOS里设置只允许UEFI启动，竟然启动了\u0026hellip;.\n更坑爹的是，双硬盘时启动不了，通过换sata线的接口就启动了\u0026hellip;\n","href":"/posts/technical/grub_uefi_repair/","title":"一次修复linux的efi引导的集中方法总结记录"},{"content":"","href":"/tags/raspberry/","title":"raspberry"},{"content":"感觉这方面的资料最好优先google英文的，中文博客上竟然连scratch2用的哪套GPIO的编号都找半天\u0026hellip;\n树莓派的apt仓库里有三个scratch版本，其中scratch为稳定版，scratch2和scratch3还在测试仓库，改成了基于跨平台技术electron的开发。我在树莓派3b上scratch3打开没反应，scratch2虽然是测试版，但使用没发现问题，打开速度上明显比scratch慢。\nscratch2相比scratch在GPIO上简化了大量的操作，不用通过广播的形式发送各种GPIO server的消息，将GPIO的操作简化成了两个函数。\n1. 安装Scratch2 sudo apt install scratch2\n2. 控制相关的GPIO口 更多模块 -\u0026gt; 添加扩展 选择Pi GPIO\n下面会多出两个控制GPIO的函数。\nset gpio *id* to *output high* 此函数用于设置gpio口，第一个指定GPIO的id，第二个指定功能，如输出高电平、输入低电平、输入模式。\ngpio *id* is high? 此函数用于控制语句中作为条件，判断当前gpio口是否为高电平，通常用在输入模式下检测传感器一类的输入。\n就这么简单，剩下的当成简单单片机用就行了。\nGPIO 针脚图 树莓派有多种GPIO的编号方式，使用python等调用需要指定具体的编码，scratch用的是下图这种（图源自树莓派官网）。\n","href":"/posts/technical/raspberry_scratch2_gpio_control.md/","title":"树莓派基于scratch2控制GPIO"},{"content":"网上教程很多，但是google和百度排在前面的博客操作起来各种问题，因此简单写写。\n1. 烧录系统 官网有可以系统可以下载，通常建议，有特殊需求可以考虑其它的几个系统。\n官网推荐使用balenaEtcher烧录系统。（很多博客推荐先一个工具格式化sd卡，然后win32imagewriter不知道是不是以前的做法）\n2. 配置系统 上面的烧录后，sd卡会被分为多个分区，其中windows系统下能识别的只有一个名为boot的分区，存储启动相关的配置文件。\n2.1 开启ssh raspbian 系统默认不开启ssh远程访问，在boot分区下新建文件名为SSH的文件（内容为空无后缀），系统启动时检测到此文件会开启ssh进程。\n2.2 配置wifi 在boot分区下新建文件名为wpa_supplicant.conf的文件，添加以下内容：\ncountry=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\u0026quot;yourWifiName\u0026quot; psk=\u0026quot;passwd\u0026quot; key_mgmt=WPA-PSK priority=1 } 修改其中的wifi名和密码（ssid与psk）\n如果想省事可以直接用网线连上路由器\n3. 远程访问 3.1 查找树莓派ip 此处需要将电脑和树莓派连接在同一路由器下。\n方法一：浏览器上输入192.168.1.1 （根据不同路由器网关不同），进入管理页面查看树莓派ip。\n方法二：使用软件Advanced IP Scanner扫描局域网中的树莓派。\n3.2 ssh 远程登录 ssh是linux上最常用的命令行远程访问工具。\n使用软件putty用于远程ssh登录，输入树莓ip，密码为raspberry。\n3.3 开启vnc vnc类似windows上的rdp远程登录，是linux上最常用的带界面远程访问协议。\nssh远程登录后，sudo raspi-config 然后在Interfacing Options -\u0026gt; VNC里enable VNC服务。（貌似是启动vnc的服务后设置了开机启动）\n然后使用realVNC viewer输入ip访问即可。\nvnc默认使用5900端口，当端口占用时会往后推使用5901等端口。多个vncserver运行时需要使用ip:590x的形式指定端口号。\n此处小坑 树莓派自带的vnc server使用的加密方式和tigerVNC viewer不兼容，会显示以下错误：\nUnknown authentication scheme from VNC server: 13, 5, 6, 130, 192\n使用realVNC客户端正常访问。\n还可以考虑在树莓派上安装tightvncserver。\n4. 附软件源安装 默认的软件源仓库的网速较慢，使用apt安装某些软件时过于龟速，可以考虑换国内的镜像源。如等。\n","href":"/posts/technical/raspberry_from_install_to_remote_access/","title":"树莓派从烧录系统到通过wifi远程访问（新树莓派配置，无显示器、网线、键盘）"},{"content":"","href":"/tags/software/","title":"software"},{"content":"vsftpd (very secure ftpd)，这软件在权限管理什么的也太安全了点，一点小细节出问题也会出现访问不了的问题。只是想架个ftp局域网传文件，一些博客里小细节和背后设计没有提到，踩了一点坑，记录一下简单的匿名ftp访问方案。\n主要步骤 1. 使用包管理器安装 vsftpd 。（apt, yum, pacman等)\n2. 修改配置文件 /etc/vsftpd.conf\nanonymous_enable=YES # 允许匿名访问 write_enable=YES # 允许写文件 anon_upload_enable=YES # 允许匿名用户上传文件 anon_mkdir_write_enable=YES # 允许匿名用户创建目录和写权限 anon_other_write_enable=YES # 允许匿名用户删除、重命名等其它权限 这个在配置文件里默认找不到 3. 新建匿名访问的用户和文件夹\n通过 local_enable 选项能够允许ftp通过本地用户访问，登录之后会访问用户的主目录。当使用匿名用户访问时，vsftpd会将用户名为ftp的用户作为登录用户，进入ftp用户的主目录。\n注意，考虑到安全问题，ftp匿名用户的主目录必须为只读，如果需要上传文件，需要在主目录下新建有写权限的文件夹。\n通常会选择/var/ftp文件夹存放文件而不是用户默认的/home，因此可以修改用户的主目录位置（一般放在/var/ftp），不修改也能用。再次强调，注意主目录对ftp用户的权限必须为只读。\nsudo mkdir /var/ftp # 新建用户文件夹 sudo useradd -d /var/ftp ftp # 新建用户，并指定用户home目录  # 如果ftp用户已经存在，在/etc/passwd文件里改用户目录为/var/ftp sudo mkdir /var/ftp/pub # 新建一个用于写数据的文件夹 sudo chmod 777 /var/ftp/pub # 修改文件夹权限 4. 启动服务\nsystemctl start vsftpd\n其它 防火墙和SELinux如果使用了需要添加响应的通过规则。\n测试访问可以直接用浏览器 ftp://ip_address，linux下可以使用FileZilla。\n","href":"/posts/technical/vsftpd_configuration/","title":"vsftp 匿名访问设置设置"},{"content":"","href":"/tags/log4j/","title":"log4j"},{"content":"简述 使用log4j可以根据配置文件控制输出日志的级别，记录到文件、命令行等的位置，不需要代码上的更改。\n日志在一定程度上会影响性能，特别是高并发环境。一般更建议使用log4j 2.x，在性能上有较大的提高，由于hadoop 2.7使用的log4j 1.2，下面主要写这一版本。\n本文主要介绍log4j：\n 根据日志级别记录日志 (logger上设置） 运行时决定具体的记录位置（appender上设置）和日志格式（layout上设置）  一些概念 日志级别（priority，代码里为level） 日志级别从低到高为trace, debug, info, warn, error, fatal。默认级别为info，低于设置级别的日志不会被打印。\n常用组件 一般情况下常设置的组件有logger，appender， layout。\n用类的方式表达三个组件的关系为\nLogger{ name; level; // 控制日志级别 appenderList; // 可对应多个appender } Appender{ name; // 控制文件位置 如fileAppender layout; // 控制格式 filter; // 过滤部分日志 } logger logger以一种树状关系管理日志的类型，log4j.rootCategory为根节点，如果没有标记 log4j.additivity.MyLogger = false ，则子logger会默认继承上一级的设置。\n通过树的组织形式，对不同的包中的不同的类，可以分别设置不同的日志方式。\n通过点表示层级，如com.foo为com.foo.Bar的上级\n关于category，早期的log4j使用category较多，但在log4j 1.2之后，建议使用logger代替category。\nappender 主要用于\n 控制日志的输出位置，当前支持the console, files, GUI components, remote socket servers, NT Event Loggers, and remote UNIX Syslog daemons. 控制日志的格式（通过下面的layout）  一个logger能够指定多个appender，使日志记录在多个位置。\nlayout 用于控制日志的格式，一个典型的格式为\n  %r [%t]%-5p %c - %m%n 会得到： 176 [main] INFO org.foo.Bar - Located nearest gas station.\n上面的日志分别对应：程序运行时间 线程 优先级 category的名称 日志信息\nlog4j.properties 配置 提供了两种动态的配置方式，一种使用配置文件log4j.properties（更建议），另一种使用java代码直接配置。\n一般涉及：\n 配置rootLogger (配置全局的appender和priority) 配置子logger (配置指定类的appender和priority) 配置appender （配置日志记录的位置等属性） 配置layout （配置日志输出的格式）  示例 # root logger 的level和对应的appender (fileAppender在后面定义） log4j.rootLogger=info, fileAppender # 定义fileAppender 为 File appender log4j.appender.fileAppender=org.apache.log4j.FileAppender log4j.appender.fileAppender.File=/home/abc/test # 定义 fileAppender 的 layout log4j.appender.fileAppender.layout=org.apache.log4j.PatternLayout log4j.appender.fileAppender.layout.conversionPattern=%m%n # 子logger配置 针对com.a.Test4log这个类 设置为System.err的输出 log4j.logger.com.a.Test4log = INFO, myConsole # 输出到标准err的appender log4j.appender.myConsole=org.apache.log4j.ConsoleAppender log4j.appender.myConsole.target=System.err # 定义layout输出格式 log4j.appender.myConsole.layout=org.apache.log4j.PatternLayout log4j.appender.myConsole.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n myConsole 分层的语法略奇葩，而且前面可以用到后面定义的变量。\njava代码调用 Log log = LogFactory.getLog(Test4log.class); log.info(\u0026#34;test\u0026#34;); 程序会在classpath下查找log4j.properties，因此一般放在src/main/resources文件夹下\n","href":"/posts/technical/log4j_properties_simple_introduction/","title":"log4j 1.2 配置和使用简述"},{"content":"","href":"/categories/life/","title":"life"},{"content":"","href":"/tags/reading/","title":"reading"},{"content":"人类相比一般动物在身体上的特殊性 大脑和直立行走。\n脑容量的增大使人类拥有更强的思维能力；直立行走使人类的手能做更多一般动物做不了的事，如制作和使用工具，尤其是使用火。但脑容量的增加导致耗能增加，只占体重的2%却消耗20%的能量，其它猿类只占约8%，直接导致了肌肉萎缩。\n直立行走使臀部变窄，使女性为了正常生育只能让婴儿提前出生，导致人类婴儿早期发育时间相比其它动物较长。同时，由于一个人很难照顾下一代间接促进了人类的合作。\n人类使用的石器工具更多的是用来敲碎骨头吃其它动物剩下的骨髓，此时还只是在食物链中层。用火使人类相比其它动物能够动用超越自身身体的力量，初步战胜其它的动物。并且用火烹饪过的食物病菌和寄生虫更少且易于消化。\n语言能力的发展与认知革命 在非洲的智人走向世界前，人类还有欧洲的尼安德特人和亚洲的直立人等，同样掌握了用火和使用工具等技术以及群体协作。大约7万年前，智人从非洲向其它区域扩张，智人所到之处的其它人类开始在地球上消失，最终智人统治整个地球。对于智人为什么能够战胜其它的人类，书中给了一个很有意思的观点，最重要的靠的是智人在语言交流上的虚构能力（认知革命）。\n通过很多动物都存在的简单语言，使人类能够进行小规模的合作（如传达危险信息等）。而相比动物表达的“小心，有危险”，人类能够更精确的表达出“在附近xx方向距离xx的位置有xx只狮子，我们应该\u0026hellip;”。\n书中认为人类的语言交流更重要的是了解人类之间的信息以创建一个巨大的团队，如一个部落的其它人员做什么、谁更靠谱。作者提到现代智人能够聊天长达数小时之久，通过日常聊天交流，使人类能够更容易了解群体的信息。但根据其它动物以及现代人类的观察，仅仅凭借一般的语言交流难以维持一个更大规模的群体（难以超过150人），黑猩猩族群极少情况下能超过100只，数量增加容易造成族群分裂，现代的公司人数超过150人必须使用更强的管理模式。\n作者认为智人能够维护更大部落的能力，来自于能够构建并且相信虚构的事物（认知革命），如宗教、神话、国家甚至是现在的国家体系。可能一句神的指示就能调动成千上万的智人团结起来做一件事，而智人以外从地球上消失的其它原始人类很可能不具备这一能力。智人通过认知革命解决了一般哺乳类动物很难组成较大群体的问题，虚构能力使人类能以类似国家的形式维持大规模的群体。\n绕过基因组的快速进化 人类使用工具和大规模协作已经在食物链中的地位不断上升，通过语言交流和文字等形式又进一步加速了进化，开启了一条采用“文化演化”的快速道路。过去想要改变社会结构、发明新科技或是移居到新的地点，多半是因为基因突变、环境压力，需要一个相当漫长的过程。而人类能力的发展不再仅仅依赖基因上的改变，知识能够在一代又一代的发展中大量积累而不是重新开始。\n智人走向全世界的过程中导致了大量物种的灭绝，主要证据来源于很多大型动物的灭绝时间和智人抵达的时间吻合。传统的进化方式使物种之间有一个漫长的适应期，狮子捕猎能力加强的同时其它猎物也在不断的提高躲避能力。就像现代人开着坦克飞机穿越到古代，人类的“文化演化”道路直接打破了生态的平衡。\n个人理解 这本书的后几个章节也经常提到虚构。比如人权、自由、道德约束等，在最初的自然界并不存在，对于地球上的生存法则也不一定理所当然，但却成了如今人类社会大多数人所接受的东西。不断的进行各种虚构，并通过战争等一系列的生存竞争不断的检验和提高虚构的程度，有点定向基因突变的感觉。\n很多虚构不一定科学但有意想不到的结果。原始社会里神的存在，或许最初只是因为某些难以解释的自然现象，却很有可能是智人统治全球的原因之一。只因为大多数人相信规则。\n很多虚构也不一定都在往更好的方向发展。战争与竞争促进了社会生产力的不断提高，但并没有带来幸福度的大幅提升，当前社会带来的各种压力和欲望很多也出自于虚构，少有人能选择打破或逃避。也只因为大多数人相信规则。\n一个虚构的规则，一旦被大多数人相信而且短期无法被撬动，就会像一个真实具体的事物。或许相信规则也算是人类进化出的能力之一。社会一直都是少部分人改变规则而大多数人遵守。\n通过不断的创造故事与相信故事，人类已经编织出一个复杂的故事网络，制定出一系列超越自然界本身的规则。现代社会仍旧在制定各种规则。也在挑战各种规则。\n","href":"/posts/life/reading_brief_history_of_humankind_1/","title":"阅读《人类简史》-- 1.认知革命"},{"content":"首先吐槽，anki作为老牌软件，国内资料并不多。\n虽然html的卡片显示和python的插件式开发上看比较适合程序员，但从各种配置上感觉程序员用户量并不大。\n因此，想深度使用准备折腾。\n简单使用  淘制作好的卡片，导入 卡片可以套模板更美观（添加时的Cards选项，支持html） 添加单词和读音用FastWQ（只支持新版本，查词速度快） （已不支持新版本）插件里的awesome TTS很多人推荐但速度略慢 （已不支持新版本）添加单词可以用Word Query  官方文档https://apps.ankiweb.net/docs/manual.html\n插件编写文档https://apps.ankiweb.net/docs/addons.html\n插件安装 官网上找插件对应的id编号，然后打开anki的插件设置，添加插件中填入插件id号即可下载。\nFastWQ插件 首先在tools菜单下的FastWQ插件设置中，选择note type，然后第一列中选择单词所在位置，第三列选择想要用的在线字典，第四列的Fields中选择行对应的需要填入的内容。\n然后在add单词的目录中，先填入单次，然后点query\u0026ndash;\u0026gt; all fields，会将查到的结果填入所有的框。\n一些坑 删除卡片不会删除对应的媒体文件，需要点击 check media 后手动删除。\nanki有些历史遗留问题，大量的插件和资料都是在之前的anki 2.0.x上的，现在的2.1.x版本将pyqt4升级到pyqt5，很多插件没有跟着升级而无法使用。\nanki server 的安装 官网的速度爆表，而且有数据安全问题，因此官网给出了自建anki server的解决方案。\n百度上的大多使用 https://github.com/dsnopek/anki-sync-server ，可以基于pip2和python2直接安装，个人在基于Arch的linux下感觉坑多，在linux上的anki 2.1.9连不上上面python2的服务器（bug解决一个又出一个），更建议使用基于python3的fork项目：https://github.com/tsudoko/anki-sync-server 。\n基于python3的仓库 github上的readme已经写得比较清楚，下面的搬运点大概。\n1、clone 仓库\n git clone https://github.com/tsudoko/anki-sync-server.git\n2、安装anki或anki-bundled相关的库\n直接使用包管理器安装 sudo pacman -S anki\n如果包管理器里没有anki（如debian），也可以用pip安装anki-bundled相关的库\n$ git submodule update --init # anki-bundled已经加入为submodule，可以先更新 $ cd anki-bundled $ pip install -r requirements.txt # 安装相关的库 3、安装webob\npip install webob\n4、修改 ankisyncd.conf 文件\n文件中保存了主要的配置，主要改端口，默认端口一般也就能用。\n5、创建用户\n./ankisyncctl.py adduser \u0026lt;username\u0026gt;\n6、启动服务器\n python -m ankisyncd\n客户端配置 android anki 在高级设置里填上ip和端口就行。\nanki桌面版2.1.x 修改了添加插件方式。在插件文件夹下新建一个新的文件夹（官方插件命名都是数字方便更新，用字母也行），然后在其下新建一个文件__init__.py，加入以下内容。\nimport anki.sync, anki.hooks, aqt addr = \u0026#34;http://127.0.0.1:27701/\u0026#34; # put your server address here anki.sync.SYNC_BASE = \u0026#34;%s\u0026#34; + addr def resetHostNum(): aqt.mw.pm.profile[\u0026#39;hostNum\u0026#39;] = None anki.hooks.addHook(\u0026#34;profileLoaded\u0026#34;, resetHostNum) anki桌面版2.0 直接在插件文件夹下新建一个.py文件（如ankisyncd.py），加入以下内容。\nimport anki.sync addr = \u0026#34;http://127.0.0.1:27701/\u0026#34; # put your server address here anki.sync.SYNC_BASE = addr anki.sync.SYNC_MEDIA_BASE = addr + \u0026#34;msync/\u0026#34; 基于python2的server 百度上搜到的差不多都是这种，可能出各种bug，不怎么建议折腾，列一下大概的折腾步骤和踩坑。\n简直就是个没人测试的系统！各种莫名奇妙的bug需要调。\n好不容易装好了，局域网下卡片数量较多时（4000）速度也不怎么样\u0026hellip;.\ndebian 系统安装稍正常\neasy_install ankiserver # 为什么不用pip？ 因为会有莫名奇妙的错误！！ mkdir ankiserver_data # anki server的数据目录 cd ankiserver_data cp /usr/lib/python2.7/site-packages/AnkiServer-2.0.6-py2.7.egg/examples/example.ini ./production.ini # 复制配置文件，如有必要可以改改端口一类的 ankiserverctl adduser test # 添加用户 ankiserverctl debug # debug模式启动 （为什么是debug，你猜一次成功的概率？） 如果此时显示了正常启动然后手机能连上就算幸运了。\n踩过的坑：\n 虽然python3的ankiserver在pip仓库里有，但还是不试为好。 要用 easy_install 代替pip（小心找不到文件一个个改路径） 装server的系统上最好不要装anki客户端（anki使用的python3莫名奇妙会被python2的server调用\u0026hellip;.估计是anki在/usr/share文件夹下，/usr/share又是PATH的目录，如果非要装就把/usr/share/anki改个名字吧，虚拟环境都上了还是跳到anki客户端的python3代码上报错） andriod手机登录时显示服务器和手机时间差了5s，可能折腾一下ntp就行吧 系统编码需要设置成utf-8（默认用英语没碰到这问题）  安卓手机使用正常，但是anki 2.1.9 linux桌面版连不上。\n","href":"/posts/technical/anki_and_anki_server/","title":"anki的使用以及anki server的配置"},{"content":"在从deepin的kdd桌面换到xfce桌面后，命令行和界面操作上动不动会让主机响一声。\nmanjaro的xfce版也是如此，不知道是不是linux下xfce的通病。\n主要是搜索的时候百度的结果很奇葩\u0026hellip;\n用关键字 beep of xfce4 搜到了arch wiki下的内容，原来这玩意叫pc speaker，针对不同的情况有不同的解决方案。\n最简单粗暴的方式 内核中加载了pcspkr模块导致的主板声音，rmmod移除此模块，然后/etc/modprobe.d文件夹下加入黑名单，使开机过程不加载。\n  rmmod pcspkr echo \u0026ldquo;blacklist pcspkr\u0026rdquo; \u0026gt; /etc/modprobe.d/nobeep.conf 具体参考 https://wiki.archlinux.org/index.php/PC_speaker\n","href":"/posts/technical/mainboard_speaker_close/","title":"linux 关闭主板上的蜂鸣器声音"},{"content":"安装manjaro时使用独显的单显示器，在主板上接第二个显示器一直没反应。\n几个问题和解决 BIOS里检查是否关闭了集显开关 大多数显卡的默认设置都会在识别独显后关闭集显，要使用集显上的接口需要单独设置。\n如果接口允许，最好将两个显示器都接在独显上。\n基于KDE等桌面 如果主板和显卡驱动正常，一般各大桌面环境都支持GUI配置，可以在显示设置里直接修改。\n使用 xrandr 识别和控制显示器 xrandr 直接执行会得到显示器的连接状态，获取显示器的名称后可以用下面的命令显示。\n（其中DVI-I-1-1与VGA1为两个显示器的名称）\nxrandr --output DVI-I-1-1 --mode 1440x900 --primary --output VGA1 --mode 1366x768 --pos 1440x132 设置输出的显示器以及显示参数，每个--output后接显示器名以及参数，--mode指定分辨率，--primary指定主显示器，--pos指定位置，或者用--right-of指定相对位置。\n更进一步的设置可以在arch wiki\nxrandr 找不到显示器 xrandr \u0026ndash;listproviders 得到当前的显示器输入设备（一般name为Intel的是集显，name为nouveau的是开源独显驱动，Nvidia为闭源显卡驱动）\nxrandr \u0026ndash;setprovideroutputsource 0 1 将上面的设备设置为输入源\n如果xrandr \u0026ndash;listproviders 没有得到所有的输入源，则需要折腾驱动。\n驱动问题 一般建议将两个显示器都接在独显上，出问题的概率更低（独显一般口不够或者需要转换略尴尬）。\n我将显示器分别接在独显和主板接口上，在manjaro和deepin两个系统下都发现NVIDIA驱动有问题，primary显示器会显示两个显示器的内容。而将显卡驱动切换到开源驱动（nouveau）时正常(据说开源驱动性能略低）。\nmhwd -li --pci 查看已经安装的驱动 mhwd -l --pci 查看能用的驱动 sudo mhwd -r pci video-nvidia 移除驱动video-nvidia sudo mhwd -a pci videa-linux 安装开源显卡驱动（nouveau） manjaro上通过mhwd简化了各种配置，详见：\nhttps://wiki.manjaro.org/index.php/Configure_Graphics_Cards\nAwesomeWM 默认快捷键：\nctrl+super+j/k 屏幕之间焦点移动 super+o 当前窗口移动到另一个屏幕\n默认的设置不多，想要的功能可以自己撸，如\n添加一个快捷键，将窗口移动到另一个屏幕并且保持焦点在当前屏幕\nawful.key({ modkey, \u0026#34;Shift\u0026#34; }, \u0026#34;o\u0026#34;, function (c) c: move_to_screen() awful.screen.focus_relative(-1) end, {description = \u0026#34;move to other screen without move focus\u0026#34;, group = \u0026#34;MySettings\u0026#34;}) ","href":"/posts/technical/dual_monitor_manjaro_awesome/","title":"manjaro AwesomeWM 上使用双显示器"},{"content":"本来还很简单的事，被默认的选项弄出一堆坑\n步骤 先安装fcitx用来管理输入法，然后安装搜狗输入法并配置，然后添加环境变量使相关的应用默认加载fcitx。\n1. 安装fcitx以及配置 sudo pacman -S fcitx fcitx-im fcitx-configtool\nfcitx 为基础安装包，fcitx-im用于GTK/QT等界面上使用的包，fcitx-configtool为配置界面（kde下还能安装一个kde版的configtool）。\n2. 安装搜狗输入法 yaourt fcitx-sogoupinyin\n此处有坑，默认的安装方式会编译安装qtwebkit，速度非常的慢（一个小时午觉后还没好\u0026hellip;)\n在库的官方说明中（来自 https://aur.archlinux.org/packages/fcitx-sogoupinyin/ ）依赖项为qtwebkit (qtwebkit-bin)\n其实只依赖qtwebkit-bin，因此先安装qtwebkit-bin可以解决依赖问题（不到一分钟\u0026hellip;)\n yaourt -S qtwebkit-bin\n3. fcitx 设置中添加搜狗拼音 fcitx configuration中点加号添加sogou pinyin（默认语言为英语时需要勾选一个选项）\n4. fcitx环境变量的添加 gui应用的环境变量一般不通过profile和bashrc。\narch wiki下的内容：\n  KDM, GDM, LightDM 等显示管理器，请使用 ~/.xprofile arch wiki 警告: 上述用户不要在~/.xinitrc中加入下述脚本，否则会造成无法登陆。(但在里头加了也没挂) 如果您用 startx 或者 Slim 启动，请使用~/.xinitrc 中加入\n  export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx\n  如果你使用的是较新版本的GNOME，使用 Wayland 显示管理器，则请在/etc/environment中加入\n  GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx\n参考链接中有更详细的说明，我用的manjaro+xfce4以及后面改装的cinnamon和awesome都是在lightDM下该的.xinitrc，没有.xprofile文件，也能正常用。 （注意添加在最后exec $(\u0026hellip;)的前面）\n使用manjaro+kde和awesomewm混用时，加在.xinitrc下莫名奇妙的失效，不知道和为了deepin-wine运行的cinnamon-xsettings有没有关系，加在/etc/environment文件中正常运行。\n5. 注销后重新登录 汇总  yaourt -S qtwebkit-bin  sudo pacman -S fcitx fcitx-im fcitx-configtool yaourt fcitx-sogoupinyin\nfcitx configuration 配置搜狗输入法\n添加fcitx相关的环境变量\n注销重新登录\n少量问题  fcitx的安装一般会自动启动（右下角会有输入法图标，top里可以看），如果在i3 awesomewm等窗口管理器中没有自动启动，则将fcitx -r加入到自动启动的脚本中。 ibus输入法管理与fcitx冲突，如果已有安装需要禁用。  主要参考 https://wiki.archlinux.org/index.php/Fcitx_(简体中文)\nhttps://www.yangshengliang.com/kaiyuan-shijie/linux-shijie/651.html\n","href":"/posts/technical/sogou_input_install_in_arch_manjaro/","title":"manjaro (arch) 安装搜狗输入法"},{"content":"基于AUR的安装是没什么难度了，主要安装后会出各种问题，还有选不同的包的影响。\n官方的wiki上推荐安装deepin-wine-tim，基于wine和最新版的tim。安装后存在qq密码每次都要输入的问题（201804测试没有此问题，但还是不太稳定，2018年因为wine的更新导致挂了两次只能回退）。\n更推荐使用的deepin.com.qq.office，基于deepin-wine，配置好了比较稳定。\n安装步骤 安装  yaourt -S deepin.com.qq.office\nps：吐槽，安装deepin-wine的各个确认略多。 d\nqq提取消息、截图等快捷键设置 在/opt/deepinwine/tools/sendkeys.sh脚本能够传递快捷键，如直接运行./sendkeys.sh a 则会向qq或tim进程发送 ctrl+alt+a。\n不同桌面环境添加快捷键的方法差不多，主要步骤：\n setting -\u0026gt; keyboard -\u0026gt; shortcut 添加快捷键，选择上面的脚本，在脚本后面加上a 指定运行脚本的快捷键  此时按快捷键后相当于qq中按 ctrl+alt+a (截图)\n同理可以设置qq其它快捷键\n一般问题 大多出现在基于wine的tim上，基于deepin的tim问题很少。\ndeepin-wine在非gnome系的桌面上的运行问题 3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误\n  X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)\n由于deepin-wine依赖了gnome系（mate,cinnamon,gnome）的setting-daemon，需要安装后运行（一般加入开机启动）\nsudo pacman -S cinnamon-settings-daemon /usr/lib/cinnamon-settings-daemon/csd-xsettings 无法输入中文 如果其它地方可以使用输入法，一般为环境变量的问题，fcitx没有配置好。\n粗暴解决方式: 下面的文件夹中加入环境变量\n/opt/deepinwine/apps/Deepin-TIM/run.sh\n  export XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; export GTK_IM_MODULE=\u0026ldquo;fcitx\u0026rdquo; export QT_IM_MODULE=\u0026ldquo;fcitx\u0026rdquo;\n正常的解决方式: 根据系统环境在.xinitrc、.xprofile、/etc/environment等文件中选择正确的文件加入环境变量。（具体参考fcitx的配置）\n基于wine的问题 文字过小问题 出现在基于wine的TIM上，deepin-wine下没问题。\n后面列出的官方wiki上有设置字体的方法，我只是在winecfg命令后加大了dpi，还可以具体改字体。（已经能忍，不想折腾）\n表情无法使用 出现在xfce4上\nall settings -\u0026gt; window Manager -\u0026gt; Focus -\u0026gt; 取消勾选 \u0026ldquo;automatically give focus to newly created windows\u0026rdquo;\n点右键的菜单都不能用的问题 一个很烦的一点，特别是不能收藏表情，保存图片，还不能屏蔽群消息！\n从xfce4转到i3wm后就好了，不知道是不是xfce4的专属bug，现在不想折腾，以后再换KDE一类的试试。\n貌似xfce4对wine特别是wine qq不怎么友好。\n每次登录显示身份过期,必须重新输入密码 安装deepin后卸载xfce4,然后就出现了这一奇葩问题.\n安装xfce4后解决问题.（不知道怎么出的问题，也不知道怎么好的）\nother 一些没有出现的问题，在wiki上有说明，可在后面的链接上找。此处只列问题：\n 文件被占用 字体设置  参考 从deepin系统转向arch的，deepin在国产软件的处理上确实相当不错，deepin-wine应该算是对开源社区做出的最大贡献之一，解决qq这一大刚需问题。\nhttps://wiki.archlinux.org/index.php/Tencent_QQ_(简体中文)\nhttps://aur.archlinux.org/packages/deepin.com.qq.office/\n","href":"/posts/technical/tim_install_wine/","title":"arch linux (manjaro) 下运行tim和qq"},{"content":"i3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误\n  X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)\n在gnome、mate、cinnamon三个桌面上运行较好，xfce4上运行有少许焦点上的bug，其它桌面环境和管理器下直接出上面的错误。\n最近终于在aur上看到是因为deepin-wine依赖了gnome-settings-daemon（gnome系的cinnamon和mate的对应组件也能用），启动后就能正常运行，但AwesomeWM会使用xsettings对应的主题，KDE基本正常运行，其它非gnome系的桌面环境未测试。\n解决方案 1. 安装gnome-settings-daemon (arch 系） sudo pacman -S gnome-settings-daemon ubuntu 下的包和运行的程序名略不一样，参考：\nhttps://github.com/wszqkzqk/deepin-wine-ubuntu/issues/12#issuecomment-443656358\n2. 在tim启动脚本中加入启动 /opt/deepinwine/apps/Deepin-TIM/run.sh 的文件前添加下面的行：\n/usr/lib/gsd-xsettings \u0026amp;\n注意 主要缺点——影响主题（某些桌面环境） AwesomeWM在使用xsettings之后，主题等需要与对应的xsettings设置相对应。如使用gnome-settings-daemon时，需要在gnome的设置里更改主题。使用lxappearance修改主题只会更改~/.gtkrc-2.0等文件，不会生效。\ncsd-xsettings 的影响 因为大小和简洁的原因从gnome的xsettings换到了cinnamon的xsettings，下面的设置在gsd-xsettings上未测试。\ncsd-xsettings 主要影响两个地方：1. 启动过程； 2. 在tim内调用外部程序打开链接的过程（如打开网页、打开本地目录）。\n可以考虑启动后关闭对tim，可以避免影响系统主题一类的问题，但会导致无法调用外部程序。加上运行后5s关闭的参数即可:\n/usr/lib/cinnamon-settings-daemon/csd-xsettings --exit-time 5 \u0026amp;\n附：使用cinnamon的xsettings的设置 主题的问题在awesome这种环境下略坑，懒得去试gnome上的主题设置需要哪些包，安装整个gnome的包需要800多M，直接安装了cinnamon的基础包（90M左右）。和gnome只是些名字上的区别：\nsudo pacman -S cinnamon # awesome的autorun里加入下面程序使开机运行 /usr/lib/cinnamon-settings-daemon/csd-xsettings 在系统设置里可以下载和更改主题\n小坑   tim和qq会在点击好友图像时卡死的情况。原因之一可能是pulseaudio进程，kill掉就行，会影响声音的调整。（千里之外的两个程序不知道为什么会卡一起）\n  使用csd-xsettings时可能出现无法调声音的情况，关了之后就行了，懒得再往下折腾了\u0026hellip;\n  这两个问题不太记得当初什么情况，在kde版本的manjaro上已经不存在了（201907）。\n","href":"/posts/technical/deepin_wine_run_in_not_gnome_desktop_environment/","title":"在非gnome系桌面环境下运行deepin-wine tim的错误解决"},{"content":"","href":"/categories/research/","title":"research"},{"content":"之前的附件使用zotfile单独的文件夹管理，换了一块硬盘，挂载目录发生变化后zotero里所有的附件都打不开，在zotero的目录设置和zotfile的目录设置里改了都没用。\n使用sqllite的浏览器看了一眼zotero的存储数据库(zotero.sqlite)，在表itemAttachments中存储了所有附件的类型地址等信息，发现里头的地址全都使用的绝对路径！！\n重点在于设置zotero和zotfile的附件路径和转移文件。\n使用网盘同步的不用折腾这些。\n方法一：设置为相对路径并修改文件 设置  zotero preferences -\u0026gt; Files and Folders -\u0026gt; Linked Attachment Base Directory 设置存储路径 （注意不是 data directory） 把zotfile里的路径也改到这（不知道具体什么机制，zotfile有个相对路径的pull request不知道读的是不是这个，懒得多折腾）  已有的文件移动   如果由于换硬盘换系统一类的问题，先使用软连接指向原来的目录，让zotero能够找到原来的文件。（源目录可以使用sqllite的浏览器看到）\n  在library下全选所有的items，然后右键 Manage Attachments -\u0026gt; Rename Attachments。（看起来是重命名，实质上会移动所有的文件）\n  此时此前附件中的绝对路径/mnt/data/...会变成attachments：catagory1/test1.pdf 类似的相对路径。\n方法二：直接操作sqllite数据库来改 下面的语句供参考，建议稍了解后操作，使用update导致数据丢失会很麻烦。\n把下面路径中的/home/fly/public_download/改成自己数据库里的路径即可。\nupdate itemAttachments set path=replace(path, '/home/fly/public_download/', 'attachments:') where path like '/home/fly/public_download%' 最后 跨操作系统或者跨目录直接设置到相同的目录即可。\n","href":"/posts/research/zotero_multiple_directory_pdf_sync/","title":"zotero zotfile插件 pdf附件文件夹在多系统下的同步设置"},{"content":"Spark提供了HDFS上一般的文件文件读取接口 sc.textFile()，但在某些情况下HDFS中需要存储自定义格式的文件，需要更加灵活的读取方式。\n使用KeyValueTextInputFormat Hadoop的MapReduce框架下提供了一些InputFormat的实现，其中MapReduce2的接口(org.apache.hadoop.mapreduce下)与先前MapReduce1(org.apache.hadoop.mapred下)有区别，对应于newAPIHadoopFile函数。\n使用KeyValueTextInputFormat的文件读取如下\nimport org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat import org.apache.hadoop.io.Text val hFile = sc.newAPIHadoopFile(\u0026#34;hdfs://hadoopmaster:9000/user/sparkl/README.md\u0026#34;, classOf[KeyValueTextInputFormat], classOf[Text], classOf[Text]) hFile.collect 使用自定义InputFormat InputFormat是MapReduce框架下将输入的文件解析成字符串的组件，Spark对HDFS中的文件实现自定义读写需要通过InputFormat的子类实现。下面只写简单的思路，具体的可以参考InputFormat和MapReduce相关资料。\nInputFormat的修改可以参考TextInputFormat，继承FileInputFormat后，重载createRecordReader返回一个新的继承RecordReader的类，通过新的RecordReader读取数据返回键值对。\n打包后注意上传时将jar包一起上传：\n`./spark-shell \u0026ndash;jars newInputFormat.jar\n运行的代码和上面差不多，import相关的包后\nval hFile = sc.newAPIHadoopFile(\u0026#34;hdfs://hadoopmaster:9000/user/sparkl/README.md\u0026#34;, classOf[NewTextInputFormat], classOf[Text], classOf[Text]) 一些坑 序列化问题 在读取文件后使用first或者collect时，出现下面的错误\n  ERROR scheduler.TaskSetManager: Task 0.0 in stage 2.0 (TID 18) had a not serializable result: org.apache.hadoop.io.IntWritable Serialization stack: - object not serializable (class: org.apache.hadoop.io.IntWritable, value: 35) - element of array (index: 0) - array (class [Lorg.apache.hadoop.io.IntWritable;, size 1); not retrying 18/12/15 10:40:10 ERROR scheduler.TaskSetManager: Task 2.0 in stage 2.0 (TID 21) had a not serializable result: org.apache.hadoop.io.IntWritable Serialization stack: - object not serializable (class: org.apache.hadoop.io.IntWritable, value: 35) - element of array (index: 0) - array (class [Lorg.apache.hadoop.io.IntWritable;, size 1); not retrying\n当键值对是其它的类型时，还可能出现类似的：\n  ERROR scheduler.TaskSetManager: Task 0.0 in stage 2.0 (TID 18) had a not serializable result: org.apache.hadoop.io.LongWritable ERROR scheduler.TaskSetManager: Task 0.0 in stage 2.0 (TID 18) had a not serializable result: org.apache.hadoop.io.Text\n此问题略奇怪，都实现了Hadoop的Writable接口，却不能被序列化。某些地方提到Hadoop与Spark没有使用同一套序列化机制，需要在Spark的序列化框架下注册才能使用。\n一般更建议在drive程序上收集信息时，首先转换成基本的数据类型：\nhFile.filter(k =\u0026gt; k._1.toString.contains(\u0026ldquo;a\u0026rdquo;)).collect\njava.lang.IllegalStateException: unread block data   ERROR executor.Executor: Exception in task 0.3 in stage 0.0 (TID 3) java.lang.IllegalStateException: unread block data at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2781)\n一个很坑的错误，spark-shell下只出现这个，并未表明真正的错误在哪。在spark的webUI上能够看到相关的运行日志，上面的异常前还有一个异常写的是我重写的InputSplit没有实现Writable接口。此处的坑，InputFormat中用的InputSplit如果需要重写需要实现Writable接口，在MapReduce下使用貌似没有这一要求。\n补上之后上传到集群的nodemanager即可。注意，当nodemanager和spark-shell上传的jar包中有相同的类时，nodemanager优先使用了自身的类。\n","href":"/posts/technical/problem_spark_reading_hdfs_serializable/","title":"Spark设置自定义的InputFormat读取HDFS文件"},{"content":"Hadoop会通过集群的拓扑（节点在交换机的连接形式）优化文件的存储，降低跨交换机的数据通信，使副本跨交换机以保证数据安全。\n但Hadoop没有默认的集群拓扑识别机制，需要使用额外的java类或脚本两种形式设置。\n官网上给了集群拓扑的基本说明（!(Rack Awareness)[https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/RackAwareness.html]），给出来的那两段脚本看得有点懵，就自己试了一下，写了个更简单的。\n其实只是Hadoop会调用脚本，将多个Datanode的ip作为输入，每次最多输入的ip数设置在net.topology.script.number.args，将输入的ip转换成/rack-num的形式(以/开头的字符串)，用标准输出流（如Python的print）输出结果。\n具体操作 编写脚本 下面的脚本在输入\n192.168.3.1 192.168.3.4 时，会输出\n/rack1 /rack4 #!/bin/python3 import sys # 第一个参数是脚本路径，直接pop掉 sys.argv.pop(0) # 0-3 rack0 # 4-7 rack1 # 8-11 rack2 # ... # 其它的参数里每个参数都是一个ip，此处直接取ip的最后一位除以4作为Racknum # 实践上可以读文件确定ip的对应关系 for ip in sys.argv: hostNum = int(ip.split(\u0026#34;.\u0026#34;)[3]) print(\u0026#34;/rack\u0026#34; + str(int(hostNum/4))) 设置配置参数 \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;net.topology.script.file.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/sparkl/hadoop/etc/hadoop/topology.py\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; 重启集群即可\n验证结果 以下命令能够直接获取某一个文件的分布状态，以及总的rack数量：\nhdfs fsck /readme.md -files -blocks -racks\n貌似没有直接以树状的形式输出集群拓扑的命令，namenode的日志中能看到datanode在连接时的拓扑位置。\n","href":"/posts/technical/hadoop_rack_awareness/","title":"Hadoop 机架（集群拓扑）设置"},{"content":"大多数的叫法都是副本放置策略，实质上是HDFS对所有数据的位置放置策略，并非只是针对数据的副本。因此Hadoop的源码里有block replicator(configuration)、 BlockPlacementPolicy(具体逻辑源码)两种叫法。\n主要用途：上传文件时决定文件在HDFS上存储的位置（具体到datanode上的具体存储介质，如具体到存储在哪块硬盘）；rebalance、datanode退出集群、副本数量更改等导致数据移动的操作中，数据移动的具体位置。\nBlockPlacementPolicy BlockPlacementPolicy 作为虚基类提供了基本的接口，具体的子类重点实现下面 选择副本 、 验证副本放置是否满足要求 、 选择能够删除的副本 三个函数：\n/** * 核心的副本放置策略实现，返回副本放置数量的存储位置 * **如果有效节点数量不够（少于副本数），返回尽可能多的节点，而非失败** * * @param srcPath 上传文件的路径 * @param numOfReplicas 除下面chosen参数里已经选择的datanode，还需要的副本数量 * @param writer 写数据的机器, null if not in the cluster. 一般用于放置第一个副本以降低网络通信 * @param chosen 已经选择的节点 * @param returnChosenNodes 返回结果里是否包含chosen的datanode * @param excludedNodes 不选的节点 * @param blocksize 块大小 * @return 排序好的选择结果 */ public abstract DatanodeStorageInfo[] chooseTarget(String srcPath, int numOfReplicas, Node writer, List\u0026lt;DatanodeStorageInfo\u0026gt; chosen, boolean returnChosenNodes, Set\u0026lt;Node\u0026gt; excludedNodes, long blocksize, BlockStoragePolicy storagePolicy); /** * 判断传入的放置方式是否符合要求 */ abstract public BlockPlacementStatus verifyBlockPlacement( DatanodeInfo[] locs, int numOfReplicas); /** * 当副本数量较多时，选择需要删除的节点 */ abstract public List\u0026lt;DatanodeStorageInfo\u0026gt; chooseReplicasToDelete( Collection\u0026lt;DatanodeStorageInfo\u0026gt; candidates, int expectedNumOfReplicas, List\u0026lt;StorageType\u0026gt; excessTypes, DatanodeDescriptor addedNode, DatanodeDescriptor delNodeHint); Hadoop 提供的 BlockPlacementPolicy 实现 Hadoop提供了BlockPlacementPolicyDefault、BlockPlacementPolicyWithNodeGroup、AvailableSpaceBlockPlacementPolicy三种实现（hadoop 2.7.7）。\n其中BlockPlacementPolicyDefault是默认三副本策略的实现：第一个副本尽可能放在写入数据的节点，第二个副本放在与第一个副本不在同一机架（rack）下的节点，第三个副本与第二副本放在同一个机架。\nBlockPlacementPolicyWithNodeGroup中第一、二个副本和Default副本放置相同，第三个副本在第二个机架下选择不同node group的结点。AvailableSpaceBlockPlacementPolicy实现存储平衡。Hadoop3.1中还加入了BlockPlacementPolicyRackFaultTolerant将数据存储到更多的机架下，BlockPlacementPolicyWithUpgradeDomain使用默认的副本放置策略，但是3个副本选择的datanode都要有不同的upgrade domains（为了方便大集群中datanode的更新和重启、将结点分配给不同的upgrade domain）。\n通过改变dfs.block.replicator.classname 能够选择具体的实现类，默认值为org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault。（Hadoop 2.7.7下，貌似不同版本的Hadoop的命名还不一样，而且2.7.7默认的配置文件里还没有，需要在源码中查）\nBlockPlacementPolicyDefault 源码阅读 public abstract DatanodeStorageInfo[] chooseTarget(String srcPath, int numOfReplicas, Node writer, List\u0026lt;DatanodeStorageInfo\u0026gt; chosen, boolean returnChosenNodes, Set\u0026lt;Node\u0026gt; excludedNodes, long blocksize, BlockStoragePolicy storagePolicy); chooseTarget函数实现了具体的三副本策略。各种特殊情况（如只有1个副本、datanode数量不够、集群拓扑不满足要求等）的考虑让代码看起来比较复杂，常规情况直接跟着调试代码走会跳过很多异常处理部分，便于裂解正常流程。\n在副本的选择上用了各种带chooseTarget函数，注意有几个函数结果是通过参数传出而不是返回值。\n主要实现思路：\n 各种变量初始化 考虑favoredNodes的放置 除满足条件的favoredNodes后的副本放置策略（三副本） 结果排序  首先 srcPath没有被考虑，被直接舍弃：\nreturn chooseTarget(numOfReplicas, writer, chosenNodes, returnChosenNodes, excludedNodes, blocksize, storagePolicy, flags); // ignore srcPath 因此默认的副本放置策略，在同一文件包含多个block时，每个block的存储位置独立考虑，并非存储在同一datanode。\n处理favoredNodes 上传文件时可以指定favoredNodes（默认为空），首先对favoredNodes所在的节点判断是否合适。如果满足条件的节点数还低于副本数，则添加新的副本。\n// --------------Choose favored nodes ---------------  // 从favored nodes中选择，在上传文件时可以指定  List\u0026lt;DatanodeStorageInfo\u0026gt; results = new ArrayList\u0026lt;\u0026gt;(); boolean avoidStaleNodes = stats != null \u0026amp;\u0026amp; stats.isAvoidingStaleDataNodesForWrite(); int maxNodesAndReplicas[] = getMaxNodesPerRack(0, numOfReplicas); numOfReplicas = maxNodesAndReplicas[0]; int maxNodesPerRack = maxNodesAndReplicas[1]; chooseFavouredNodes(src, numOfReplicas, favoredNodes, favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); // ---------------如果满足要求的favored nodes数量不足-----------  if (results.size() \u0026lt; numOfReplicas) { // Not enough favored nodes, choose other nodes, based on block  // placement policy (HDFS-9393).  numOfReplicas -= results.size(); for (DatanodeStorageInfo storage : results) { // add localMachine and related nodes to favoriteAndExcludedNodes  addToExcludedNodes(storage.getDatanodeDescriptor(), favoriteAndExcludedNodes); } DatanodeStorageInfo[] remainingTargets = chooseTarget(src, numOfReplicas, writer, new ArrayList\u0026lt;DatanodeStorageInfo\u0026gt;(numOfReplicas), false, favoriteAndExcludedNodes, blocksize, storagePolicy, flags); for (int i = 0; i \u0026lt; remainingTargets.length; i++) { results.add(remainingTargets[i]); } } 三副本选择 实现逻辑在 chooseTargetInOrder(\u0026hellip;) 函数中\n// 第一个副本的选择 if (numOfResults == 0) { writer = chooseLocalStorage(writer, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes, true) .getDatanodeDescriptor(); if (--numOfReplicas == 0) { return writer; } } // 选择与第一个副本不在同一Rack下的第二个副本 final DatanodeDescriptor dn0 = results.get(0).getDatanodeDescriptor(); if (numOfResults \u0026lt;= 1) { chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); if (--numOfReplicas == 0) { return writer; } } // 第三个副本 if (numOfResults \u0026lt;= 2) { final DatanodeDescriptor dn1 = results.get(1).getDatanodeDescriptor(); // 第一、二副本在同一Rack下时选第三个副本  // （前面的favoredNodes以及集群条件可能造成这种情况）  if (clusterMap.isOnSameRack(dn0, dn1)) { chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); } else if (newBlock){ // 正常情况，第二副本的localRack下选第三副本  chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); } else { // 其它的以外  chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); } if (--numOfReplicas == 0) { return writer; } } // 如果副本数量还没到0，剩下的副本随机选择 chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes); return writer; 再到具体的选择 选择具体的存储位置被上面包装到了 chooseRemoteRack 和 chooseLocalRack 两个函数。\n实际调用时只是 chooseRandom 函数，在限定的rack下选择一个随机的节点。\n源码阅读的几个注意 代码在直接阅读时各种跳，但主线思路比较明确。主要带来阅读困难的位置：\n 很多函数调用不是通过返回值传出结果，而是通过参数。 注意某些if后的return会直接返回结果，后面的代码不会被调用。 递归的形式多次调用同一个函数以选择多个副本。 很多代码为了避免一些特殊情况，可以暂时略过（如catch里的异常处理）。  修改HDFS默认的副本放置机制 可以选择直接复制或继承BlockPlacementPolicyDefault的实现，或者直接继承BlockPlacementPolicy类编写对应的接口具体实现。\n将编译好的jar包放入$HADOOP_PREFIX/share/hadoop/common下（或者其它的Hadoop jar包路径）。\n改变dfs.block.replicator.classname 为上面的实现类，要带包的名称。\nRackAwareness 机架感知 Hadoop 并不能自动检测集群的机架状态，而是要预先设置机架的状态，通过脚本或java类将datanode的ip转换成具体的机架上的位置。\n官方文档介绍了基本思路，虽然实现上介绍得不是太清楚，只要将输入的ip转换成\u0026quot;/rackNum\u0026quot;的形式即可。\nhttps://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/RackAwareness.html\n","href":"/posts/technical/hadoop_block_placement_policy/","title":"Hadoop 副本放置策略的源码阅读和设置"},{"content":"最近打开网易云音乐没有反应，只在htop命令下能看到运行的进程（manjaro+mate+awesome）。\n命令行sudo可以正常运行\n无用尝试  安装官网给的最新1.1.3的deepin与ubuntu16两个版本 网上提到的\u0026ndash;no-sandbox参数运行 kill已经运行的netease-cloud-music相关进程  解决方案 回退到更早的1.0.0版，估计新版没有在各个linux系统下测试。\nhttp://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb\ndebian系就直接dpkg -i吧\narch系通过AUR安装稍麻烦:\n 卸载原版本 yaourt -S netease-cloud-music 按y Edit PKGBUILD 将1.1.3的安装包地址替换为1.1.0的安装包地址，并且将对应hash值改为skip，具体如下  改之前：\nsource=( \u0026quot;http://packages.deepin.com/deepin/pool/main/n/netease-cloud-music/netease-cloud-music_${pkgver}-${_pkgrel}_amd64.deb\u0026quot; \u0026quot;http://music.163.com/html/web2/service.html\u0026quot; ) md5sums=('53c47c1bf6797b2a0e455bc59833ab2d' 'SKIP') 改之后\nsource=( \u0026quot;http://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb\u0026quot; \u0026quot;http://music.163.com/html/web2/service.html\u0026quot; ) md5sums=('SKIP' 'SKIP') 然后正常安装即可\n","href":"/posts/technical/netease_music_can_not_open/","title":"arch linux下网易云音乐运行没反应，只能使用root用户运行"},{"content":"","href":"/tags/git/","title":"git"},{"content":"题目   Median of Two Sorted Arrays There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: nums1 = [1, 3] nums2 = [2] The median is 2.0 Example 2: nums1 = [1, 2] nums2 = [3, 4] The median is (2 + 3)/2 = 2.5\n主要思想 为找到合适的位置划分两个数组:\n在nums1和nums2两个数组中分别截取i,j两个长度，将两个数组划分成4部分，使\n 划分后两个数组的左部分的数量和与右部分数量和相等 i+j == (m+n)/2 (奇数偶数情况都满足此式） \u0026amp;\u0026amp; 左部分的最大值小于右部分的最小值 max(nums1[i-1], nums2[j-1]) \u0026lt; min(nums1[i], nums2[j]) (由于数组有序)  注： i==0时，nums所有元素被分配到右方； i==nums1.length时，nums所有元素被分到左方\n则:\n 当m+n为偶数时，(max(nums1[i-1], nums1[j-1]) + min(nums1[i], nums2[j]))/2对应的位置为中位数的位置 当m+n为奇数时，max(nums1[i-1], nums1[j-1])对应的位置为中位数的位置  具体实现 在nums1中二分查找i，对于每个i可以直接计算 j=(m+n)/2-i，然后判断是否满足条件，不满足条件则继续搜索。\n主要的麻烦在于处理几个极端情况，i、j为0和长度为最大时。\nleetcode题目的解决方案提到需要让i成为较长的数组，上面的处理没用到。\n此时算法复杂度为O(log(m))，将数组调换位置，每次搜索较短的数组，能够将算法复杂度降低到O**(log(min(m,n)))。\nclass Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { if (nums1.length == 0) return (nums2[(nums2.length - 1) / 2] + nums2[nums2.length / 2]) / 2.0; if (nums2.length == 0) // return median of nums1  return (nums1[(nums1.length - 1) / 2] + nums1[nums1.length / 2]) / 2.0; int iMin = 0; int iMax = nums1.length; int i; // represent begin of right array of divided position, range in [0, nums1.length]  // i = 0 means all nums1 will be put in right  // i = nums1.length means all nums1 will be put in left  while (iMin \u0026lt;= iMax) { i = (iMin + iMax) / 2; int j = (nums1.length + nums2.length) / 2 - i; // range in [0, jNum.length]  if (j \u0026lt; 0) { iMax = i - 1; continue; } else if (j \u0026gt; nums2.length) { iMin = i + 1; continue; } int leftEnd1; // end element of left part in nums1  int leftEnd2; int rightBegin1; int rightBegin2; // nums1 may be all put to right(==0) or left(==nums1.length)  if (i == 0) { leftEnd1 = Integer.MIN_VALUE; // leftEnd1 is not existed  rightBegin1 = nums1[i]; } else if (i == nums1.length) { leftEnd1 = nums1[i - 1]; rightBegin1 = Integer.MAX_VALUE; } else { leftEnd1 = nums1[i - 1]; rightBegin1 = nums1[i]; } // nums2 may be all put to right(==0) or left(==nums2.length)  if (j == 0) { leftEnd2 = Integer.MIN_VALUE; rightBegin2 = nums2[j]; } else if (j == nums2.length) { leftEnd2 = nums2[j - 1]; rightBegin2 = Integer.MAX_VALUE; } else { leftEnd2 = nums2[j - 1]; rightBegin2 = nums2[j]; } int maxLeftEnd = Math.max(leftEnd1, leftEnd2); int minRightBegin = Math.min(rightBegin1, rightBegin2); if (maxLeftEnd \u0026lt;= minRightBegin) { if ((nums1.length + nums2.length) % 2 == 0) return (minRightBegin + maxLeftEnd) / 2.0; else return minRightBegin; } else { if (j == 0) iMax = i - 1; else if (i == 0) iMin = i + 1; else if (nums1[i - 1] \u0026gt; nums2[j - 1]) iMax = i - 1; else iMin = i + 1; } } return -999; } } public class _4MedianOfTwoSortedArrays { public static void main(String[] argv) { int[] nums1 = {1, 3, 4}; int[] nums2 = {2, 5, 8, 10}; Solution solution = new Solution(); double result = solution.findMedianSortedArrays(nums1, nums2); System.out.println(result); } } ","href":"/posts/technical/leetcode4/","title":"leetcode: Median of Two Sorted Arrays"},{"content":"20190118更新:\n最近发现有在非gnome系的DE下运行deepin-wine的解决方案，没必要专门跑一个mate。\n安装gnome-setttings-daemon，然后运行/usr/lib/gsd-xsettings。（不同系统会不一样）\n具体记录在另一篇博客\n AwesomeWM这种平铺的窗口管理器用得很爽，只是基于wine的qq最近又莫名其妙抽风，感觉还是切到deepin-wine上比较靠谱。而deepin-wine在awesome下运行qq会报错X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)，而在Gnome系下运行正常。看到Gnome和Mate能够运行awesomewm，就折腾了一下试试。\nAwesome只是Gnome等桌面管理器的组件之一，gnome系的Mate可以修改默认的窗口管理器。\n具体折腾   安装AwesomeWM、Mate桌面环境与dconf-editor（arch下使用pacman -S）。\n  进入Mate桌面环境后，修改org.mate.session.required-components windowmanager 的值为\u0026rsquo;awesome'，如果不需要桌面上的图标，可以将org.mate.session.required-components的值只留下windowmanager。\n  上面的设置无法通过命令行打开awesome，需要添加awesome的图标。在/usr/share/applications目录下新建awesome.desktop，内容如下（网上直接粘的，估计有些可以不要，懒得试了）：\n  [Desktop Entry] Type=Application Name=awesome Exec=awesome NoDisplay=true # name of loadable control center module X-MATE-WMSettingsModule=awesome # name we put on the WM spec check window X-MATE-WMName=awesome # back compat only X-MateWMSettingsLibrary=awesome X-MATE-Bugzilla-Bugzilla=MATE X-MATE-Bugzilla-Product=awesome X-MATE-Bugzilla-Component=general X-MATE-Autostart-Phase=WindowManager X-MATE-Provides=windowmanager X-MATE-Autostart-Notify=true ","href":"/posts/technical/using_awesomewm_as_wm_of_mate_desktop/","title":"使用AwesomeWM作为Mate(Gnome相同) Desktop的窗口管理器"},{"content":"","href":"/tags/life/","title":"life"},{"content":"看了奇葩说后查了一下李诞，又因为一些博客里提到了这个采访才看了《十三邀》。一个在综艺节目中脑回路极大、思维敏捷、搞笑，而又在生活中保持佛系态度,让我想看看采访中表达的思想。\n看了对马东和李诞两个人的采访，五十多分钟的访谈看完了似乎没什么感觉，又印象有很多带动点思考的东西。\n看一些评论有点意思，从一段对话里带着个人色彩解读，展示一些看不到的东西，虽然某些只以一个节目批判许知远人品和采访能力的论述略显浮躁。\n评价一个人没什么意思，特别是以并不能展示全貌的公众视角，只谈看视频后的各种对自己的联想。\n许知远似乎一直想表现出心底的与众不同，或者可能是在故意把自己的观点展示得更为偏激以试探对方的反应。很多地方表现出对当前社会状态的不满，期待对方有相同的感受，而感觉上马东和李诞都表示出某些理解，而现在又不属于同样的感觉。\n马东作为一个老练的主持人表现得很成熟，表现出这个世界的悲凉，但又保持一个积极的态度，像是以一个太极的感觉回应许知远对时代的不满。\n和李诞的访谈中，他们看起来是在以不同的方式做自己的坚持。一个处处展示自己知识分子的身份和追求，表现出愤青的批判；一个以佛系的心态面对生活，放低姿态以“浅薄”自嘲。\n对当前的生活状态，显然谈不上不太满意，无论是能力还是心态上都还距离自己想要的高度甚远。过去的一段时间，想给自己贴上成熟的标签，但又总感觉少了点青春，某些严肃也显得和自己略不协调。在《天才在左，疯子在右》中某个善于模仿他人的“患者”提到，人一生的最理想状态或许是历经沧桑后老年人的那种平和。也经常想象自己在心态上的终极追求，年老时最想要达到的心态，或许，成熟之中，还需要李诞那样的一份佛系和“浅薄”。\n记下的一点东西 李诞 佛系。\n通过笑话说实话。\n“人是社会动物，人就是为了别人活的，你充分的自得，活在自己的精神世界里面，你就死了”。\n“好吧，我就是想活在浅薄里，我就是想活得流于表面。”\n马东 每个时代都追求精致，但又难以找到精致。\n开始《奇葩说》是因为有很多吸引他的未知的东西，技术、平台等。\n人生的底色是凄凉，不像积极主义者，凄凉是指无法改变的东西。\n“被误会是表达者的宿命”。\n","href":"/posts/life/_13_reviewes/","title":"《十三邀》--李诞、马东、许知远"},{"content":"reset 某些特殊的情况下，需要回退到先前的某一次提交。\ngit log 查找想要回退的commit的id后运行：\ngit reset --hard 2c1e288\n回退后git log只会显示回退版本之前的提交。如果需要返回最新的提交，使用git reflog查看对应的id。\ngit reset只适合本地的回退和查看先前代码。如果远程仓库已有最新的提交，git会认为远程仓库的代码较新，需要先同步远程代码再进行修改，此情况下建议使用revert。\ngit reset \u0026ndash;soft \u0026ndash;mixed \u0026ndash;hard 以HEAD～为例（HEAD前的一次提交）\ngit reset --soft HEAD~ 会回到前一次提交的commit执行之前的状态 git reset --mixed HEAD~ 会回到前一次提交的add执行之前的状态 git reset --hard HEAD~ 会回到前一次提交的add执行之前的状态，并且将目录里的所有文件调整为前一次的提交状态\n通常回退时需要将文件也回退需要加 --hard 标签。\ngit的文件组织 git将所有的文件以hash码命名放在仓库中存储。\nHEAD指针，一般可以理解为当前commit状态的一个快照（指向仓库中当前commit的所有的文件）。每次commit或者merge等会创建新的commit节点时，会让HEAD指向新的位置。\nreset会改变HEAD指针的位置与HEAD对应的分支指针的位置，checkout只会改变HEAD指针指向的分支。\nrevert git revert \u0026lt;commit-id\u0026gt; 相当于取消一次commit ，会让结果和没有这一次提交一样，并非像reset那样直接回到某一次commit的代码。\n使用revert不会破坏历史记录，只是提交一个新的修改使修改后代码和以前一致。\n实质上相当于用前的代码merge 后的代码，因此如果后面对代码文件做了修改需要解决冲突。\nrevert一个merge commit 注意revert用在merge的commit上的情况有坑\ngit revert \u0026lt;commit-id\u0026gt; -m 1  需要添加-m参数，指定是merge前的第几个分支（git log上的merge后）。\nrevert的主要麻烦：如果存在分支合并的情况，如下，从m1 revert到a2时会添加一个新的提交m2，当m2与b2 merge时会显示已经merge过。\na1 -\u0026gt; a2 -\u0026gt; m1 -\u0026gt; m2 b1 -\u0026gt; b2 /\n因此在两个分支还需要合并时，不能直接使用merge，而要先revert上一次的revert，让两次revert抵消，也就是  git revert \u0026lt;m2 commit id\u0026gt; 。\n为了少折腾，碰到两个分支以后注定还是要合并的情况，还是不要revert了吧，或者revert之后改完相应的代码就revert回来，貌似没人提到更好的解决方案\u0026hellip;.\n不常用的回退 以下命令存在危险性不建议使用，而且一般也没有使用必要。注意某些操作针对未提交前的处理，可能导致对文件修改的丢失。git对已提交的文件几乎总是可以恢复的，因此建议尽量在提交后处理。\n git checkout \u0026lt;file\u0026gt; 撤销文件修改（到上一次提交）。  git commit --amend 重新提交，提交后删除上一次提交。\n","href":"/posts/technical/git_code_roll_back_revert_and_reset/","title":"git 代码回滚与爬坑 -- reset and revert"},{"content":"SpatialHadoop相对HadoopGIS等库，在MapReduce时代的空间数据处理开源库算处理较好。SpatialHadoop在效率上相对一些新的基于Spark空间数据处理开源库明显偏低，加上本身的功能实现得差不多，最近提交的更新越来越少，感觉发展趋势不太好，主要用于学习相关的索引技术。\n编译与运行 主页上有已经编译好的包，可以直接解压到Hadoop目录下运行，但官方的版本解压有错误，因此下载github上源码编译。\n需要的环境：\n jdk8 Hadoop 2.7.7 maven  源码编译 源码地址 https://github.com/aseldawy/spatialhadoop2，直接下载或者git clone到本地。\n需要安装maven用于代码编译。\n编译前将pom.xml文件中hadoop相关的版本改为需要的版本。\nmvn compile 编译源码 mvn assembly:assembly 代码打包，会在target目录下生成jar和一个包含jar与相关依赖的tar.gz包\n在2f1aefd32860d0279f2fc479a8bafb68d07e3761版本（Mar 13,2018）编译时会由于缺少一个测试文件测试失败，可以选择跳过测试，或者注释掉测试的代码（src/test/java/edu/umn/cs/spatialHadoop/indexing/RStarTreeTest.java中的某个函数）。\n运行 首先需要有一个Hadoop集群，能够提交yarn任务。\n将target目录下生成的tar.gz包（spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz）拷贝到Hadoop目录下并解压即可。\ncp target/spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz $HADOOP_HOME/ cd $HADOOP_HOME tar -zxvf spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz Hadoop目录下运行下面的测试代码，会向HDFS中写入一个随机生成的矩形文件。\nsbin/shadoop generate test.rects size:1.gb shape:rect mbr:0,0,1000000,1000000 -overwrite\nSpatialHadoop运行机制 shadoop 脚本 SpatialHadoop 通过脚本shadoop运行命令，脚本就只有几行代码\nbin=`dirname \u0026#34;$0\u0026#34;` bin=`cd \u0026#34;$bin\u0026#34; \u0026gt; /dev/null; pwd` # Call Hadoop with the operations.Main as the main class . \u0026#34;$bin\u0026#34;/hadoop edu.umn.cs.spatialHadoop.operations.Main $@ 其实只是将spatialhadoop的jar包与相关依赖jar包放入Hadoop的包目录中，然后通过shadoop脚本调用Hadoop脚本调用包中的一个类，向YARN提交MapReduce任务。\nspatialhadoop的相关文件 spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz 中有以下的文件。\n. ├── bin │ └── shadoop ├── etc │ └── hadoop │ ├── spatial-site.xml │ └── spatial-site.xml.template ├── LICENSE.txt ├── README.md └── share └── hadoop └── common └── lib ├── esri-geometry-api-1.2.1.jar ├── javax.mail-1.5.5.jar ├── javax.mail-api-1.5.5.jar ├── jts-1.13.jar └── spatialhadoop-2.4.3-SNAPSHOT.jar 配置文件貌似基本功能上用得不多，shadoop脚本也比较简单，除去使用的相关环境依赖jar包，spatialhadoop实质上只是执行spatialhadoop-2.4.3-SNAPSHOT.jar包中的函数而已。\nSpatialHadoop 基本使用 构建索引文件与空间范围查询\nshadoop index test.rects sindex:grid test.grid shape:rect shadoop rangequery test.grid rect:10,10,2000,3000 rangequery.out shape:rect 主要的索引结构，文件存储形式等在官网有相关文档。\n具体运行的参数和运行的命令很多没有介绍，输入bin/shadoop以及bin/shadoop 接命令能够看到命令的基本使用情况，更具体的估计要去找源码了。\n主要参考链接  http://spatialhadoop.cs.umn.edu/all_operations.html 所有操作和说明 http://spatialhadoop.cs.umn.edu/ 官网 https://github.com/aseldawy/spatialhadoop2 github仓库  ","href":"/posts/technical/spatialhadoop_compile_and_run/","title":"SpatialHadoop的编译与运行"},{"content":"","href":"/tags/blog/","title":"blog"},{"content":"搜了一些博客，发现写得最清楚的还是《Hadoop权威指南》，以下内容主要来自《Hadoop The Definitive Guide》 4th Edition 2015.3。\nHadoop YARN Scheduler 三个调度器 YARN提供了CapacityScheduler, FairScheduler, FifoScheduler三个调度器，继承于AbstractYarnScheduler，Resource Manager通过调度器决定对提交application分配的资源大小。\nCapacityScheduler首先将所有资源分配到hierarchical queue中，每个任务执行时指定对应的queue，使大任务不会占用整个集群的资源，通过对queue的资源管理提高整个集群的资源共享能力。通常会使小任务执行更快，大任务更慢。\nFair Scheduler 会在第一个任务运行时分配当前同级队列的所有资源，当有其它任务运行时，回收前面任务运行时的部分资源（一般为运行完成的Container）用于其它任务。\n至于FIFO，源码里都没有描述，可能就是一般的先进先出了。\nYARN默认使用CapacityScheduler，通过下面的属性配置：\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.scheduler.class\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; YARN 动态资源分配 YARN 能够动态申请资源，如MapReduce中reduce的container会在map过程结束后申请。但Spark On YARN的机制为申请固定的executor，而不动态改变已申请的资源。\nYARN上新运行的任务能够使用已运行任务回收的资源(如运行完Map task的container)，甚至还能够通过强行结束先前任务的container抢占资源。\nCapacity Scheduler CapacityScheduler重点解决多个组织共享集群资源，并保证每个组织自己的资源使用量。当自己的资源不足时能够使用其它组织的空闲资源。\n资源通过层级队列（hierarchical queues）的形式进行组织，配置在etc/hadoop/capacity-scheduler.xml.\n\u0026lt;!-- 队列结构设置 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.queues\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;a,b\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;The queues at the this level (root is the root queue). \u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.a.queues\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;a1,a2\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;The queues at the this level (root is the root queue). \u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 队列能力设置 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.a.capacity\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;40\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.b.capacity\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;60\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.a.a1.capacity\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;50\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.a.a2.capacity\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;50\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 最大能力占用 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.capacity.root.a.maximum-capacity\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;75\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; root ├── a 40% | ├── a1 50% | └── a2 50% └── b 60% 上面的设置形成了如图的hierarchical queues，并指定a队列使用40%的资源，b队列60%，a1 a2各占a队列的50%，a队列在b队列资源空闲时，最高可占用集群75%的资源。\n一些设置和特点  通过设置queue的maximum capacity能够避免使用相邻子队列的所有资源。 改变文件后需要运行 $HADOOP_YARN_HOME/bin/yarn rmadmin -refreshQueues 子队列能使用的最大资源为父队列的资源 队列上除了对资源的管理，还提供了运行的用户、应用数量等的限制功能。 默认只支持内存，通过配置可以支持CPU  Fair Scheduler （公平调度器） 对比CapacityScheduler的主要区别： 任务提交时占用同一层队列所有的资源 (Capacity Scheduler中只使用maximum-capacity限制下的其它队列闲置的资源），另一个任务提交时，会回收先前任务的部分资源。\n\u0026lt;allocations\u0026gt; \u0026lt;defaultQueueSchedulingPolicy\u0026gt;fair\u0026lt;/defaultQueueSchedulingPolicy\u0026gt; \u0026lt;queue name=\u0026#34;a\u0026#34;\u0026gt; \u0026lt;weight\u0026gt;4\u0026lt;/weight\u0026gt; \u0026lt;schedulingPolicy\u0026gt;fifo\u0026lt;/schedulingPolicy\u0026gt; \u0026lt;queue name=\u0026#34;a1\u0026#34; /\u0026gt; \u0026lt;queue name=\u0026#34;a2\u0026#34; /\u0026gt; \u0026lt;/queue\u0026gt; \u0026lt;queue name=\u0026#34;b\u0026#34;\u0026gt; \u0026lt;weight\u0026gt;6\u0026lt;/weight\u0026gt; \u0026lt;/queue\u0026gt; \u0026lt;queuePlacementPolicy\u0026gt; \u0026lt;rule name=\u0026#34;specified\u0026#34; create=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;rule name=\u0026#34;primaryGroup\u0026#34; create=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;rule name=\u0026#34;default\u0026#34; queue=\u0026#34;a.a1\u0026#34; /\u0026gt; \u0026lt;/queuePlacementPolicy\u0026gt; \u0026lt;/allocations\u0026gt; 上面的配置文件给出了一个如下图的层级队列。\nroot ├── a (权重4 因此占用总体40%的资源） | ├── a1 没有指定权重，因此与a2队列平分a队列40%的资源；队列内部的多个应用使用fifo策略。 | └── a2 └── b （权重6 因此占用总体60%的资源） 向a1队列中提交任务1时，首先会占用整个集群；向b队列提交任务2时，会从任务1中回收60%的资源用于任务2；向a1队列中继续提交任务3时，会按fifo的策略使用a队列的40%资源；向a2队列提交任务4时，会从a1队列的任务1、任务3中回收资源，使a1队列资源和a2队列相同。\n在Hadoop Fair Scheduler的具体实现中，并没有对每个application实现绝对公平的资源分配，而是针对同一级队列内部的资源，队列内部可以选择其它的调度策略。并且使用weight参数，使相同层级的队列资源根据weight分配而非直接平均，设置不同weight后并不“fair”。（实质上和CapacityScheduler类似，都是对层级队列的管理，每一层的队列之间资源存在共享，有博客提到FairScheduler在不断的发展中已经能够实现大部分CapacityScheduler的功能，两者的功能越来越接近）\n注意，Fair Scheduler会默认对每个用户创建一个queue用于没指定queue的任务，weight为1，因此要想忽略默认创建的用户queue，需要将权重设置偏大。\n队列内部调度策略 每个队列内使用一定的调度策略，常见的FIFO、FAIR和DRF。\nFIFO(first in first out), 先提交的任务先分配资源。\nFAIR (max-min fairness)， 先把资源平均分配，某些任务如果有多出资源则将多出的资源分配给其它任务，对资源要求低的任务优先。\nDRF（dominant resource fairness），解决有多种资源（CPU、内存等）同时考虑的分配问题，如一个CPU要求高内存要求低与一个CPU要求低内存要求高的应用。\n","href":"/posts/technical/hadoop_yarn_resource_scheduler/","title":"Hadoop YARN 调度器（scheduler） —— 资源调度策略"},{"content":"","href":"/categories/operation/","title":"Operation"},{"content":"用个人域名搭建的博客在百度搜索上的SEO太差，百度一直只收录主页，懒得再为这些问题折腾，直接同步到博客园算了，考虑用Python。\n貌似CSDN已经关闭了metawebblog接口，只在博客园上测试。\nPython发博客的主要方案  通过xmlprc的metaweblog接口（首选） CSDN和博客园的api（定位不是用来发博客的，申请key和调接口略麻烦） 使用抓包的技术模拟浏览器登录发博客（没悬念更折腾）  代码 对于支持metaweblog的博客平台，只要提供用户名、密码和博客相关信息。\npython2 需要将后面的xmlrpc.client改为xmlrpclib，并且import xmlrpclib\n#!/bin/python3 import xmlrpc.client username = \u0026#39;\u0026#39; # TODO your username passwd = \u0026#39;\u0026#39; # TODO your passwd # url = \u0026#39;http://www.cnblogs.com/\u0026#39; + username + \u0026#39;/services/metaweblog.aspx\u0026#39; # 此链接已挂 url = \u0026#39;https://rpc.cnblogs.com/metaweblog/\u0026#39; + username title = \u0026#34;helloWorld\u0026#34; content = \u0026#34;\u0026lt;p\u0026gt; test \u0026lt;p\u0026gt;\u0026#34; tags = \u0026#34;tag1, tag2\u0026#34; blogProxy = xmlrpc.client.ServerProxy(url) # 获取最近博客列表 print(blogProxy.metaWeblog.getRecentPosts(\u0026#39;\u0026#39;, username, passwd, 1)) # 发布博客 blogProxy.metaWeblog.newPost(\u0026#39;\u0026#39;, username, passwd, dict(title=title, description=content, mt_keywords=tags), True) 参考 https://rpc.cnblogs.com/metaweblog/fly2wind#Post API文档\nhttps://magicsword.wordpress.com/2012/01/17/tet34/\nhttps://blog.csdn.net/shajunxing/article/details/79553472\nhttps://github.com/RussellLuo/pymwa\nhttps://github.com/huafengxi/pblog\n","href":"/posts/technical/python3_publish_blog/","title":"使用Python3发布博客到支持mateweblog的平台（博客园等）"},{"content":"给博客加个域名准备长用，Hugo生成后一直放在github page上，为了让百度能搜到费了一堆事。\n问题 如果只是在github page上弄个自己域名的网站，只需要在结果文件中添加一个CNAME文件，写入网站域名，然后在域名运营商提交解析。等待域名解析生效后即可通过域名访问。\n然后为了让搜索引擎能够检索，通过baidu、bing、google的站长工具提交链接。\n此时发生一个大bug，github因为某种原因限制了百度爬虫的进入，也就是百度上很少搜到github内网页的原因。\n重点解决的问题为：github page上的内容无法被百度检索。\n解决方案 相关解决github page被检索的方案较多，重点都是通过CDN缓存网站和将网站托管在其它地方两个方案。\nCDN略麻烦，还需要其它的服务。 在各种折腾之后选择了托管在netlify上，然后在百度站长工具中提交网站。\n还没完 Hugo的sitemap百度无法识别 Hugo默认可以使用多语言，当设置了中文和英文时，默认路径下的sitemap会指向两种语言的sitemap路径而非直接的网页，百度无法识别\u0026hellip;.\n解决方案，只设置一种语言。\n百度长时间只收录主页（收录链接数为1） 百度能看到一堆人碰到类似的问题。\n有解决方案建议放在CSDN一类的普通博客上，并附上链接，百度时间长了会自动收录。（google就没这问题\u0026hellip;）\n还有稳定更新，提高博客的质量。\n然后静静的等待\u0026hellip;.\n附：国内外的免费静态网站托管 国外代码托管系列\n netlify，最好最方便，没有之一，添加域名和github仓库的地址就能解决问题，github上的提交还会自动同步。 github page，网页放上去选择显示的分支即可，网速虽然没有飞起但在教育网下还行，主要问题在于上面提到的，百度搜索不到\u0026hellip; gitlab，同github，但使用了Docker技术提高了构建能力，能够上传源博客在服务端构建。只是折腾了一会，fork的项目构建网页一直失败，懒得再debug\u0026hellip; bitbucket，同github，一个大bug在于不能直接添加域名，域名解析过去无效，需要额外的服务（又是一堆配置）  国内代码托管\n 码云，同github，但添加域名是收费功能。 coding，之前博客提到的最多，貌似最近加入了广告，进入网页前几秒会跳入广告页（略不能忍）。  ","href":"/posts/technical/hugo_blog_host_and_seo/","title":"静态blog的免费托管部署、加域名与搜索优化（SEO）"},{"content":"Hadoop 典型的调试方式是通过log4j输出日志，基于日志的形式查看运行信息。在源码阅读中，经常有不容易猜的变量，通过大量日志输出调试没有远程调试方便。\nJava 远程调试 不想了解的可以直接跳到下面Hadoop\n通过JPDA（Java Platform Debugger Architecture），调试时启动服务，通过socket端口与调试服务端通信。\n下面只用最常用的服务端启动调试服务监听端口，本地IDE（idea）连接服务端。\n具体操作 1、启动被调试程序时添加参数：   jdk9: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:8000\njdk5-8: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000\njdk4: -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000\njdk3 及以前: -Xnoagent -Djava.compiler=NONE -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000\n此处有坑，网上大部分没有提到jdk版本不同导致的区别，很多博客使用jdk4的写法，可能导致问题（idea配置远程调试时有上面的选项）。\n另外一个小坑, 下面第一个命令正常执行，第二个命令会忽略调试选项：\n java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000 test java test -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000  主要参数。suspend=y时，程序启动会先挂起，IDE连接后才会运行；suspend=n时，程序启动会直接运行。address后面为端口号，不与其它端口重合即可。\n2、启动Idea连接调试 使用idea打开调试项目的源码工程\nRun -\u0026gt; Edit Configurations , 点“加号” -\u0026gt; remote，然后填上被调试程序所在主机的ip以及上面的address对应端口号，并选择源码所在的module。\n添加后debug运行，剩下的和本地调试相同。\nHadoop 远程调试 思路和上面的操作一致。下面以调试HDFS中的namenode为例。\n具体操作 1、修改Hadoop启动参数为debug模式 如果需要调试namenode服务，在etc/hadoop/hadoop-env.sh文件后添加：\nexport HDFS_NAMENODE_OPTS=\u0026quot;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000\u0026quot; \nHDFS启动的jvm主要为namenode和datanode，jvm启动的参数设置在etc/hadoop/hadoop-env.sh中。其中namenode启动参数环境变量为 HDFS_NAMENODE_OPTS，datanode为 HDFS_DATANODE_OPTS（针对Hadoop3，hadoop2的设置为HADOOP_NAMENODE_OPTS HADOOP_NAMENODE_OPTS）。YARN等服务对应的环境变量需要另查。\n2、启动服务 sbin/start-dfs.sh 或者 bin/hdfs --daemon start namenode仅启动namenode\n3、启动idea连接服务 下载源码并导入到工程（可以只导入需要调试的部分）\nRun -\u0026gt; Edit Configurations , 点“加号” -\u0026gt; remote，然后填上被调试程序所在主机的ip以及上面的address对应端口号，并选择需要调试的module。\n踩坑   不建议像某些博客中写的直接修改HADOOP_OPTS变量，容易发生端口冲突等问题（在Hadoop 3.1.0上运行出错）\n  注意指定的端口避免冲突，如一台主机上同时运行namenode和datanode服务时端口要分开。\n  注意jdk版本的不同需要设置不同的调试参数。\n  未解之坑 使用一台服务器通过Docker运行4个容器组建Hadoop集群，主机能够直接通过端口访问Docker内容器的服务，当无法通过debug端口连接上容器内的调试程序，只能通过内部端口映射到外部主机后访问。\ngoogle上有类似问题未解决。\n总结 实质上比较简单，主要是踩坑，特别是docker内部一直连不上的坑，以及某些博客比较早已经不适用于Hadoop 3.1.0。\n在hadoope-env.sh文件中设置需要调试服务的jvm启动参数，然后启动idea导入源码后连接即可。\n","href":"/posts/technical/remote_debug_of_hadoop_in_docker/","title":"Hadoop HDFS 远程调试（Docker环境下的Hadoop集群）"},{"content":"错误   error: invalid arch-independent ELF magic. Entering rescue mode\u0026hellip; grub rescue\u0026gt;\n使用Rufu ISO模式烧录的U盘，lagency 模式能够启动，但点安装后出上面错误；UEFI模式直接出上面错误。\n解决方案 不多说，百度背锅，google答案的前几个就是正解。\nU盘烧录问题，使用rufu烧录U盘时，最好使用DD模式而非ISO模式。（去年安装manjaro-xfce4时用ISO模式没出过）\nhttps://forum.manjaro.org/t/grub-error-computer-with-no-os-installed-invalid-arch-independent-elf-magic/21805\n解决方案：使用Rufu烧录U盘，点开始后会有选择DD模式或者ISO模式，此时选DD模式，然后UEFI启动即可。\n论坛上还推荐使用etcher\n","href":"/posts/technical/manjaro_install_problem_grub/","title":"使用u盘安装linux(manjaro)时Grub报错"},{"content":"用了很长一段时间的linux，和很多人对linux相比windows的优点评价相同，linux是非常自由的操作系统。从内核到桌面环境到各个应用都可以自行定制，能够完全按照自己的喜好修改，实在没有的功能甚至能够自己造轮子。\n也因此对于我这样的强迫症患者，在各个组件上都想追求一个最舒适的解决方案。这样一个系统确实用得舒服，但也总有用得不舒服的地方需要持续改善，不断调整各个组件以及造一些脚本级的轮子。\n最近连续几周效率严重偏低，也突然发现自己在这些看似意义不大的地方耗费的时间太多。一个emacs各种折腾最后只是写写简单的c++、Python和org；awesomeWM嵌入Mate其实相比传统的多workspace方式也没特别大的区别；软件尽可能找到开源替代与商业版本隔离。\n或许太多时候以geek自居追求某种“无强迫”环境，而忘记要事优先。\n提醒一下自己刚开始读研的目标，在一堆感兴趣的hello world基础之上有所深入。\n感兴趣的技术太多，总要有所舍弃。\nlinux是用来折腾的，更是用来解决问题的。\n","href":"/posts/technical/from_geeker_to_no_self_inflicted/","title":"开启不折腾模式"},{"content":"","href":"/tags/design-patterns/","title":"design patterns"},{"content":"","href":"/categories/programming/","title":"programming"},{"content":"吐槽 感觉这是至今最值得吐槽的设计模式之一，由于原型模式在本质上与工厂模式极为类似，并且简单，但相关的书和博客很少提到要点。某些书上和博客还直接在类里加个clone方法就告诉我这是原型模式，不说清楚为什么要划分原型类和具体类\u0026hellip;.\n还有某些书上把原型模式划分为通用实现和java、c#一类的特定语言实现，不就是稍微改改clone函数的具体实现么，一点简单的语法而已\u0026hellip;.\n有些地方提到原型模式与工厂模式类似，而极少有位置提到后面的客户端的实现问题\u0026hellip;.\n感觉原型模式没什么意思，实质上就是把工厂模式中new的过程改为clone，具体的类对应于完成初始化的多个对象。\n原型模式（Prototype Pattern） 首先画重点，原型模式是一种 创建对象 的模式。通过复制已经初始化好的对象以避免对对象进行某些复杂和耗时的初始化过程。可能存在多个被复制的对象，创建自不同的类或同一个类的不同初始化过程，用户需要动态决定复制哪一个对象。\n主要实现思想：\n 对象的复制只需要在每个类中实现一个clone函数即可 使用工厂模式相关思想获取具体的clone对象  java实现的clone操作 下面的实现基于java，如c++一类的语言对于每个对象的复制需要自行处理。\njava的所有类都继承于Object，Object类中定义了native实现的clone函数，但需要实现Cloneable接口才能调用。通过clone函数能够直接复制内存中的对象而不用调用构造函数。\n注意，java Object的clone函数为 浅拷贝，只会复制类成员对象地址而不创建新的对象。需要根据实际情况判读是否做相应的深拷贝修改。 吐槽：很多博客和书上的示例实质上就下面这一段，然后加个实例里n个成员变量和函数凑出十几到几十行，实现个Cloneable接口加个clone函数就算完了\u0026hellip;.\nclass Prototype implements Cloneable{ int attr; public Prototype clone(){ Prototype prototype = null; try { prototype = (Prototype)super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return prototype; } } 一个不使用java特性的简单实现 class Prototype{ int attr; public Prototype clone(){ Prototype clone = new Prototype(); clone.attr = this.attr; return clone; } } 同上，注意深拷贝和浅拷贝问题。\n原型模式具体实现 一般都会提到，原型模式有原型类（Prototype，一般为抽象类或者实际类），具体原型类（Concrete Prototype）以及调用客户端（client）。\n其中具体原型类继承原型类，客户端通过具体原型的clone函数实现对象复制。\n具体原型类定义 class ConcretePrototype1 extends Prototype { int attr; public Prototype clone(){ Prototype prototype = (ConcretePrototype1)super.clone(); return prototype; } } class ConcretePrototype2 extends Prototype { int attr; public Prototype clone(){ Prototype prototype = (ConcretePrototype2)super.clone(); return prototype; } } 有的书上提到原型类还能使用只包含clone函数的接口，这样在客户端段调用时还要根据具体类做类型转换，还是不建议折腾了。\n客户端实现 客户端用于初始化具体的类对象，和工厂模式中的工厂类似，根据参数决定具体克隆的对象，一般考虑几个工厂模式的思想。\n简单工厂模式实现：\nclass PrototypeFactory{ public static Prototype[]prototypes; public PrototypeFactory(){ prototypes = new Prototype[3]; prototypes[0] = new ConcretePrototype1(); prototypes[1] = new ConcretePrototype2(); prototypes[2] = new ConcretePrototype2();// 可以考虑在后面对同一个类进行两种不同的初始化  // 此处省略初始化操作....  } public static Prototype getProduct(int id){ return prototypes[id].clone(); } } public class PrototypePattern { public static void main(String []argvs){ Prototype prototype1 = PrototypeFactory.getProduct(0); Prototype prototype2 = PrototypeFactory.getProduct(2); } } 当每个具体类需要多套初始化参数，或者具体类数量较多时，还可以参考抽象工厂模式类似的实现。\n总结 通过克隆已经初始化对象的方式创建新的对象是一种比较好的思想。在掌握几种工厂模式的基础上，其实实现没什么难度，不用在意各种书和博客上的细节。\n原型模式的典型缺点：当类成员较为复杂时，clone函数中的复制会较为复杂。（如有一堆同样需要clone的对象作为成员）\n","href":"/posts/technical/design_patterns_prototype/","title":"设计模式 之 原型模式"},{"content":"singleton pattern\n主要目标：对象只创建一次，每次都获得先前第一次创建的对象而不创建新的对象。（最好在使用时创建对象）\n实现思想：使用静态方法getInstance得到对象，为了保证对象只能通过getInstance创建，使构造函数私有。\n主要麻烦在于：\n 多线程环境下getInstance方法的调用可能产生多个对象 使用synchronized关键字可能降低高并发效率  单例模式有很多种，大多用于解决多线程环境下的效率问题，高并发场景通常使用某些固定方案（java常用内部类机制），一般情况下思想比较简单，从应用的角度感觉不必深究。\n（后面懒得用实际例子命名了，Log4j中获取的logger对象就使用了单例模式）\n/** * 简单实现 * * 存在的问题： * * 当创建过程需要时间时，连续调用getInstance方法会导致创建多个对象，特别是涉及多线程时容易出问题。 */ class Singleton_problem { private static Singleton_problem m_singletonProblem = null; private Singleton_problem(){ // ...  } public static Singleton_problem getInstance(){ if (m_singletonProblem == null) m_singletonProblem = new Singleton_problem(); return m_singletonProblem; } } /** * 解决方案一： eager initialization * * 缺点在于没有lazy loading机制 */ class Singleton_eager{ private static final Singleton_eager m_singleton = new Singleton_eager(); private Singleton_eager(){ // ...  } public static Singleton_eager getInstance(){ return m_singleton; } } /** * 解决方案二： lazy initialization * * 在进行高并发操作时可能造成系统性能降低，由于调用getInstance函数每次只能一个线程使用 * 在后面的测试代码里时间不明显，通过线程池等方式可能会不一样 */ class Singleton_lazy{ private static Singleton_lazy m_singleton = null; // 线程锁，加锁的位置每次只能运行一个线程  public static synchronized Singleton_lazy getInstance(){ if (m_singleton == null) m_singleton = new Singleton_lazy(); return m_singleton; } } /** * 解决方案三： lazy initialization + 双重加锁 * * 降低方案二中的等待用时，当对象创建后就不用通过锁判断，创建后没有效率问题。 */ class Singleton_lazy_double_lock{ private static Singleton_lazy_double_lock m_singleton = null; // 线程锁，加锁的位置每次只能运行一个线程  public static synchronized Singleton_lazy_double_lock getInstance(){ //第一重判断  if (m_singleton == null) { //锁定代码块  synchronized (Singleton_lazy_double_lock.class) { //第二重判断  if (m_singleton == null) { m_singleton = new Singleton_lazy_double_lock(); //创建单例实例  } } } return m_singleton; } } /** Initialization on Demand Holder，通过java内部类机制 * 貌似是java的最优实现方式，依赖具体语言 * 由于内部类对象依赖外部类对象，因此内部类中的静态成员会在外部类对象创建后得到， * 此时相当于在使用时才进行初始化。 */ class Singleton_holder{ private Singleton_holder() { } private static class HolderClass { private final static Singleton_holder instance = new Singleton_holder(); } public static Singleton_holder getInstance() { return HolderClass.instance; } public static void main(String args[]) { Singleton_holder s1, s2; s1 = Singleton_holder.getInstance(); s2 = Singleton_holder.getInstance(); System.out.println(s1==s2); } } /** * 对上面的测试 */ public class Singleton{ // 下面两个函数测试的结果使用两种方式的速度基本一致？？？？  // 线程创建和启动的时间过长，基本忽略了线程锁带来的时间差  public static void time4singleton_lazy(){ System.out.println(\u0026#34;start\u0026#34;); for(int i=0; i\u0026lt;10000; i++){ Thread thread = new Thread() { @Override public void run() { Singleton_lazy.getInstance(); } }; thread.start(); } System.out.println(\u0026#34;end\u0026#34;); } public static void time4singleton_eager(){ int threadNum = 10000; Thread []threads = new Thread[threadNum]; for(int i=0; i\u0026lt;threadNum; i++){ threads[i] = new Thread() { @Override public void run() { Singleton_eager.getInstance(); } }; } System.out.println(\u0026#34;start\u0026#34;); for(int i=0; i\u0026lt;threadNum; i++) threads[i].start(); System.out.println(\u0026#34;end\u0026#34;); } public static void main(String []argvs){ //time4singleton_lazy();  time4singleton_eager(); } } ","href":"/posts/technical/design_patterns_singleton/","title":"设计模式 之 单例模式"},{"content":"linux系统 桌面操作系统：windows，MacOS和各linux发行版。\n2017年数据，windows份额超过90%，MacOS约6%，Linux份额最高的记录在2016年7月创下，是2.33%。\n貌似用linux和MacOS的大多是程序员了。MacOS和linux系统正常使用（看书、上网、看电影等）已经比较成熟，没有太大的体验差异。\nlinux系统的主要缺点：\n 某些常用软件在linux上没有或运行有问题（qq、迅雷、office等，只有deepin通过虚拟windows系统解决得稍好） 完美折腾需要掌握大量相关知识，不折腾难以体现其优点 某些设置复杂（较好的发行版已有极大的改善，某些操作需要使用命令）  linux作为桌面系统主要优点（作为服务器系统广泛使用不谈）：\n 软件管理容易 可定制性超强 免费（看版权意识）  对于开发人员，大部分的软件一键安装还解决依赖问题，想要的操作大部分可以通过修改配置和安装软件实现。在运行某些开发软件会明显感觉更快，绝大部分配置通过文本文件容易修改。\nlinux发行版 一般的linux发行版包括：Linux内核，一些GNU程序库和工具，命令行shell，图形界面的X Window系统和相应的桌面环境，以及一系列其他的软件包（浏览器、阅读器、文本编辑器等）。由各种组织和个人维护。\n主要用过的几个桌面发行版：  也许桌面用户最多的Ubuntu 不折腾的Arch系Manjaro （当前主力） 和Manjaro在distrowatch上争第一的Ubuntu进化版Mint 号称最美linux的Elementary 超稳定适合服务器的版本Centos （只在服务器上用） 最强国产化linux的Deepin和一般国产化的优麒麟  下面叙述中不包含在内的主要道听途说\n主流的发行版 debian系：Debian -\u0026gt; Ubuntu -\u0026gt; Mint | Elementary | Deepin | 优麒麟 fedora : Fedora -\u0026gt; RHEL -\u0026gt; Centos | Oracle linux SUSE : SUSE -\u0026gt; SLES -\u0026gt; openSUSE (没有用过，大多对其评价较为中立，暂不讨论) arch : Arch -\u0026gt; Manjaro gantoo\n其中箭头后的系统基于前面的系统发展，但并不影响前面系统的优势。如Ubuntu基于Debian系统成为较好的桌面系统，但Debian由于其轻量级和可定制仍有广泛使用。\n发行版之间主要区别 不同发行版的主要区别在于桌面环境、软件包管理器、软件包以及软件包版本的不同。\n包管理 不同的包管理器在实现功能上差距不大，只是对软件包稳定性的态度决定了能够使用的软件版本。\nFedora系的yum管理器，对所有能够安装的软件包做严格的测试，软件包的版本一般较旧但极为稳定，因此服务器上使用较多。其中Fedora相比Centos的软件包略新也略不稳定。对于大规模服务器的管理，一般会搭建其自己的软件仓库解决部分需要使用的软件问题。吐槽：工业级软件求稳定就算了，emacs和vim这种编辑器都是老的，想要配置某些插件还需要自己下载源码编译安装\u0026hellip;如果没有相关的测试要求，一般不建议使用centos这种作为个人电脑的操作系统，很多桌面软件不是版本偏低就是没有，需要手动安装。\nDebian系使用apt管理软件包，其思路比centos稍激进，软件包版本较新但一般情况下不容易出大问题。通过apt能够下载绝大部分想要的软件，对于某些不在官方仓库的软件能够通过添加apt源安装。因此被桌面系统广泛使用。\nArch系使用滚动更新的pacman，“一周一小更，一月一大更”。相比上述两个能够安装大多数软件的最新版本。还有AUR第三方用户包的加成，通过yaourt命令能够搜索和安装绝大部分linux上有的软件（典型示例为快速安装tensorflow）。过分激进的更新方式必然影响软件包质量，Arch系的包测试比之前成熟得多，在桌面端很少出现软件更新导致不兼容的bug。Ubuntu的软件源已经够丰富，但习惯AUR安装软件后在Ubuntu上会经常有找不到软件导致的不习惯。\nGentoo和Arch类似，软件源丰富，能够下载各个版本的软件包源码并自行定制编译的各种选项，还能使多个版本的软件包共同使用。缺点在于自定义的编译需要较强的硬件能力、对大型软件的编译速度较慢。\n桌面环境 主要决定了界面的显示方式以及任务栏、终端、设置、文件管理器、文本编辑器等软件。一个系统的外观、操作和配置都取决于桌面环境。\n用户量最大的老牌桌面环境 gnome 和 KDE，分别使用基于C语言的gtk和基于Qt的C++开发，有强大的定制性和大量的主题。\nCinnamon和MATE，相对出现较晚但发展迅速。\n轻量级桌面xfce4、LXDE。消耗内存相对少得多，UI配置靠主题。轻微吐槽xfce4，与wineqq有几个不兼容（强迫症注意），还有个super快捷键的bug。\nDeepin，默认的主题就很不错不用折腾，消耗内存略大，针对qq等wine程序有优化。\n还有很多可以选择的，详见https://wiki.archlinux.org/index.php/Desktop_environment_(简体中文)\n顺便提两个平铺窗口管理器i3wm、awesomewm，配置后可以单独作为桌面环境使用。将窗口分块显示，有很多的配置选项，适合键盘折腾党，可以直接设置各种快捷键。当前主力使用awesomewn，由于i3wm里状态栏的qq经常消失（deepin和manjaro上测试）。\n体验各种桌面环境: arch系支持大多数桌面环境，一般也不存在冲突问题，直接安装Manjaro任意版然后pacman安装其它环境即可，其中还支持deepin桌面（注意最好复制环境配置文件到用户目录得到最优的配置）。\n简单聊聊发行版 不想折腾的话肯定是国产化deepin，UI炫酷还能在应用商店直接安装各种国产软件和其它优秀软件，能够免费使用wine的收费版crossover。偶尔出现不稳定（貌似已经很少了）。Manjaro桌面加deepin效果也不错，只是没有了deepin应用商店，安装软件要靠命令。优麒麟在Ubuntu本身上变化不大，和deepin比难免在某些问题上背锅，但和Ubuntu的软件包类似可以降低某些软件的兼容问题。\n一般折腾的系统Ubuntu和Mint，Mint更稳定、折腾的地方更少并且有多种桌面可选（轻量级到重量级随便挑），个人认为优势更大。想要更轻量级的还可以从debian折腾起。貌似OpenSUSE也可以算在此范畴。\n推荐稍微熟悉linux系统后使用Arch系或Gentoo（Gentoo有硬件配置要求）。安装arch后需要一步步安装各种包才能好好使用，算学习linux的一种方式，archwiki提供了齐全的文档。不想折腾的可以直接Manjaro，一个Arch的完整配置版，官方和社区提供了各种桌面环境。Gentoo受机器性能限制没折腾过\u0026hellip;\nElementary号称最美，但是默认配置看起来也太朴素了点，国内也没有相关源的镜像导致安装软件包有点不舒服。\n总结：默认的折腾路线Mint/ubuntu/deepin等起步，熟悉后换arch系，电脑配置还行的可以考虑gentoo，需要和服务器保持兼容另说。如果中间感觉用得舒服了停止即可，滚动更新的系统软件丰富，但Debian系肯定也够用不复杂。\n个人感觉 对于操作系统的圣战，个人感觉linux和windows各有长处，经过一定的配置相互之间都能有对方的功能，没必要崇尚开源精神就贬低windows，更没必要批判linux桌面的不习惯。\n使用Manjaro作为工作系统半年，平时用来写代码、上网、看论文绰绰有余，正常工作效率不亚于windows。linux系统能够不断的定制和积累以不断的提高效率，个人也很喜欢linux的设计哲学。\n但某些东西一折腾就停不下来也算浪费了大量时间，何况linux有折腾不完的东西，需要时刻提醒自己操作系统不是用来折腾的。\n对于喜欢折腾的人值得一试。\n附 某些不舒服的点：\n 基于wine的TIM在awesome wm和xfce4下略有bug，deepin wm下基本完美 wps配置中文字体后大部分文件正常，偶尔不正常的需要上office online，如果需要外加插入文献的插件，那还是回windows或者直接LaTeX吧  主力软件：\n vivaldi+Vimium 浏览器+vim操作 zotero 文献管理 foxitReader / master pdf editor 阅读和批注pdf wine TIM golden dict 词典 坚果云 同步 emacs+spacemacs 只用来做markdown/org/python好像有点浪费 vim/spf13 日常文件编辑 awesomewm 高效切割屏幕 idea JavaIDE zsh+ohmyzsh 只用了几个简单插件 fsearch+catfish 做文件搜索  ","href":"/posts/technical/linux_desktop_distribution/","title":"linux桌面发行版简介"},{"content":"暑假在家的最后一天晚上，骑自行车穿过曾经的高中和初中，回忆还算努力的六年，或许直到今天都还没跳出那六年的形成的价值观。还有很让自己熟悉的孤独。\n一个人骑自行车回家的感觉很熟悉，外带黑夜的加成。相比在武汉，县城的路上骑车格外的顺畅和舒服。而那种熟悉的孤独，更多的成为一种类似醉的美感。一直想写这种感觉，看了刘同的《你的孤独，虽败犹荣》后更想，而我难写得更美。早期对孤独的忧郁、之后对独处宁静的享受、以及某些只属于自己的各种努力和心酸，夹杂成一种醉，和一种别样的美。\n从七年级第一次生出孤独感，到高中二年级的某天开始接受与孤独为友，曾在所谓的孤独中忧郁了三四年。\n那个时候也经常问自己，是不是真的孤独。\n或许有，吧。曾经是一个愤青吐槽社会缺乏精神信仰而物欲横流，曾把部队那种的豪放和磨砺视作自己最终的归宿。相信自己与众不同，或者只是想表现得与众不同。而当时，身边很少有人能理解，或者只是没有人会和我有一样的选择。直到从某一天开始接受，这种想法没人理解本就很正常，也同时成了当时非常去部队的原因之一（也许那里，有志同道合的人）。\n而在今天看，更多的为孤独而孤独而忧郁而已。理解了这个社会便不再愤青，而所谓的不被理解，只是没有表达而已。中学时代的几个同学或许难有不理解，而大学里，更是庆幸有很多能交心的好友以及曾经想象的那种志同道合。\n想着想着，突然都想用工科思维给孤独下个严格的定义，但还是算了吧\u0026hellip;\n记得曾经还相信绝大多数人的青春都会陷入孤独，而之后才慢慢承认，不是所有的人都会庸人自扰。\n 经常考虑这个话题，所以想写写。\n现在，不孤独，并喜欢独处，感受一个人的宁静与轻松。\n仍就欣赏当年的洒脱：\n 追逐天边最冷的北风\n寻找世界最高的山峰\n我把孤独当做朋友\n天地任我遨游不为谁停留\n\u0026mdash;《追风少年》\n ","href":"/posts/life/simplealone/","title":"浅忆孤独"},{"content":"这两种模式的相似度极高，作用也类似，都是对已有的类进行包装，以添加新的控制（代理模式）和功能（装饰者模式），其实这两点也没有严格区分。\n两种设计模式的重点在于，已有的类（被代理、被装饰）与新类（代理类、装饰类）都实现同一接口，通过接口调用新类会和调用已有的类相同。\n设计模式中常说使用“组合”优先于“继承”。对于想要改变一个写好的类中的某些功能，一般情况下使用继承的灵活性不如组合。继承的某些缺点：单继承（多继承也面临一些问题）、破坏封装（子类可能改变某些细节），父类的改变对子类可能有影响。“组合”的方式将需要被修改或加强的类作为新类的类成员，可以通过添加多个类成员以得到组合多种功能的效果。\n静态代理模式 （static proxy） 静态代理的思想：将被代理类作为代理类的成员，通过代理类调用被代理类的函数，并添加新的控制。包装类与被包装类实现同一接口，使得使用时的代码一致。\n应用：已经有一个日志记录器LoggerSubject，需要对writeLog()函数的前后进行某些操作（如初始化、异常处理等），使用Proxy类间接调用LoggerSubject.writeLog()实现新控制操作的添加。\n实现如下\ninterface Logger { void writeLog(); } // 被代理类 class LoggerSubject implements Logger{ @Override public void writeLog(){ System.out.println(\u0026#34;writeLog by LoggerSubject\u0026#34;); } } // 代理类 class Proxy implements Logger{ Logger logger; // 与装饰者模式的主要区别位置  // 代理模式一般要求和原来的类行为一致，因此构造函数不传入对象  Proxy(){ this.logger = new LoggerSubject(); } @Override public void writeLog(){ System.out.println(\u0026#34;logger write before\u0026#34;); logger.writeLog(); System.out.println(\u0026#34;logger write after\u0026#34;); } } public class StaticProxy { private static void write(Logger logger){ logger.writeLog(); } public static void main(String []argvs){ Logger logger = new Proxy(); // 还可能出现下面的嵌套  //Logger logger = new Logger3(new Proxy(new LoggerSubject()));  write(logger); } } 装饰者模式 主要用于给一个类添加新功能\n主要思想：被装饰类作为类成员被调用，为了使装饰类能和被装饰类一样的使用，两者实现相同的接口。\n通过构造函数传入被包装类，能够自由组合装饰，如下面的最后的使用。\ninterface Logger { public void writeLog(); } class BaseLogger implements Logger { public void writeLog(){ System.out.println(\u0026#34;writeLog\u0026#34;); } } class DecorationLogger implements Logger{ private Logger logger; DecorationLogger(Logger logger){ this.logger = logger; } @Override public void writeLog(){ logger.writeLog(); System.out.println(\u0026#34;Decoration\u0026#34;); } } class DecorationLogger2 implements Logger{ private Logger logger; DecorationLogger2(Logger logger){ this.logger = logger; } @Override public void writeLog(){ logger.writeLog(); System.out.println(\u0026#34;Decoration2\u0026#34;); } } public class Decoration { public static void main(String []argvs){ Logger logger = new DecorationLogger2(new DecorationLogger(new BaseLogger())); logger.writeLog(); Logger logger1 = new DecorationLogger(new DecorationLogger2(new BaseLogger())); logger1.writeLog(); Logger logger2 = new DecorationLogger(new BaseLogger()); logger2.writeLog(); } } 缺点和注意：包装的自由组合的灵活性可能导致测试的困难，注意组合可能带来的bug。\n静态代理与装饰者模式的主要区别  原则上的区别，代理为了控制对某个函数前后的操作，而装饰着模式是为了添加某一操作（其实目标没差太远） 实现上的区别，代理模式的类一般和被代理类的操作一致，因此构造函数一般不传入类对象，使用时的不同如下： Logger logger = new Proxy(); // 代理模式 （为了让Proxy的行为像Logger） Logger logger = new DecorateLogger(new Logger()); // 装饰者模式，还可以有更多层  个人吐槽 很多博客里再提高一点深度的说法：静态代理在编译时已经确定代理的具体对象，装饰模式是在运行动态的构造。（听起来有道理，其实就是要不要在构造函数中传入对象的问题）\n如果需要对一个类的众多派生类做代理，按照标准的说法岂不是对每一个派生类都需要写一个静态代理类？？ 感觉上如果不要求代理类和被代理类在构建对象时一致（或者也给被代理类一个构造函数传入），从构造函数传入被代理类能让代理类更加灵活的处理实现接口的各种类。因此，此处还是建议根据具体情况活用；当然，更建议直接用动态代理。\n","href":"/posts/technical/design_patterns_static_proxy_and_decoration/","title":"设计模式 之 静态代理模式和装饰者模式"},{"content":"TODO 某些思想感觉没写清楚和有重复\n几种工厂模式(Factory Pattern)简介 工厂模式主要分为：\n 简单工厂模式（Simple Factory Pattern） 工厂方法模式（Factory Method Pattern 经常简称为工厂模式） 抽象工厂模式（Abstract Factory Pattern）  主要思想：将类的创建逻辑转移到工厂类中，工厂类直接得到初始化后的产品类，使产品类的初始化逻辑清晰、一致，容易添加新的产品。\n目标：\n 将产品的创建逻辑(如读取本地文件、连接数据库）放入工厂类，简化使用逻辑。 隐藏具体创建的对象，提高代码的通用性 （网上博客很多地方没提这点，只有结合java反射机制才行）  需求示例 简单工厂模式 和 工厂方法模式  实现多个日志记录器logger(文件logger，数据库logger等) 通过配置文件确定使用的具体logger类 添加新的logger类不修改源码（添加新的java包并修改配置文件）  抽象工厂模式 抽象工厂模式应用场景略有不同。\n存在多种不同的主题，每个主题都有不同的Button和Text的实现逻辑，因此每个主题都有Button和Text控件的派生类，导致类的初始化较多。\n容易添加新的主题\n不应用工厂模式的一般实现 （FactoryProblem.java）  logger 基类实现通用的日志记录功能，子类实现各自的特有功能 使用时根据配置文件中的类型，new相应的子类  类的实现：\nabstract class Logger { public void writeLog(){ System.out.println(\u0026#34;writeLog by Logger\u0026#34;); } // 可添加公共实现 } class FileLogger extends Logger { @Override public void writeLog(){ System.out.println(\u0026#34;writeLog by the FileLogger\u0026#34;); } } class DataBaseLogger extends Logger { @Override public void writeLog(){ System.out.println(\u0026#34;writeLog by the DataBaseLogger\u0026#34;); } } 使用时:\nif (loggerType.equals(\u0026#34;database\u0026#34;)){ // 此处一般会添加相应的初始化  logger = new FileLogger(); } else if(loggerType.equals(\u0026#34;file\u0026#34;)){ // 此处一般会添加相应的初始化  logger = new DataBaseLogger(); } else logger = null; 从一般实现到工厂方法模式 一般实现存在下面的两个问题。\n问题一：根据字符串生成对象会产生大量的判断 简单工厂模式将对象的初始化放入工厂类中，以简化调用类的逻辑。（还可以使用后面的反射机制）\n// simple factoryPatten class SimpleFact { public static Logger produceLogger(){ String loggerType;// 从配置文件中读取 也可放在函数的参数中  Logger logger; if (loggerType == \u0026#34;file\u0026#34;){ // 此处一般会添加相应的初始化（连接数据库等）  logger = new FileLogger(); } else if(loggerType == \u0026#34;database\u0026#34;){ // 此处一般会添加相应的初始化 （创建日志文件等）  logger = new DataBaseLogger(); } else logger = null; return logger; } } 使用时直接通过工厂类得到对象\nLogger logger = SimpleFact.produceLogger(); 实质上主要提高了代码的可读性，将logger的具体类型和初始化过程用单独的简单工厂类处理，主要为逻辑清晰上的优点。\n仍存在添加新的对象需要修改简单工厂类的问题。\n问题二：添加新的对象需要修改源码的问题 利用java的反射机制，直接通过字符串直接创建对象（一般loggerName来自配置文件）\n// simple factoryPatten class SimpleFact { public static Logger produceLogger2(String loggerName) { Logger logger = null; Class c = Class.forName(loggerName); logger = (Logger)c.newInstance(); // 省略 try catch ......  return logger; } } 添加新类时，直接添加新类的jar包，将类名添加到配置文件即可。\n无法解决不同类的初始化逻辑不同的问题。\n问题三：不同logger的初始化需要各自不同的设置 前面的反射使客户端无法对各个具体的logger派生类实现不同的初始化。当初始化过程复杂时，放在另一个类（工厂类）中会让逻辑更为清晰。（工厂模式）\n而且通过工厂类的封装后有了相同的初始化逻辑，能够直接上用上面的反射创建工厂\n对每个logger构建一个工厂类，使用工厂类初始化logger后得到最后的对象。\nabstract class Logger { public void writeLog(){ System.out.println(\u0026#34;writeLog by Logger\u0026#34;); } // 可添加公共实现 } abstract class SuperFactory{ public abstract Logger produceLogger(); } class FileLogger extends Logger { @Override public void writeLog(){ System.out.println(\u0026#34;writeLog by the FileLogger\u0026#34;); } } class FileLoggerFactory extends SuperFactory{ @Override public Logger produceLogger(){ // 初始化忽略  return new FileLogger(); } } class DataBaseLogger extends Logger { @Override public void writeLog(){ System.out.println(\u0026#34;writeLog by the DataBaseLogger\u0026#34;); } } class DataBaseLoggerFactory extends SuperFactory{ @Override public Logger produceLogger(){ // 初始化忽略  return new DataBaseLogger(); } } 添加新的产品时添加logger和对应的工厂类，然后通过配置文件创建对应的工厂即可。\nps: 感觉此处如果初始化较为简单，构建工厂类的行为有点多余。\n再到抽象工厂模式 工厂方法模式的思想主要是每个产品类使用一个工厂类初始化。\n类似提供多套主题的情况，每套主题有多个控件，此时可以使用一个工厂初始化同一主题下的多个产品对象。\n// ---- button class ButtonUI{ public void print() { System.out.println(\u0026#34;ButtonUI\u0026#34;);} } class ButtonUI_theme1 extends ButtonUI{ @Override public void print() { System.out.println(\u0026#34;ButtonUI_theme1\u0026#34;);} } class ButtonUI_theme2 extends ButtonUI{ @Override public void print() { System.out.println(\u0026#34;ButtonUI_theme2\u0026#34;);} } // ---- text class TextUI{ public void print() { System.out.println(\u0026#34;TextUI\u0026#34;);} } class TextUI_theme1 extends TextUI{ @Override public void print() { System.out.println(\u0026#34;TextUI_theme1\u0026#34;);} } class TextUI_theme2 extends TextUI{ @Override public void print() { System.out.println(\u0026#34;TextUI_theme2\u0026#34;);} } // ---- factory abstract class AbstractThemeFactory{ public void printCommon(){ System.out.println(\u0026#34;common factory method\u0026#34;); } abstract public ButtonUI createButton(); abstract public TextUI createText(); } class Theme1Factory extends AbstractThemeFactory{ @Override public ButtonUI createButton(){ return new ButtonUI_theme1(); } @Override public TextUI createText() { return new TextUI_theme1(); } } class Theme2Factory extends AbstractThemeFactory{ @Override public ButtonUI createButton() { return new ButtonUI_theme2(); } @Override public TextUI createText() { return new TextUI_theme2(); } } // ------------ Test public class AbstractFactory { public static void main(String args[]){ AbstractThemeFactory factory = new Theme1Factory(); ButtonUI buttonUI = factory.createButton(); TextUI textUI = factory.createText(); } } 个人看法 new具体对象的主要问题不只是使用不同的类，而是不同类有不同的初始化流程需要处理。\n个人认为工厂模式的主要作用为：\n 将new具体的对象的过程放入工厂类解耦（需要和反射机制结合） 处理多个产品的选择逻辑（通过if或者反射机制） 处理产品的初始化逻辑 对产品分类创建（抽象工厂）  工厂模式不应该被过分整体套用，而应对于具体解决的问题选择其中的处理方式。如对于随便几个参数就能初始化的情况，工厂类起到的作用并不大。\n主要的启示：\n 在有多个产品或以后可能有多个产品扩展的情况下（而且数量不会过多、初始化逻辑不复杂），使用简单工厂模式将产品的选择逻辑放在工厂类，出现产品变化时只需要修改工厂类而不需要修改每一处的使用逻辑。 在产品类有较为复杂的初始化和其他逻辑时，使用工厂方法模式构建工厂类包装简化使用。 在产品类较多且有明显的分类时，使用抽象工厂模式对每个分类的产品构建一个工厂类。  吐槽 很多人的工厂方法模式，将new具体的对象变成了new具体的工厂，然后工厂类就变成了一对一的产品初始化类，正常人都能想到的吧\u0026hellip;\n某些书上讲的各种问题感觉就是根据已有的模式写法强套的问题，如很多提到简单工厂模式的缺点在于不适合管理多个产品，添加新产品需要修改源码。前者只在于产品类需要复杂的初始化逻辑，后者和工厂方法模式一样使用反射就能解决了。\n网上其他的看法 使用new对类实例化可能破坏类的可扩展性，由于new跟随的是具体的对象，很可能会被修改，因此给其他人使用的类要尽可能少用new。感觉工厂方法模式虽然对加入新的产品能够降低修改，但反射同样可以解决此问题。\n","href":"/posts/technical/design_patterns_factory/","title":"设计模式 之 工厂模式"},{"content":"本科的时候随手写写，读研之后偶尔改改，也没加过几句。或许，能力略有提高，性格却越发清淡。\n 钢铁更在烈火与骤冷中炼成\n 钢铁只在烈火与骤冷中炼成\n破坏原则和准则的自己被称作废物\n永远相信世界的美好，永远保持对自己的冷漠。\n只有最痛苦的经历才有最美好的回忆\n因为害怕失去，所以不敢放纵\n永不退缩的意志\n“当命运像铁环一样将你紧紧箍住的时候，坚强才是可贵的…”\n誓以更加残酷的训练面对所谓残酷的现实\n汗水只是玩笑，伤痛只是儿戏，真正的战斗永远才刚刚开始。\n不要等到命运让人必须成熟的时候\nlife isn\u0026rsquo;t about how to get through a storm, but how to dance in the rain.\n感不感到痛，由意志决定…\n梦，只要出发，就一定能到达…\n不经历地狱般的磨砺哪来变态般的能力\n有些事就算害怕也要去做\n时刻准备着\n简单到纯粹，纯粹到自然。\n早已过骂自己废物的时候，现在处于越过对自己冷漠的时候\n倒下会带来很多的关心，你能选择倒下，或是更坚强\n对别人一认真，就知道自己输了；对自己不严肃，就知道输得更惨\n人的一生会有很多次告别，而每一次 告别都伴随着阵痛，这种阵痛叫成长\n最痛苦的事情不是如何选择，而是别无选择\n让有限的生命发挥出无限的价值，更在于自己掌握\n回忆往事，不因虚度年华而悔恨，不因碌碌无为而羞耻。\n为了一个不可能达到的目标而努力，更加努力……直到自己足够强大，然后淡淡承认：不可能而已。 （那个目标最终达到，或是自己永远不足够强大）\n必须严肃，切勿愤怒\n有的事现在不做，以后就永远不会做了；有的事过去做了，现在就不觉得牛B了；有些事过去能做，现在说不能做了。\n现实，让人强大或堕落，更在于自己把握。\n一个真正的人，对困难的回答是战斗，对战斗的回答是胜利，对胜利的回答是谦虚\n除非永远倒下，否则决不停止\n最悲哀的也是最幸运的：除了奋斗，别无选择。\n初中笔记本{ 只有失去才会珍惜，然而为时已晚（第一句） 所做的一切都不是给别人看的 人的一天，一个假日，一生的度过应当有自己的标准。（我的标准——为明天留下点什么，绝不能再让有限的光阴流逝） 加入共青团后，不要忘记你是一个团员 没有不能冲出黑暗的，只有不愿走出去的，不惧一切冲出黑暗（既然心中有个太阳，又何惧眼前之黑暗） 过去的成功不是理由，现在的失败没有理由 原则问题不能退让，非原则问题不必过于浪费时间 让去年，让上个月，让昨天，让上个小时，乃至前一分钟充满记忆 让过去的事过去，所要面对的是未来与现在 投出微笑，何必在意那回报的是什么呢？ 纵然每一次奋斗的最后都是无奈的笑容和泪水，真正的战士永不言弃 }\n任何人都阻止不了你，如果你想要平庸 同样，任何人都阻止不了你，如果你想要nb No one can stop you, if you want to be ordinary. Likewise, no one can stop you, if you want to be great.\n要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧啊啊啊啊啊要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要死了要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧要不要停下来算了还是再跑一会吧坚持最后一段 啊总算到了\n当你信心满怀时，别人看见的就是光芒万丈的你； 当你沮丧失落时，别人看见的就是不值得托付的你； 当你昂扬向上时，别人看见的就是值得信赖的你； 当你忧伤孤独时，别人看见的就是可怜兮兮毫无魅力的你； 当你冷漠时，不会在意，别人看不见真实的你。\n???：真的很累吗？累就对了，舒服是留给死人的！苦-才是人生 ，累-才是工作， 变-才是命运 ， 忍-才是历练，容-才是智慧 ， 静-才是修养，舍-才是得到 ，做-才是拥有。 如果，感到此时的自己很辛苦，告诉自己：容易走的都是下坡路，坚持住，因为你正在走上坡路！\nindifferent\n","href":"/posts/life/will/","title":"本科笔记-will"},{"content":"终于初步搞定了这个博客，Hugo虽然自称最快，但要想找个合适的主题外加适应中文真不是一般的折腾，各种css调了半天还没达到想要的效果。只是作为一个折腾的helloworld程序员，即便有aur一键安装，也难忍搞个博客还要来一波nodejs或ruby。\n改成中文各种看起来不舒服，还没搞清楚具体怎么翻译。域名申请还是等后面有点内容的时候再说吧。\n搞个博客能干啥，最近发现自己一直违背了高效工作必备的“要事优先”原则，博客园、简书、豆瓣等不折腾平台还是够用了。不过还是有点折腾博客的理由：不想多个平台换；感觉博客这东西应该用git一类的工具管理；吐槽学术界大部分方向的封闭；一键上传；说不定写写小说好用；看到很多人用；反正就是折腾了。\n作为一个还在学术界又不确定以后会不会在学术界的半个researcher，准备先走走技术流，有个博客记录总是好的。\n聊聊技术，谈谈学术，写写人生。\n","href":"/posts/life/blog_first/","title":"第一篇博客"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/series/","title":"Series"}]
