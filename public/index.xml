<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on A Notebook of Extendswind</title>
    <link>https://extendswind.top/</link>
    <description>Recent content in Home on A Notebook of Extendswind</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 17 Dec 2021 19:30:00 +0800</lastBuildDate><atom:link href="https://extendswind.top/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Hive代码阅读 -- SQL语句执行流程</title>
      <link>https://extendswind.top/posts/technical/hive_hadoop_sql_simple_execute_src_read/</link>
      <pubDate>Fri, 17 Dec 2021 19:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hive_hadoop_sql_simple_execute_src_read/</guid>
      <description>写一下Hive源码中执行SQL的SELECT语句的简单执行流程，手头没有具体的环境进调试模式，只根据源码写写大概的处理流程。
总体上从beeline脚本执行，调用了类Beeline.java，将终端的命令读入后通过rpc发送给driver处理。driver调用SemanticAnalyzer将SQL语句编译为可以执行的tasks，然后给每个task创建一个线程执行，在task中调用Tez等并行框架处理。
脚本执行 以beeline脚本执行为例，跳了两个脚本后执行了etx/beeline.sh中的beeline()执行对应的java类。
bin/beeline 脚本的执行会跳到 bin/hive 脚本，并传递service参数。
# beeline 脚本 bin=`dirname &amp;#34;$0&amp;#34;` bin=`cd &amp;#34;$bin&amp;#34;; pwd` . &amp;#34;$bin&amp;#34;/hive --service beeline &amp;#34;$@&amp;#34; 在 bin/hive 脚本中，首先从$bin/ext/*.sh以及$bin/ext/util/*.sh目录下执行所有脚本，脚本中定了一个和service名相同的函数，并且把service名加入到SERVICE_LIST变量。然后根据SREVICE名称运行对应脚本中的函数。
# bin/hive 省略了大部分代码 SERVICE_LIST=&amp;#34;&amp;#34; for i in &amp;#34;$bin&amp;#34;/ext/*.sh ; do . $i done for i in &amp;#34;$bin&amp;#34;/ext/util/*.sh ; do . $i done TORUN=&amp;#34;&amp;#34; for j in $SERVICE_LIST ; do if [ &amp;#34;$j&amp;#34; = &amp;#34;$SERVICE&amp;#34; ] ; then TORUN=${j}$HELP fi done if [ &amp;#34;$TORUN&amp;#34; = &amp;#34;&amp;#34; ] ; then echo &amp;#34;Service $SERVICEnot found&amp;#34; echo &amp;#34;Available Services: $SERVICE_LIST&amp;#34; exit 7 else set -- &amp;#34;${SERVICE_ARGS[@]}&amp;#34; $TORUN &amp;#34;$@&amp;#34; fi 对应执行bin/ext/beeline.</description>
    </item>
    
    <item>
      <title>Hadoop集群对datanode宕机后的处理机制源码阅读</title>
      <link>https://extendswind.top/posts/technical/hadoop_datanode_failure_processing/</link>
      <pubDate>Mon, 06 Dec 2021 16:00:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_datanode_failure_processing/</guid>
      <description>总体上涉及了心跳检测、副本移除线程、副本恢复线程。当datanode发生宕机或者datanode中的某个storage（如一块硬盘）发生的错误时，namenode会根据datanode发送的心跳进行检测。但namenode并没有在心跳检测的汇报中进行即时反应，而是先记录对应的心跳信息，由另一个定期检测线程移除DatanodeManager和BlockManager中对应的block信息，并记录需要恢复的数据。对于数据的恢复，又新建了一个线程进行定期扫描，分配恢复副本需要的源数据节点和目标数据节点，在datanode的下一轮心跳检测中转换为对应的命令返回给datanode。
宕机的心跳检测 datanode会定时向namenode发送心跳数据包汇报当前的运行状态。namenode在一定时间内没收到数据节点的心跳时会标记为stale状态，然后转移该数据节点中的block到其它的数据节点。
hdfs配置中的几个参数：
 dfs.heartbeat.interval，Hadoop心跳检测间隔，默认为3s。 dfs.namenode.stale.datanode.minimum.interval，datanode标记为stale状态的需要丢失的最小心跳次数，默认为3。 dfs.namenode.stale.datanode.interval，Hadoop datanode超时范围，超过此时间没收到心跳检测会被标记为stale状态，默认为30s，大小必须超过前面两个参数的乘积。  接收心跳消息 Hadoop的datanode心跳检测通过rpc的形式发送，rpc函数通过参数传递数据节点统计信息，返回namenode需要对数据节点的命令。
datanode在通过rpc发送消息时，namenode首先在rpc server处理，交给NameSystem。NameNodeRpcServer中的处理：
@Override // DatanodeProtocol public HeartbeatResponse sendHeartbeat(DatanodeRegistration nodeReg, StorageReport[] report, long dnCacheCapacity, long dnCacheUsed, int xmitsInProgress, int xceiverCount, int failedVolumes, VolumeFailureSummary volumeFailureSummary, boolean requestFullBlockReportLease, @Nonnull SlowPeerReports slowPeers, @Nonnull SlowDiskReports slowDisks) throws IOException { checkNNStartup(); verifyRequest(nodeReg); return namesystem.handleHeartbeat(nodeReg, report, dnCacheCapacity, dnCacheUsed, xceiverCount, xmitsInProgress, failedVolumes, volumeFailureSummary, requestFullBlockReportLease, slowPeers, slowDisks); } namesystem的类型为FSNamesystem，负责name-space state的相关管理（is a container of both transient and persisted name-space state, and does all the book-keeping work on a NameNode），是BlockManager, DatanodeManager, DelegationTokens, LeaseManager等服务的容器。在handleHeartbeat函数中，通过blockManager获取的DatanodeManager进行了处理：</description>
    </item>
    
    <item>
      <title>syncthing文件同步网盘配置</title>
      <link>https://extendswind.top/posts/technical/syncthing_install_for_vps/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/syncthing_install_for_vps/</guid>
      <description>在需要同步的文件不太大时，坚果云一类的网盘的效果不错，安装软件即可，不需要折腾还功能多。不考虑同步功能，只是想要存数据的话，NAS一般就可以满足要求。owncloud、nextcloud一类的私有云网盘提供了更多的功能，如可以浏览器查看分享文件。
相比之下，Syncthing只是一个纯粹的文件同步软件。主要优点是配置简单，没有其它的依赖，配置局域网的文件同步以及vps的文件同步实现起来容易，不像私有网盘程序依赖一套数据库、php、web服务等。但是缺点也很明显，没有什么多余的功能，无法单独上传和下载文件，也不能直接分享单个文件。
简单配置 linux的包管理器大多可以直接安装，然后运行Syncthing就可以启动，默认只提供了浏览器的web端管理UI，在 127.0.0.1:8384 访问。
两个节点都安装启动后，可以直接通过id添加对方。运行Syncting的各个节点之间没有主从的区别，通过共享文件夹的方式全部同步为相同的文件状态。添加后需要在对方的web UI中确认。
如果在没有桌面环境的linux服务器（如VPS）上安装，需要在 ~/.config/syncthing/config.xml 配置中将127.0.0.1改为0.0.0.0，防火墙放开8384端口、22000端口。然后在本地浏览器中用服务器 ip:8384 访问。
直连服务器配置 在局域网内或者连接有公网ip的主机时，会默认使用直连的方式。当两个主机不能直接连接，或者网络状态不好时，会通过relay中继服务器连接。
VPS的web UI中直连的listener选项卡为：
 quic://0.0.0.0:22000
tcp://0.0.0.0:22000
 连接VPS时，在address选项中将上面0.0.0.0替换成VPS服务器的ip，替代默认的dynamic即可。
文件版本保存 一个文件可能会修改多次，文件夹的设置中有File Version选项，可以按时间、修改次数、删除等方式备份多个版本，具体设置界面有说明。
安全相关 每个节点的id不包含隐私信息，连接时以及分享文件夹时都需要在两个节点的web UI中确认，id没必要加密保存。节点之间的数据传输通过TLS加密，不用太考虑中心服务器导致的隐私问题。
web UI 页面直接暴露给外网可能会容易被被端口扫描后攻击，可以设置密码加强安全性。或者通过反向代理隐藏web UI的端口，具体配置在 https://docs.syncthing.net/users/reverseproxy.html。关于反向代理踩的一个小坑：nginx设置中的location /syncthing/后面的斜杠不能漏。
文件分享 Syncthing不支持文件分享，只能间接的处理，下面放个简单的nginx配置解决web服务中分享某个文件文件的下载功能。（至于上传，可以考虑sftp、samba一类的服务，这个比较弱）
 location /file_share/ { alias /home/user/Syncthing/public/; autoindex on; autoindex_exact_size off; # 文件大小显示MB，GB单位，默认为b； autoindex_localtime on; # 服务器本地时区显示文件修改日期 } 基本原理 同步设计上首先将大文件切割成block，小文件直接单独作为block（和HDFS的操作类似）。对每个block计算hash值，通过hash值判断文件的完整性和变化（可以自动识别重命名）。当发生文件变化时，操作系统会通知Syncthing程序，Syncthing程序之间传输元数据信息以及变化的数据。
连接上每个Syncthing程序通过唯一id识别，默认打开了本地发现（local discovery）和全网发现（global discovery）。本地发现能够在添加其它节点时自动找到局域网内的其它服务，全局发现依赖了额外的官方服务器，能根据id直接找到对应的节点（不确定ip是通过id算出来的还是全局发现找到的）。
为了使不在同一个局域网下的节点能够同步，官方提供了relay服务器作为中介，不在局域网内的同步默认可以直接通过官方relay服务器进行，也可以自己在有公网ip的机器上架服务。relay服务默认为开启状态，局域网内的节点可能由于网络状况等问题从直连转为relay连接，在配置的web GUI中的Remote Devices下的address中可以看到是直接的ip还是带relay的ip，此处配置可以修改。
Sycnthing默认有几个地方会连接官方服务器：1. 使用数据收集（第一次打开web UI会询问是否同意）；2. 全局发现；3. relay中继服务器。为了方便无所谓，如果只是想单纯在网络可以互通的环境下使用文件同步，可以考虑在设置中把这几个都关了。</description>
    </item>
    
    <item>
      <title>git push时提示错误 sign_and_send_pubkey: no mutual signature supported</title>
      <link>https://extendswind.top/posts/technical/git_push_sign_and_send_pubkey/</link>
      <pubDate>Fri, 03 Dec 2021 16:00:48 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/git_push_sign_and_send_pubkey/</guid>
      <description>git push命令之后，出现下面的错误提示：
 sign_and_send_pubkey: no mutual signature supported git@gitee.com: Permission denied (publickey). fatal: Could not read from remote repository.
Please make sure you have the correct access rights and the repository exists.
 openssh的新版本（当前8.8p1-1）默认不支持ras的默认秘钥。
一开始以为是gitee码云干了什么升级，之后发现是我的manjaro openssh版本太新的问题，已经不支持我几年前生成的秘钥（但是为什么ssh-keygen还是默认用的rsa）。
推荐做法 ssh-keygen -t ed25519 -C &amp;ldquo;your_email@example.com&amp;rdquo;
生成一个新的秘钥，然后公钥添加到gitee账户。
最简单处理 修改ssh的客户端的配置文件，~/.ssh/config 或全局的配置文件 /etc/ssh/ssh_config，在其中加下面的代码。
 PubkeyAcceptedKeyTypes +ssh-rsa
 </description>
    </item>
    
    <item>
      <title>python脚本避免被多次执行</title>
      <link>https://extendswind.top/posts/technical/python_prevent_python_script_running_more_than_once/</link>
      <pubDate>Wed, 01 Sep 2021 08:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/python_prevent_python_script_running_more_than_once/</guid>
      <description>写了一个脚本，想挂后台运行，又想避免重复运行，需要检测后台是否有已经运行的脚本。实现目标：python脚本只运行一次，第二次运行时直接退出。
在linux上比较合适的做法是创建一个systemd控制的service，有时候就临时用一用，还有考虑跨设备运行的时候也有点麻烦。
找了两个比较简单的方案。
1. 使用tendo import tendo.singleton single = tendo.singleton.SingleInstance() # 测试代码 import time while(True): print(&amp;#34;test&amp;#34;) time.sleep(2) 2. 使用pidfile from pid import PidFile # 会对with中的代码块加锁 with PidFile(): import time while(True): print(&amp;#34;test&amp;#34;) time.sleep(2) 或者
from pid.decorator import pidfile @pidfile def main(): # 被pidfile标签装饰的函数只能运行一次 # running code 基本原理 最常见的基本操作都差不多，在运行到需要只能执行一次的代码时，在某个路径下创建一个pidfile的文件，第二次执行时如果检测到路径下有pidfile就报错跳过执行。代码执行完成后删除pidfile。
为了避免pidfile在某些特殊情况下退出未执行，通过atexit等库处理退出时的情况。
类似的做法还有创建一个linux的socket，退出时删除。以及基于ps等linux脚本命令查看运行的进程名。
参考链接 https://stackoverflow.com/questions/788411/check-to-see-if-python-script-is-running/7758075#7758075
https://pythonhosted.org/tendo/
https://pypi.org/project/pid/</description>
    </item>
    
    <item>
      <title>MQTT服务搭建和简单使用</title>
      <link>https://extendswind.top/posts/technical/mqtt_simple_use/</link>
      <pubDate>Mon, 15 Mar 2021 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/mqtt_simple_use/</guid>
      <description>MQTT为了物联网的消息传递而设计，业余时间弄了个报警器，之前用长轮询的实现感觉略麻烦，测试了一下MQTT的实现。
个人感觉使用比较简单，对网络问题的处理也比较完善，但是某些方面的灵活性略微不足，而且中文资料相对较少。
简单使用 服务端用mosquitto，客户端用python-paho-mqtt。
服务端 安装mosquitto，然后systemctl start mosquitto启动对应的服务。
公网环境下建议将配置文件中的默认端口1883改为其它端口，避免被直接扫描。
一些安全方面的设置也建议加上。
客户端 subscriber
#!/bin/python import paho.mqtt.subscribe as subscribe # 当调用这个函数时，程序会堵塞在这里，直到有一条消息发送到 topics/topic1 主题 msg = subscribe.simple(&amp;#34;topics/topic1&amp;#34;, hostname=&amp;#34;your ip&amp;#34;, port=yourport, retained=False, client_id=&amp;#34;youid&amp;#34;, clean_session=False, qos=1) print(f&amp;#34;{msg.topic}{msg.payload}&amp;#34;) hostname和port需要改为正确的参数。
其中，网络环境好并且不需要离线接收消息时，可以不设置clean_session、client_id、qos三个参数。
publisher
发送一条消息
#!/bin/python import paho.mqtt.publish as publish publish.single(&amp;#34;topics/topic1&amp;#34;, &amp;#34;a message&amp;#34;, hostname=&amp;#34;your ip&amp;#34;, port=yourport, qos=1) 其它 MQTT 几个基本概念 通常由3部分构成：subscriber订阅客户端、publisher发布消息客户端、Server服务器。
主题topic，类似一连串消息的标识符。
Message，具体的消息，对应于每个topic。
publisher向服务器指定主题发送消息。
subscriber连接服务器并且指定主题，当publisher向订阅的主题推送消息后，服务器会推送到对应的subscriber。
retained消息 MQTT使用了一个retained消息机制，用于保存主题的状态。publisher可以向主题发送retained消息，在subscriber获取retained消息时（获取参数中retained=True）服务端会返回最后一条retained消息，每一次都会返回而非普通消息的那种只读取一次。ratained消息更像是一种保存消息的状态，用在主题状态的设置，如开门的感应器，ratained消息用于标记门是否打开。
在python的paho库中，publisher的retained参数默认是False，而subscriber的retained参数默认为True，这个有点小坑。
QoS（Quality of Service）与离线消息 在subscriber和publisher中都可以指定，定义消息的可靠性级别，服务器会取两个客户端中较低的级别作为主题消息对应的处理级别。
QoS0，At most once，至多一次； QoS1，At least once，至少一次； QoS2，Exactly once，确保只有一次。</description>
    </item>
    
    <item>
      <title>STR树 —— R-tree的构建方案之一</title>
      <link>https://extendswind.top/posts/technical/str_tree_rtree_construction/</link>
      <pubDate>Wed, 18 Nov 2020 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/str_tree_rtree_construction/</guid>
      <description>MathJax = { tex: { inlineMath: [[&#34;$&#34;, &#34;$&#34;]], }, displayMath: [ [&#34;$$&#34;, &#34;$$&#34;], [&#34;\[\[&#34;, &#34;\]\]&#34;], ], svg: { fontCache: &#34;global&#34;, }, };    最近需要使用R树做一下空间索引，在GeoSpark中使用了JTS库中实现的STR树，一开始以为是R-tree的一个变种，细看发现只是R树的构建（packing）方式之一。
STR是Sort-Tile-Recursive的缩写，是一种R-tree的packing算法。具体的介绍可以看作者的论文 https://www.cs.odu.edu/%7Emln/ltrs-pdfs/icase-1997-14.pdf ，CSDN上有个主要内容的翻译 https://blog.csdn.net/qq_41775852/article/details/105405918。
R树常见构建过程 通常R树是针对动态有增删的数据，因此构建过程可以将所有的数据逐个插入到R树中。这种情况可能会存在一些缺点：
 (a) high load time (b) sub-optimal spac eutilization (c) poor R-tree structure requiring the retrieval of anunduly large number of nodes in order to satisfy a query.  因此，常用packing的方式自底向上的构建R树，主要流程如下：
 假设一共有r个矩形需要被索引，每个叶子结点中存储的矩形数量为n。首先将所有的矩形分成r/n（此处取上界）个组；（分组方式通过下面的packing算法） 将各个分组写入硬盘的pages，并计算每个分组内所有矩形的MBR以及分组对应的page-id； 对分组的MBR递归的执行上面的步骤，直到根节点。  在第1步中，将需要被索引的矩形分成r/n个组，论文中介绍了常见的Nearest-X(NX)、HilbertSort(HS)以及论文提出的Sort-Tile-Recursive(STR)。</description>
    </item>
    
    <item>
      <title>SpatialHadoop二级空间索引机制源码分析</title>
      <link>https://extendswind.top/posts/technical/spatialhadoop_operation_code_analysis/</link>
      <pubDate>Sat, 07 Nov 2020 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/spatialhadoop_operation_code_analysis/</guid>
      <description>SpatialHadoop已经长期没有更新，MapReduce框架的效率也略低，虽然不太适合直接用，但代码的实现机制可以参考。最近准备重新了解一下HDFS上的空间索引问题，在两年前（没想到距离上次运行SpatialHadoop都两年了..）的基本使用的基础上（一个简单使用的记录），记录一下空间索引机制的处理方式。后面重点关注在Hadoop上的任务提交、并行索引构建、索引的存储与读取这几个方面。
相比GeoSpark的代码，没有Spark现成的算子可以复用并且要处理文件方面的问题，逻辑上的处理稍复杂一点。
空间分析任务的提交 SpatialHadoop提供了一个脚本，用于基本的空间处理，如下面的代码生成测试数据。
sbin/shadoop generate test.rects size:1.gb shape:rect mbr:0,0,1000000,1000000 -overwrite shadoop脚本做的操作不多，直接通过Hadoop的运行命令运行了edu.umn.cs.spatialHadoop.operations.Main类，在类中的Main函数中处理输入参数。
bin=`dirname &amp;#34;$0&amp;#34;` bin=`cd &amp;#34;$bin&amp;#34; &amp;gt; /dev/null; pwd` # Call Hadoop with the operations.Main as the main class . &amp;#34;$bin&amp;#34;/hadoop edu.umn.cs.spatialHadoop.operations.Main $@ 在Main函数中使用了Hadoop的ProgramDriver运行具体的类对象。首先从配置文件 spatial-operations.yaml 中读取支持的类，然后利用反射机制，读取对应类注释的shortName标签，通过shortName决定参数传递的具体的类。
public static void main(String[] args) { int exitCode = -1; ProgramDriver pgd = new ProgramDriver(); try { // 这个位置加载配置文件，配置文件spatial-operations.yaml中包含了支持的完整类名  Yaml yaml = new Yaml(); List&amp;lt;String&amp;gt; ops = yaml.load(SpatialSite.class.getResourceAsStream(&amp;#34;/spatial-operations.yaml&amp;#34;)); // 通过反射的机制，提取类对应的源码中的annotation里的shortName，运行时会通过shortname执行对应的类 	// 用在上面的生成随机数据中就是通过generate执行edu.umn.cs.spatialHadoop.operations.RandomSpatialGenerator。  for (String op : ops) { Class&amp;lt;?</description>
    </item>
    
    <item>
      <title>GeoSpark范围查询源码分析</title>
      <link>https://extendswind.top/posts/technical/geospark_range_query_code_analysis/</link>
      <pubDate>Thu, 05 Nov 2020 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/geospark_range_query_code_analysis/</guid>
      <description>GeoSpark GeoSpark是基于Spark的空间数据处理开源库，在RDD模型的基础上添加了空间数据操作，以底层的SpatialRDD为基础设计了空间分析、空间SQL、空间数据可视化等组件。详细信息可以参考作者博客 https://jiayuasu.github.io/ 以及项目主页 http://sedona.apache.org。GeoSpark一开始是Spark的一个第三方组件，之后改名为sedona提交到apache基金会，当前（2020.11）正处于孵化阶段。
在空间数据的索引与并行访问上，没有像SpatialHadoop那样直接基于HDFS构建针对文件的索引，而是将数据读到RDD中在内存中后进行分区和索引构建操作，索引后的数据可以持久化到硬盘避免下一次的读取，内存的大小一定程度上限制了单次能够处理的数据总量。
最近通过Spark提高SpatialHadoop在设计上的效率，看了一眼GeoSpark在常见的空间处理上的逻辑，针对空间数据读取、索引、划分几个方面的逻辑记个笔记。
主要代码逻辑 GeoSpark的代码大多直接用的java编写，调用了Spark的java API，整体的逻辑比我想象的要简单。代码注释、缩进、命名等貌似都略有非主流的地方。
示例代码主要参考官网教程 http://sedona.apache.org/tutorial/rdd/ 与github仓库源码。
读取csv文件并创建PointRDD  官方示例 Suppose we have a checkin.csv CSV file at Path /Download/checkin.csv as follows:
-88.331492,32.324142,hotel -88.175933,32.360763,gas -88.388954,32.357073,bar -88.221102,32.35078,restaurant
This file has three columns and corresponding offsets(Column IDs) are 0, 1, 2. Use the following code to create a PointRDD
  val pointRDDInputLocation = &amp;#34;/Download/checkin.csv&amp;#34; val pointRDDOffset = 0 // The point long/lat starts from Column 0 val pointRDDSplitter = FileDataSplitter.</description>
    </item>
    
    <item>
      <title>Java数据结构笔记</title>
      <link>https://extendswind.top/posts/technical/java_data_structure/</link>
      <pubDate>Sat, 25 Jul 2020 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/java_data_structure/</guid>
      <description>系统的看一下Java支持的数据结构，记一下从数据结构到java实现的一些基础笔记。以下内容主要参考《java核心技术》与jdk11源码。
用于保存对象的数据结构一般称作容器类，也称作泛型集合（generic collection，由于容易和Collection接口混淆，因此有些书直接叫做容器类container library）。主要分为Collection和Map两种，Collection用于存储独立的元素，而Map用于存储“键值对”对象。
一些细节 在查找元素、查找位置、移除等操作中，判断对象是否相同的方式是调用equal函数。
retainAll(Collection&amp;lt;?&amp;gt; c)求两个集合的交集。
实现时接口与实现分离。使用时用满足需要的接口（如队列使用Queue），针对具体的场景new合适的实现。当需要自行实现对应的功能，为了降低实现接口中过多函数的复杂程度，可以直接扩展对应的Abastract类（如AbstractQueue），这种抽象接口加抽象类的方式在集合设计中经常遇到。
集合类只能容纳对象句柄。集合在存储基本类型时，会通过封装器（Integer等）将基本类型转换成普通类，因此在处理效率上不如数组（直接存储基本类型）。
迭代器 Iterator public interface Iterator&amp;lt;E&amp;gt;{ E next(); boolean hasNext(); void remove(); } // 并没有一个函数直接返回迭代器指向位置的值  public interface Iterable&amp;lt;E&amp;gt;{ Iterator&amp;lt;E&amp;gt; iterator(); } for each循环可以针对任何实现了Iterable的对象（由编译器直接翻译成Iterator对应的代码）。for (String e: c){&amp;hellip;}
Collection接口实现了Iterable接口，可以返回遍历元素的迭代器。
通过迭代器，能够用一套代码访问不同的容器类。
和C++的迭代器指向具体位置的设计不同，java的迭代器指向的位置可以看作是两个元素的中间。当调用next时，迭代器会跳过下一个元素，并返回被跳过元素的引用。不能像C++那样直接取当前位置的元素。对于remove函数，删除的是上一次next函数返回的位置（由于经常需要通过此位置的值判断是否删除）。也因此，每次调用remove函数前必须调用一次next方法，因此连续调用两次remove会出错。
List ArrayList相当于dynamic array，随机访问快，随机插入慢。类似的实现还有Vector，相当于一个线程安全的ArrayList。
LinkedList，双向链表，随机访问慢，随机插入快。LinkedList比较特殊，除了List接口还是了双端队列的Deque接口。
LinkedList无法获取到node的指针，但可以通过获取ListIterator控制前后的位置（相对于Iterator，添加了previous等向前访问的函数）。
LikedList并没有缓存指针的位置，因此get(n)等随机访问和修改的操作效率不高。
public class LinkedList&amp;lt;E&amp;gt; extends AbstractSequentialList&amp;lt;E&amp;gt; implements List&amp;lt;E&amp;gt;, Deque&amp;lt;E&amp;gt;, Cloneable, java.io.Serializable Map 《java核心技术》中将Map的介绍放在了Set之后，但是Hashset的实现直接使用了HashMap，此处先写写Map的实现。
HashMap （下面的默认参数取自openjdk11源码）
实现常量时间的数据get和put。
HashMap用hashcode结合链表的实现。使用了桶（bucket）机制，将hashcode取余后放入一个链表，当一个桶中的数据达到8个时，会通过treeifyBin函数将链表的形式转成红黑树存储以加快检索效率。
在构造函数中设置了两个参数。threshold（默认为16）和loadFactor（默认为0.75），初始化时桶的数量会用threshold，往后threshold会等于 桶的数量×loadFactor。添加元素时，HashMap中的元素个数达到threshold时会调用resize让桶的数量翻倍，此时会遍历先前的所有元素添加到扩容之后的数组中（rehash过程）。
通过一个名为table的数组存储桶的节点，默认情况下的初始化桶的个数为16，每次会增加为之前的2倍，最大为Int型的最大值。
transient Node&amp;lt;K,V&amp;gt;[] table; static class Node&amp;lt;K,V&amp;gt; implements Entry&amp;lt;K,V&amp;gt; { final int hash; final K key; V value; Node&amp;lt;K,V&amp;gt; next; // .</description>
    </item>
    
    <item>
      <title>REFInd默认启动上次的启动项</title>
      <link>https://extendswind.top/posts/technical/refind_set_default_to_last_start_item/</link>
      <pubDate>Wed, 20 May 2020 22:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/refind_set_default_to_last_start_item/</guid>
      <description>windows和linux的双系统偶尔需要切换，设置一个默认启动项没看到直接的资料。
修改配置文件 /boot/efi/EFI/refind/refind.conf（linux下），相关的项都有说明，但是这个和常规差距略大。
默认启动项的设置在default_selection 项，可以设置为如下：
default_selection &amp;quot;+,Microsoft,vmlinuz&amp;quot;
Microsoft表示windows系统，vmlinuz表示linux系统，+号表示选择上一次打开的选项。</description>
    </item>
    
    <item>
      <title>系统启动时卡在 &#39;TLP System startup/shutdown&#39; </title>
      <link>https://extendswind.top/posts/technical/startup_stuck_in_tlp_service/</link>
      <pubDate>Wed, 20 May 2020 22:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/startup_stuck_in_tlp_service/</guid>
      <description>问题 manjaro 在笔记本上启动时卡住（manjaro-awesome + refind引导），停在
TLP System startup/shutdown
TLP 提供优秀的 Linux 高级电源管理功能（详见arch wiki），不知道为什么在启动后卡主。
解决 没有太研究，一般启动卡住的问题和内核参数、驱动等关系比较大，具体的不太好找，可以试试下面的三种方案。
方案一：换内核（可能是硬件的驱动问题导致，对新一点的设备换新内核可能会有效）。
方案二：关闭TLP服务的开机启动， systemctl disable tlp.service 。
方案三：将refind引导改为grub引导（难道启动的时候两者的内核参数不一致？）</description>
    </item>
    
    <item>
      <title>华为笔记本magicbook14 AMD安装Manjaro Linux的一些踩坑配置</title>
      <link>https://extendswind.top/posts/technical/manjaro_magicbook_install_and_configuration/</link>
      <pubDate>Wed, 20 May 2020 16:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/manjaro_magicbook_install_and_configuration/</guid>
      <description>虽然是linux版出厂自带deepin专业版，但是随后发的一键win10装机U盘一声不坑的把deepin格式化了，售后还只在线下才提供安装包&amp;hellip;
笔记本参数 Magicbook 14 (2019)
 AMD R5 3500U 8G + 512G  内核 不同的内核在这个笔记本的表现差距略大。当前（2020年-4月）测试过的内核里，只有linux56运行比较平稳。LTS的414/419直接开机黑屏，好像有一个是由于TLP服务的问题，systemctl disable tlp可以解决，TLP提供了电源管理功能，禁止了不知道影响有多大。LTS的linux54在睡眠时仍能听到风扇转动，无法正常睡眠。
当前的linux56的主要问题（其它内核也存在）：
 指纹识别不能用 麦克风禁音键不能用 风扇无法控制 (好像没有现成的驱动）  Huawei-WMI 相当于华为为自己的笔记本添加的驱动程序，具体介绍可以参考下面的链接。
https://github.com/aymanbagabas/Huawei-WMI
主要的Features：
  Function hotkeys, implemented in v1.0 Micmute LED, implemented in v2.0. Updated in v3.0 to work with newer laptops. Battery protection, implemented in v3.0. Updated in v3.3 to use battery charge API. Fn-lock, implemented v3.0.   NOTE: Version v2.0 is the one in mainline kernel &amp;gt;= 5.</description>
    </item>
    
    <item>
      <title>Manjaro内核编译</title>
      <link>https://extendswind.top/posts/technical/manjaro_kernel_compile/</link>
      <pubDate>Tue, 19 May 2020 22:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/manjaro_kernel_compile/</guid>
      <description>重新编译内核可以修改编译时的参数，使内核在运行时更高效的支持本地硬件。Manjaro团队在gitlab上放了Manjaro内核的编译文件，稍加修改即可使用自己的选项编译。
主要参考论坛中Manjaro团队的philm的回答 https://forum.manjaro.org/t/how-to-compile-the-mainline-kernel-the-manjaro-way/51700/35
Gitlab 仓库 philm提到了manjaro在gitlab上编译内核的仓库。https://gitlab.manjaro.org/packages/core/linux56.git 后面使用不同的linux版本号。
仓库文件介绍 仓库中不同后缀文件的作用
  files ending with .patch should be clear. These are adjustments we think will fit for our distro best. files starting with config are our modified settings on how we configure the kernel on our end. files starting with linux are specific files to post configure the system. They are used either by pacman or mkinitcpio, which configures the initramfs image.</description>
    </item>
    
    <item>
      <title>java从toArray返回Object[]到泛型的类型擦除</title>
      <link>https://extendswind.top/posts/technical/java_toarray_return_and_generic_type_erase/</link>
      <pubDate>Tue, 19 May 2020 11:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/java_toarray_return_and_generic_type_erase/</guid>
      <description>在将ArrayList等Collection转为数组时，函数的返回值并不是泛型类型的数组，而是Object[]。刚好最近翻了一遍《java核心技术》，以及参考《Think in Java》，写写为什么没有直接返回对应类型的数组，以及Java泛型中类型擦除的处理方式。
主要涉及：
 ArrayList的toArray函数使用 为什么不直接定义函数 T[] toArray() 泛型数组的创建的两种常用方法 在泛型中创建具体的类实例  (部分代码没有运行过）
ArrayList的toArray函数使用 将ArrayList转为数组，提供了两个函数
Object[] toArray(); &amp;lt;T&amp;gt; T[] toArray(T[] a); // 后面考虑一个Integer类型的ArrayList ArrayList&amp;lt;Integer&amp;gt; aa = new ArrayList&amp;lt;&amp;gt;(); aa.add(1); aa.add(3); Object[] toArray(); 第一个函数是直接将ArrayList转换成Object的数组，可以用Object[] bb = aa.toArray()，在具体使用时对每个对象进行强制类型转换，如System.out.println((Integer)bb[1])。（java不支持数组之间的强制类型转换）
T[] toArray(T[] a); 第二个函数能够直接得到T类型的数组，当传入的T[] a能放下ArrayList时，会将ArrayList中的内容复制到a中（a的size较大时会a[size]=null）。否则，将构建一个新的数组并返回。具体实现如下:
public &amp;lt;T&amp;gt; T[] toArray(T[] a) { if (a.length &amp;lt; size) // Make a new array of a&amp;#39;s runtime type, but my contents:  return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.</description>
    </item>
    
    <item>
      <title>一次修复linux的efi引导的集中方法总结记录</title>
      <link>https://extendswind.top/posts/technical/grub_uefi_repair/</link>
      <pubDate>Tue, 26 Nov 2019 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/grub_uefi_repair/</guid>
      <description>起因：EFI分区被删除导致引导问题。
症状：
  通过安装其它系统的方式。正好想试试其它的linux发行版，就在另一个分区装了deepin，完成后硬盘没有发现UEFI引导；然后又尝试装了openSUSE，仍没在硬盘发现UEFI引导。（失败）
  通过live cd重新在efi分区安装grub。（wiki推荐的一般方式，仍失败）
  通过live cd安装refind。（仍不行）
  安装的系统可以通过manjaro live cd直接boot。
  安装win10可以发现UEFI的引导方式（只启动win10，安装grub也只启动win10）
  引导的问题网上的解决方案很多，对于一些新的电脑UEFI的方式应该很好修复，但一些比较老的电脑可能出现各种坑问题，用legacy的引导还是稳定一点。
UEFI的引导通过grub的各种安装尝试都无法被主板识别，一直检测不到硬盘UEFI的启动项。怀疑主板并不支持linux grub2写入的UEFI引导信息，只支持windows的。最后通过安装win10，用refind覆盖win10的efi启动条目解决问题。
最常规的修复方式 通过live cd 将系统烧入U盘，启动U盘进入系统后修复。涉及两种方式：
 通过boot-repair grub-install 命令安装  还有通过grub命令行的方式，不常用没折腾。
建议烧入的系统为ubuntu和manjaro。deepin的live cd在我的电脑上有显示的bug，而且添加ppa有一点坑。openSUSE上的grub命令和debian系arch系不怎么一样。ubuntu的主要优点在于可以通过安装boot-repair进行一键修复，manjaro和arch的live cd提供了直接的manjaro-chroot以及arch-chroot，进入后直接安装grub就行，而且manjaro的live cd支持直接引导启动efi分区中的系统。
在下面的两种操作之前，最好通过gparted等软件新建一个efi分区（fat32,一般几十兆，openSUSE建议不小于500M，带efi标签）。
基于ubuntu的boot-repair 网上的资料多操作也不复杂，主要注意U盘从UEFI模式启动。
sudo add-apt-repository ppa:yannubuntu/boot-repair -y sudo apt-get update sudo apt-get install boot-repair -y sudo boot-repair grub-install 命令安装 使用manjaro live cd，其它的系统可能需要安装grub2、efibootmgr、grub-efi-amd64、os-prober等包。
以下需要root权限，sudo -i或命令前加sudo
1、 查看要引导系统的分区和efi分区的编号（fdisk -l） 2、 挂载引导系统的分区（一般 mount /dev/sda4 /mnt） 3、 挂载efi分区到系统分区的/boot/efi目录（`mount /dev/sda2 /mnt/boot/efi） 4、 chroot到硬盘系统分区</description>
    </item>
    
    <item>
      <title>树莓派基于scratch2控制GPIO</title>
      <link>https://extendswind.top/posts/technical/raspberry_scratch2_gpio_control.md/</link>
      <pubDate>Fri, 25 Oct 2019 14:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/raspberry_scratch2_gpio_control.md/</guid>
      <description>感觉这方面的资料最好优先google英文的，中文博客上竟然连scratch2用的哪套GPIO的编号都找半天&amp;hellip;
树莓派的apt仓库里有三个scratch版本，其中scratch为稳定版，scratch2和scratch3还在测试仓库，改成了基于跨平台技术electron的开发。我在树莓派3b上scratch3打开没反应，scratch2虽然是测试版，但使用没发现问题，打开速度上明显比scratch慢。
scratch2相比scratch在GPIO上简化了大量的操作，不用通过广播的形式发送各种GPIO server的消息，将GPIO的操作简化成了两个函数。
1. 安装Scratch2 sudo apt install scratch2
2. 控制相关的GPIO口 更多模块 -&amp;gt; 添加扩展 选择Pi GPIO
下面会多出两个控制GPIO的函数。
set gpio *id* to *output high* 此函数用于设置gpio口，第一个指定GPIO的id，第二个指定功能，如输出高电平、输入低电平、输入模式。
gpio *id* is high? 此函数用于控制语句中作为条件，判断当前gpio口是否为高电平，通常用在输入模式下检测传感器一类的输入。
就这么简单，剩下的当成简单单片机用就行了。
GPIO 针脚图 树莓派有多种GPIO的编号方式，使用python等调用需要指定具体的编码，scratch用的是下图这种（图源自树莓派官网）。</description>
    </item>
    
    <item>
      <title>树莓派从烧录系统到通过wifi远程访问（新树莓派配置，无显示器、网线、键盘）</title>
      <link>https://extendswind.top/posts/technical/raspberry_from_install_to_remote_access/</link>
      <pubDate>Fri, 25 Oct 2019 10:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/raspberry_from_install_to_remote_access/</guid>
      <description>网上教程很多，但是google和百度排在前面的博客操作起来各种问题，因此简单写写。
1. 烧录系统 官网有可以系统可以下载，通常建议，有特殊需求可以考虑其它的几个系统。
官网推荐使用balenaEtcher烧录系统。（很多博客推荐先一个工具格式化sd卡，然后win32imagewriter不知道是不是以前的做法）
2. 配置系统 上面的烧录后，sd卡会被分为多个分区，其中windows系统下能识别的只有一个名为boot的分区，存储启动相关的配置文件。
2.1 开启ssh raspbian 系统默认不开启ssh远程访问，在boot分区下新建文件名为SSH的文件（内容为空无后缀），系统启动时检测到此文件会开启ssh进程。
2.2 配置wifi 在boot分区下新建文件名为wpa_supplicant.conf的文件，添加以下内容：
country=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=&amp;quot;yourWifiName&amp;quot; psk=&amp;quot;passwd&amp;quot; key_mgmt=WPA-PSK priority=1 } 修改其中的wifi名和密码（ssid与psk）
如果想省事可以直接用网线连上路由器
3. 远程访问 3.1 查找树莓派ip 此处需要将电脑和树莓派连接在同一路由器下。
方法一：浏览器上输入192.168.1.1 （根据不同路由器网关不同），进入管理页面查看树莓派ip。
方法二：使用软件Advanced IP Scanner扫描局域网中的树莓派。
3.2 ssh 远程登录 ssh是linux上最常用的命令行远程访问工具。
使用软件putty用于远程ssh登录，输入树莓ip，密码为raspberry。
3.3 开启vnc vnc类似windows上的rdp远程登录，是linux上最常用的带界面远程访问协议。
ssh远程登录后，sudo raspi-config 然后在Interfacing Options -&amp;gt; VNC里enable VNC服务。（貌似是启动vnc的服务后设置了开机启动）
然后使用realVNC viewer输入ip访问即可。
vnc默认使用5900端口，当端口占用时会往后推使用5901等端口。多个vncserver运行时需要使用ip:590x的形式指定端口号。
此处小坑 树莓派自带的vnc server使用的加密方式和tigerVNC viewer不兼容，会显示以下错误：
Unknown authentication scheme from VNC server: 13, 5, 6, 130, 192</description>
    </item>
    
    <item>
      <title>vsftp 匿名访问设置设置</title>
      <link>https://extendswind.top/posts/technical/vsftpd_configuration/</link>
      <pubDate>Fri, 18 Oct 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/vsftpd_configuration/</guid>
      <description>vsftpd (very secure ftpd)，这软件在权限管理什么的也太安全了点，一点小细节出问题也会出现访问不了的问题。只是想架个ftp局域网传文件，一些博客里小细节和背后设计没有提到，踩了一点坑，记录一下简单的匿名ftp访问方案。
主要步骤 1. 使用包管理器安装 vsftpd 。（apt, yum, pacman等)
2. 修改配置文件 /etc/vsftpd.conf
anonymous_enable=YES # 允许匿名访问 write_enable=YES # 允许写文件 anon_upload_enable=YES # 允许匿名用户上传文件 anon_mkdir_write_enable=YES # 允许匿名用户创建目录和写权限 anon_other_write_enable=YES # 允许匿名用户删除、重命名等其它权限 这个在配置文件里默认找不到 3. 新建匿名访问的用户和文件夹
通过 local_enable 选项能够允许ftp通过本地用户访问，登录之后会访问用户的主目录。当使用匿名用户访问时，vsftpd会将用户名为ftp的用户作为登录用户，进入ftp用户的主目录。
注意，考虑到安全问题，ftp匿名用户的主目录必须为只读，如果需要上传文件，需要在主目录下新建有写权限的文件夹。
通常会选择/var/ftp文件夹存放文件而不是用户默认的/home，因此可以修改用户的主目录位置（一般放在/var/ftp），不修改也能用。再次强调，注意主目录对ftp用户的权限必须为只读。
sudo mkdir /var/ftp # 新建用户文件夹 sudo useradd -d /var/ftp ftp # 新建用户，并指定用户home目录  # 如果ftp用户已经存在，在/etc/passwd文件里改用户目录为/var/ftp sudo mkdir /var/ftp/pub # 新建一个用于写数据的文件夹 sudo chmod 777 /var/ftp/pub # 修改文件夹权限 4. 启动服务
systemctl start vsftpd
其它 防火墙和SELinux如果使用了需要添加响应的通过规则。</description>
    </item>
    
    <item>
      <title>log4j 1.2 配置和使用简述</title>
      <link>https://extendswind.top/posts/technical/log4j_properties_simple_introduction/</link>
      <pubDate>Wed, 29 May 2019 20:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/log4j_properties_simple_introduction/</guid>
      <description>简述 使用log4j可以根据配置文件控制输出日志的级别，记录到文件、命令行等的位置，不需要代码上的更改。
日志在一定程度上会影响性能，特别是高并发环境。一般更建议使用log4j 2.x，在性能上有较大的提高，由于hadoop 2.7使用的log4j 1.2，下面主要写这一版本。
本文主要介绍log4j：
 根据日志级别记录日志 (logger上设置） 运行时决定具体的记录位置（appender上设置）和日志格式（layout上设置）  一些概念 日志级别（priority，代码里为level） 日志级别从低到高为trace, debug, info, warn, error, fatal。默认级别为info，低于设置级别的日志不会被打印。
常用组件 一般情况下常设置的组件有logger，appender， layout。
用类的方式表达三个组件的关系为
Logger{ name; level; // 控制日志级别 appenderList; // 可对应多个appender } Appender{ name; // 控制文件位置 如fileAppender layout; // 控制格式 filter; // 过滤部分日志 } logger logger以一种树状关系管理日志的类型，log4j.rootCategory为根节点，如果没有标记 log4j.additivity.MyLogger = false ，则子logger会默认继承上一级的设置。
通过树的组织形式，对不同的包中的不同的类，可以分别设置不同的日志方式。
通过点表示层级，如com.foo为com.foo.Bar的上级
关于category，早期的log4j使用category较多，但在log4j 1.2之后，建议使用logger代替category。
appender 主要用于
 控制日志的输出位置，当前支持the console, files, GUI components, remote socket servers, NT Event Loggers, and remote UNIX Syslog daemons.</description>
    </item>
    
    <item>
      <title>阅读《人类简史》-- 1.认知革命</title>
      <link>https://extendswind.top/posts/life/reading_brief_history_of_humankind_1/</link>
      <pubDate>Tue, 02 Apr 2019 11:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/reading_brief_history_of_humankind_1/</guid>
      <description>人类相比一般动物在身体上的特殊性 大脑和直立行走。
脑容量的增大使人类拥有更强的思维能力；直立行走使人类的手能做更多一般动物做不了的事，如制作和使用工具，尤其是使用火。但脑容量的增加导致耗能增加，只占体重的2%却消耗20%的能量，其它猿类只占约8%，直接导致了肌肉萎缩。
直立行走使臀部变窄，使女性为了正常生育只能让婴儿提前出生，导致人类婴儿早期发育时间相比其它动物较长。同时，由于一个人很难照顾下一代间接促进了人类的合作。
人类使用的石器工具更多的是用来敲碎骨头吃其它动物剩下的骨髓，此时还只是在食物链中层。用火使人类相比其它动物能够动用超越自身身体的力量，初步战胜其它的动物。并且用火烹饪过的食物病菌和寄生虫更少且易于消化。
语言能力的发展与认知革命 在非洲的智人走向世界前，人类还有欧洲的尼安德特人和亚洲的直立人等，同样掌握了用火和使用工具等技术以及群体协作。大约7万年前，智人从非洲向其它区域扩张，智人所到之处的其它人类开始在地球上消失，最终智人统治整个地球。对于智人为什么能够战胜其它的人类，书中给了一个很有意思的观点，最重要的靠的是智人在语言交流上的虚构能力（认知革命）。
通过很多动物都存在的简单语言，使人类能够进行小规模的合作（如传达危险信息等）。而相比动物表达的“小心，有危险”，人类能够更精确的表达出“在附近xx方向距离xx的位置有xx只狮子，我们应该&amp;hellip;”。
书中认为人类的语言交流更重要的是了解人类之间的信息以创建一个巨大的团队，如一个部落的其它人员做什么、谁更靠谱。作者提到现代智人能够聊天长达数小时之久，通过日常聊天交流，使人类能够更容易了解群体的信息。但根据其它动物以及现代人类的观察，仅仅凭借一般的语言交流难以维持一个更大规模的群体（难以超过150人），黑猩猩族群极少情况下能超过100只，数量增加容易造成族群分裂，现代的公司人数超过150人必须使用更强的管理模式。
作者认为智人能够维护更大部落的能力，来自于能够构建并且相信虚构的事物（认知革命），如宗教、神话、国家甚至是现在的国家体系。可能一句神的指示就能调动成千上万的智人团结起来做一件事，而智人以外从地球上消失的其它原始人类很可能不具备这一能力。智人通过认知革命解决了一般哺乳类动物很难组成较大群体的问题，虚构能力使人类能以类似国家的形式维持大规模的群体。
绕过基因组的快速进化 人类使用工具和大规模协作已经在食物链中的地位不断上升，通过语言交流和文字等形式又进一步加速了进化，开启了一条采用“文化演化”的快速道路。过去想要改变社会结构、发明新科技或是移居到新的地点，多半是因为基因突变、环境压力，需要一个相当漫长的过程。而人类能力的发展不再仅仅依赖基因上的改变，知识能够在一代又一代的发展中大量积累而不是重新开始。
智人走向全世界的过程中导致了大量物种的灭绝，主要证据来源于很多大型动物的灭绝时间和智人抵达的时间吻合。传统的进化方式使物种之间有一个漫长的适应期，狮子捕猎能力加强的同时其它猎物也在不断的提高躲避能力。就像现代人开着坦克飞机穿越到古代，人类的“文化演化”道路直接打破了生态的平衡。
个人理解 这本书的后几个章节也经常提到虚构。比如人权、自由、道德约束等，在最初的自然界并不存在，对于地球上的生存法则也不一定理所当然，但却成了如今人类社会大多数人所接受的东西。不断的进行各种虚构，并通过战争等一系列的生存竞争不断的检验和提高虚构的程度，有点定向基因突变的感觉。
很多虚构不一定科学但有意想不到的结果。原始社会里神的存在，或许最初只是因为某些难以解释的自然现象，却很有可能是智人统治全球的原因之一。只因为大多数人相信规则。
很多虚构也不一定都在往更好的方向发展。战争与竞争促进了社会生产力的不断提高，但并没有带来幸福度的大幅提升，当前社会带来的各种压力和欲望很多也出自于虚构，少有人能选择打破或逃避。也只因为大多数人相信规则。
一个虚构的规则，一旦被大多数人相信而且短期无法被撬动，就会像一个真实具体的事物。或许相信规则也算是人类进化出的能力之一。社会一直都是少部分人改变规则而大多数人遵守。
通过不断的创造故事与相信故事，人类已经编织出一个复杂的故事网络，制定出一系列超越自然界本身的规则。现代社会仍旧在制定各种规则。也在挑战各种规则。</description>
    </item>
    
    <item>
      <title>anki的使用以及anki server的配置</title>
      <link>https://extendswind.top/posts/technical/anki_and_anki_server/</link>
      <pubDate>Mon, 04 Mar 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/anki_and_anki_server/</guid>
      <description>首先吐槽，anki作为老牌软件，国内资料并不多。
虽然html的卡片显示和python的插件式开发上看比较适合程序员，但从各种配置上感觉程序员用户量并不大。
因此，想深度使用准备折腾。
简单使用  淘制作好的卡片，导入 卡片可以套模板更美观（添加时的Cards选项，支持html） 添加单词和读音用FastWQ（只支持新版本，查词速度快） （已不支持新版本）插件里的awesome TTS很多人推荐但速度略慢 （已不支持新版本）添加单词可以用Word Query  官方文档https://apps.ankiweb.net/docs/manual.html
插件编写文档https://apps.ankiweb.net/docs/addons.html
插件安装 官网上找插件对应的id编号，然后打开anki的插件设置，添加插件中填入插件id号即可下载。
FastWQ插件 首先在tools菜单下的FastWQ插件设置中，选择note type，然后第一列中选择单词所在位置，第三列选择想要用的在线字典，第四列的Fields中选择行对应的需要填入的内容。
然后在add单词的目录中，先填入单次，然后点query&amp;ndash;&amp;gt; all fields，会将查到的结果填入所有的框。
一些坑 删除卡片不会删除对应的媒体文件，需要点击 check media 后手动删除。
anki有些历史遗留问题，大量的插件和资料都是在之前的anki 2.0.x上的，现在的2.1.x版本将pyqt4升级到pyqt5，很多插件没有跟着升级而无法使用。
anki server 的安装 官网的速度爆表，而且有数据安全问题，因此官网给出了自建anki server的解决方案。
百度上的大多使用 https://github.com/dsnopek/anki-sync-server ，可以基于pip2和python2直接安装，个人在基于Arch的linux下感觉坑多，在linux上的anki 2.1.9连不上上面python2的服务器（bug解决一个又出一个），更建议使用基于python3的fork项目：https://github.com/tsudoko/anki-sync-server 。
基于python3的仓库 github上的readme已经写得比较清楚，下面的搬运点大概。
1、clone 仓库
 git clone https://github.com/tsudoko/anki-sync-server.git
2、安装anki或anki-bundled相关的库
直接使用包管理器安装 sudo pacman -S anki
如果包管理器里没有anki（如debian），也可以用pip安装anki-bundled相关的库
$ git submodule update --init # anki-bundled已经加入为submodule，可以先更新 $ cd anki-bundled $ pip install -r requirements.txt # 安装相关的库 3、安装webob</description>
    </item>
    
    <item>
      <title>linux 关闭主板上的蜂鸣器声音</title>
      <link>https://extendswind.top/posts/technical/mainboard_speaker_close/</link>
      <pubDate>Fri, 25 Jan 2019 10:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/mainboard_speaker_close/</guid>
      <description>在从deepin的kdd桌面换到xfce桌面后，命令行和界面操作上动不动会让主机响一声。
manjaro的xfce版也是如此，不知道是不是linux下xfce的通病。
主要是搜索的时候百度的结果很奇葩&amp;hellip;
用关键字 beep of xfce4 搜到了arch wiki下的内容，原来这玩意叫pc speaker，针对不同的情况有不同的解决方案。
最简单粗暴的方式 内核中加载了pcspkr模块导致的主板声音，rmmod移除此模块，然后/etc/modprobe.d文件夹下加入黑名单，使开机过程不加载。
  rmmod pcspkr echo &amp;ldquo;blacklist pcspkr&amp;rdquo; &amp;gt; /etc/modprobe.d/nobeep.conf 具体参考 https://wiki.archlinux.org/index.php/PC_speaker</description>
    </item>
    
    <item>
      <title>manjaro AwesomeWM 上使用双显示器</title>
      <link>https://extendswind.top/posts/technical/dual_monitor_manjaro_awesome/</link>
      <pubDate>Thu, 24 Jan 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/dual_monitor_manjaro_awesome/</guid>
      <description>安装manjaro时使用独显的单显示器，在主板上接第二个显示器一直没反应。
几个问题和解决 BIOS里检查是否关闭了集显开关 大多数显卡的默认设置都会在识别独显后关闭集显，要使用集显上的接口需要单独设置。
如果接口允许，最好将两个显示器都接在独显上。
基于KDE等桌面 如果主板和显卡驱动正常，一般各大桌面环境都支持GUI配置，可以在显示设置里直接修改。
使用 xrandr 识别和控制显示器 xrandr 直接执行会得到显示器的连接状态，获取显示器的名称后可以用下面的命令显示。
（其中DVI-I-1-1与VGA1为两个显示器的名称）
xrandr --output DVI-I-1-1 --mode 1440x900 --primary --output VGA1 --mode 1366x768 --pos 1440x132 设置输出的显示器以及显示参数，每个--output后接显示器名以及参数，--mode指定分辨率，--primary指定主显示器，--pos指定位置，或者用--right-of指定相对位置。
更进一步的设置可以在arch wiki
xrandr 找不到显示器 xrandr &amp;ndash;listproviders 得到当前的显示器输入设备（一般name为Intel的是集显，name为nouveau的是开源独显驱动，Nvidia为闭源显卡驱动）
xrandr &amp;ndash;setprovideroutputsource 0 1 将上面的设备设置为输入源
如果xrandr &amp;ndash;listproviders 没有得到所有的输入源，则需要折腾驱动。
驱动问题 一般建议将两个显示器都接在独显上，出问题的概率更低（独显一般口不够或者需要转换略尴尬）。
我将显示器分别接在独显和主板接口上，在manjaro和deepin两个系统下都发现NVIDIA驱动有问题，primary显示器会显示两个显示器的内容。而将显卡驱动切换到开源驱动（nouveau）时正常(据说开源驱动性能略低）。
mhwd -li --pci 查看已经安装的驱动 mhwd -l --pci 查看能用的驱动 sudo mhwd -r pci video-nvidia 移除驱动video-nvidia sudo mhwd -a pci videa-linux 安装开源显卡驱动（nouveau） manjaro上通过mhwd简化了各种配置，详见：
https://wiki.manjaro.org/index.php/Configure_Graphics_Cards
AwesomeWM 默认快捷键：
ctrl+super+j/k 屏幕之间焦点移动 super+o 当前窗口移动到另一个屏幕</description>
    </item>
    
    <item>
      <title>manjaro (arch) 安装搜狗输入法</title>
      <link>https://extendswind.top/posts/technical/sogou_input_install_in_arch_manjaro/</link>
      <pubDate>Mon, 21 Jan 2019 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/sogou_input_install_in_arch_manjaro/</guid>
      <description>本来还很简单的事，被默认的选项弄出一堆坑
步骤 先安装fcitx用来管理输入法，然后安装搜狗输入法并配置，然后添加环境变量使相关的应用默认加载fcitx。
1. 安装fcitx以及配置 sudo pacman -S fcitx fcitx-im fcitx-configtool
fcitx 为基础安装包，fcitx-im用于GTK/QT等界面上使用的包，fcitx-configtool为配置界面（kde下还能安装一个kde版的configtool）。
2. 安装搜狗输入法 yaourt fcitx-sogoupinyin
此处有坑，默认的安装方式会编译安装qtwebkit，速度非常的慢（一个小时午觉后还没好&amp;hellip;)
在库的官方说明中（来自 https://aur.archlinux.org/packages/fcitx-sogoupinyin/ ）依赖项为qtwebkit (qtwebkit-bin)
其实只依赖qtwebkit-bin，因此先安装qtwebkit-bin可以解决依赖问题（不到一分钟&amp;hellip;)
 yaourt -S qtwebkit-bin
3. fcitx 设置中添加搜狗拼音 fcitx configuration中点加号添加sogou pinyin（默认语言为英语时需要勾选一个选项）
4. fcitx环境变量的添加 gui应用的环境变量一般不通过profile和bashrc。
arch wiki下的内容：
  KDM, GDM, LightDM 等显示管理器，请使用 ~/.xprofile arch wiki 警告: 上述用户不要在~/.xinitrc中加入下述脚本，否则会造成无法登陆。(但在里头加了也没挂) 如果您用 startx 或者 Slim 启动，请使用~/.xinitrc 中加入
  export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx
  如果你使用的是较新版本的GNOME，使用 Wayland 显示管理器，则请在/etc/environment中加入
  GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx</description>
    </item>
    
    <item>
      <title>arch linux (manjaro) 下运行tim和qq</title>
      <link>https://extendswind.top/posts/technical/tim_install_wine/</link>
      <pubDate>Sun, 20 Jan 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/tim_install_wine/</guid>
      <description>基于AUR的安装是没什么难度了，主要安装后会出各种问题，还有选不同的包的影响。
官方的wiki上推荐安装deepin-wine-tim，基于wine和最新版的tim。安装后存在qq密码每次都要输入的问题（201804测试没有此问题，但还是不太稳定，2018年因为wine的更新导致挂了两次只能回退）。
更推荐使用的deepin.com.qq.office，基于deepin-wine，配置好了比较稳定。
ps: 2021年12月更新，AUR里com.qq.tim.spark从Spark应用商店的移植实现的效果也差不多，deepin-wine-time 已经从wine转到了deepin-wine，各方面的问题也有比较好的解决方案，外加作者一直在积极更新。项目地址上有一些问题的解决方案：
https://github.com/vufa/deepin-wine-tim-arch
新版本的更新在不同的环境下出现了一些新问题，建议在各个仓库对应的github链接以及一直更新的arch wiki上找找最新的方案。
安装步骤 安装  yaourt -S deepin.com.qq.office
ps：吐槽，安装deepin-wine的各个确认略多。 d
qq提取消息、截图等快捷键设置 在/opt/deepinwine/tools/sendkeys.sh脚本能够传递快捷键，如直接运行./sendkeys.sh a 则会向qq或tim进程发送 ctrl+alt+a。
不同桌面环境添加快捷键的方法差不多，主要步骤：
 setting -&amp;gt; keyboard -&amp;gt; shortcut 添加快捷键，选择上面的脚本，在脚本后面加上a 指定运行脚本的快捷键  此时按快捷键后相当于qq中按 ctrl+alt+a (截图)
同理可以设置qq其它快捷键
一般问题 大多出现在基于wine的tim上，基于deepin的tim问题很少。
deepin-wine在非gnome系的桌面上的运行问题 3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误
  X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)
由于deepin-wine依赖了gnome系（mate,cinnamon,gnome）的setting-daemon，需要安装后运行（一般加入开机启动）
sudo pacman -S cinnamon-settings-daemon /usr/lib/cinnamon-settings-daemon/csd-xsettings 无法输入中文 如果其它地方可以使用输入法，一般为环境变量的问题，fcitx没有配置好。
粗暴解决方式: 下面的文件夹中加入环境变量</description>
    </item>
    
    <item>
      <title>在非gnome系桌面环境下运行deepin-wine tim的错误解决</title>
      <link>https://extendswind.top/posts/technical/deepin_wine_run_in_not_gnome_desktop_environment/</link>
      <pubDate>Sun, 20 Jan 2019 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/deepin_wine_run_in_not_gnome_desktop_environment/</guid>
      <description>i3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误
  X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)
在gnome、mate、cinnamon三个桌面上运行较好，xfce4上运行有少许焦点上的bug，其它桌面环境和管理器下直接出上面的错误。
最近终于在aur上看到是因为deepin-wine依赖了gnome-settings-daemon（gnome系的cinnamon和mate的对应组件也能用），启动后就能正常运行，但AwesomeWM会使用xsettings对应的主题，KDE基本正常运行，其它非gnome系的桌面环境未测试。
解决方案 1. 安装gnome-settings-daemon (arch 系） sudo pacman -S gnome-settings-daemon ubuntu 下的包和运行的程序名略不一样，参考：
https://github.com/wszqkzqk/deepin-wine-ubuntu/issues/12#issuecomment-443656358
2. 在tim启动脚本中加入启动 /opt/deepinwine/apps/Deepin-TIM/run.sh 的文件前添加下面的行：
/usr/lib/gsd-xsettings &amp;amp;
注意 主要缺点——影响主题（某些桌面环境） AwesomeWM在使用xsettings之后，主题等需要与对应的xsettings设置相对应。如使用gnome-settings-daemon时，需要在gnome的设置里更改主题。使用lxappearance修改主题只会更改~/.gtkrc-2.0等文件，不会生效。
csd-xsettings 的影响 因为大小和简洁的原因从gnome的xsettings换到了cinnamon的xsettings，下面的设置在gsd-xsettings上未测试。
csd-xsettings 主要影响两个地方：1. 启动过程； 2. 在tim内调用外部程序打开链接的过程（如打开网页、打开本地目录）。
可以考虑启动后关闭对tim，可以避免影响系统主题一类的问题，但会导致无法调用外部程序。加上运行后5s关闭的参数即可:
/usr/lib/cinnamon-settings-daemon/csd-xsettings --exit-time 5 &amp;amp;
附：使用cinnamon的xsettings的设置 主题的问题在awesome这种环境下略坑，懒得去试gnome上的主题设置需要哪些包，安装整个gnome的包需要800多M，直接安装了cinnamon的基础包（90M左右）。和gnome只是些名字上的区别：
sudo pacman -S cinnamon # awesome的autorun里加入下面程序使开机运行 /usr/lib/cinnamon-settings-daemon/csd-xsettings 在系统设置里可以下载和更改主题
小坑   tim和qq会在点击好友图像时卡死的情况。原因之一可能是pulseaudio进程，kill掉就行，会影响声音的调整。（千里之外的两个程序不知道为什么会卡一起）</description>
    </item>
    
    <item>
      <title>zotero zotfile插件 pdf附件文件夹在多系统下的同步设置</title>
      <link>https://extendswind.top/posts/research/zotero_multiple_directory_pdf_sync/</link>
      <pubDate>Wed, 09 Jan 2019 09:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/research/zotero_multiple_directory_pdf_sync/</guid>
      <description>之前的附件使用zotfile单独的文件夹管理，换了一块硬盘，挂载目录发生变化后zotero里所有的附件都打不开，在zotero的目录设置和zotfile的目录设置里改了都没用。
使用sqllite的浏览器看了一眼zotero的存储数据库(zotero.sqlite)，在表itemAttachments中存储了所有附件的类型地址等信息，发现里头的地址全都使用的绝对路径！！
重点在于设置zotero和zotfile的附件路径和转移文件。
使用网盘同步的不用折腾这些。
方法一：设置为相对路径并修改文件 设置  zotero preferences -&amp;gt; Files and Folders -&amp;gt; Linked Attachment Base Directory 设置存储路径 （注意不是 data directory） 把zotfile里的路径也改到这（不知道具体什么机制，zotfile有个相对路径的pull request不知道读的是不是这个，懒得多折腾）  已有的文件移动   如果由于换硬盘换系统一类的问题，先使用软连接指向原来的目录，让zotero能够找到原来的文件。（源目录可以使用sqllite的浏览器看到）
  在library下全选所有的items，然后右键 Manage Attachments -&amp;gt; Rename Attachments。（看起来是重命名，实质上会移动所有的文件）
  此时此前附件中的绝对路径/mnt/data/...会变成attachments：catagory1/test1.pdf 类似的相对路径。
方法二：直接操作sqllite数据库来改 下面的语句供参考，建议稍了解后操作，使用update导致数据丢失会很麻烦。
把下面路径中的/home/fly/public_download/改成自己数据库里的路径即可。
update itemAttachments set path=replace(path, &#39;/home/fly/public_download/&#39;, &#39;attachments:&#39;) where path like &#39;/home/fly/public_download%&#39; 最后 跨操作系统或者跨目录直接设置到相同的目录即可。</description>
    </item>
    
    <item>
      <title>Spark设置自定义的InputFormat读取HDFS文件</title>
      <link>https://extendswind.top/posts/technical/problem_spark_reading_hdfs_serializable/</link>
      <pubDate>Sat, 15 Dec 2018 11:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/problem_spark_reading_hdfs_serializable/</guid>
      <description>Spark提供了HDFS上一般的文件文件读取接口 sc.textFile()，但在某些情况下HDFS中需要存储自定义格式的文件，需要更加灵活的读取方式。
使用KeyValueTextInputFormat Hadoop的MapReduce框架下提供了一些InputFormat的实现，其中MapReduce2的接口(org.apache.hadoop.mapreduce下)与先前MapReduce1(org.apache.hadoop.mapred下)有区别，对应于newAPIHadoopFile函数。
使用KeyValueTextInputFormat的文件读取如下
import org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat import org.apache.hadoop.io.Text val hFile = sc.newAPIHadoopFile(&amp;#34;hdfs://hadoopmaster:9000/user/sparkl/README.md&amp;#34;, classOf[KeyValueTextInputFormat], classOf[Text], classOf[Text]) hFile.collect 使用自定义InputFormat InputFormat是MapReduce框架下将输入的文件解析成字符串的组件，Spark对HDFS中的文件实现自定义读写需要通过InputFormat的子类实现。下面只写简单的思路，具体的可以参考InputFormat和MapReduce相关资料。
InputFormat的修改可以参考TextInputFormat，继承FileInputFormat后，重载createRecordReader返回一个新的继承RecordReader的类，通过新的RecordReader读取数据返回键值对。
打包后注意上传时将jar包一起上传：
`./spark-shell &amp;ndash;jars newInputFormat.jar
运行的代码和上面差不多，import相关的包后
val hFile = sc.newAPIHadoopFile(&amp;#34;hdfs://hadoopmaster:9000/user/sparkl/README.md&amp;#34;, classOf[NewTextInputFormat], classOf[Text], classOf[Text]) 一些坑 序列化问题 在读取文件后使用first或者collect时，出现下面的错误
  ERROR scheduler.TaskSetManager: Task 0.0 in stage 2.0 (TID 18) had a not serializable result: org.apache.hadoop.io.IntWritable Serialization stack: - object not serializable (class: org.apache.hadoop.io.IntWritable, value: 35) - element of array (index: 0) - array (class [Lorg.</description>
    </item>
    
    <item>
      <title>Hadoop 机架（集群拓扑）设置</title>
      <link>https://extendswind.top/posts/technical/hadoop_rack_awareness/</link>
      <pubDate>Wed, 12 Dec 2018 11:20:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_rack_awareness/</guid>
      <description>Hadoop会通过集群的拓扑（节点在交换机的连接形式）优化文件的存储，降低跨交换机的数据通信，使副本跨交换机以保证数据安全。
但Hadoop没有默认的集群拓扑识别机制，需要使用额外的java类或脚本两种形式设置。
官网上给了集群拓扑的基本说明（!(Rack Awareness)[https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/RackAwareness.html]），给出来的那两段脚本看得有点懵，就自己试了一下，写了个更简单的。
其实只是Hadoop会调用脚本，将多个Datanode的ip作为输入，每次最多输入的ip数设置在net.topology.script.number.args，将输入的ip转换成/rack-num的形式(以/开头的字符串)，用标准输出流（如Python的print）输出结果。
具体操作 编写脚本 下面的脚本在输入
192.168.3.1 192.168.3.4 时，会输出
/rack1 /rack4 #!/bin/python3 import sys # 第一个参数是脚本路径，直接pop掉 sys.argv.pop(0) # 0-3 rack0 # 4-7 rack1 # 8-11 rack2 # ... # 其它的参数里每个参数都是一个ip，此处直接取ip的最后一位除以4作为Racknum # 实践上可以读文件确定ip的对应关系 for ip in sys.argv: hostNum = int(ip.split(&amp;#34;.&amp;#34;)[3]) print(&amp;#34;/rack&amp;#34; + str(int(hostNum/4))) 设置配置参数 &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;net.topology.script.file.name&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;/home/sparkl/hadoop/etc/hadoop/topology.py&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; 重启集群即可
验证结果 以下命令能够直接获取某一个文件的分布状态，以及总的rack数量：
hdfs fsck /readme.md -files -blocks -racks
貌似没有直接以树状的形式输出集群拓扑的命令，namenode的日志中能看到datanode在连接时的拓扑位置。</description>
    </item>
    
    <item>
      <title>Hadoop 副本放置策略的源码阅读和设置</title>
      <link>https://extendswind.top/posts/technical/hadoop_block_placement_policy/</link>
      <pubDate>Tue, 11 Dec 2018 21:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_block_placement_policy/</guid>
      <description>大多数的叫法都是副本放置策略，实质上是HDFS对所有数据的位置放置策略，并非只是针对数据的副本。因此Hadoop的源码里有block replicator(configuration)、 BlockPlacementPolicy(具体逻辑源码)两种叫法。
主要用途：上传文件时决定文件在HDFS上存储的位置（具体到datanode上的具体存储介质，如具体到存储在哪块硬盘）；rebalance、datanode退出集群、副本数量更改等导致数据移动的操作中，数据移动的具体位置。
BlockPlacementPolicy BlockPlacementPolicy 作为虚基类提供了基本的接口，具体的子类重点实现下面 选择副本 、 验证副本放置是否满足要求 、 选择能够删除的副本 三个函数：
/** * 核心的副本放置策略实现，返回副本放置数量的存储位置 * **如果有效节点数量不够（少于副本数），返回尽可能多的节点，而非失败** * * @param srcPath 上传文件的路径 * @param numOfReplicas 除下面chosen参数里已经选择的datanode，还需要的副本数量 * @param writer 写数据的机器, null if not in the cluster. 一般用于放置第一个副本以降低网络通信 * @param chosen 已经选择的节点 * @param returnChosenNodes 返回结果里是否包含chosen的datanode * @param excludedNodes 不选的节点 * @param blocksize 块大小 * @return 排序好的选择结果 */ public abstract DatanodeStorageInfo[] chooseTarget(String srcPath, int numOfReplicas, Node writer, List&amp;lt;DatanodeStorageInfo&amp;gt; chosen, boolean returnChosenNodes, Set&amp;lt;Node&amp;gt; excludedNodes, long blocksize, BlockStoragePolicy storagePolicy); /** * 判断传入的放置方式是否符合要求 */ abstract public BlockPlacementStatus verifyBlockPlacement( DatanodeInfo[] locs, int numOfReplicas); /** * 当副本数量较多时，选择需要删除的节点 */ abstract public List&amp;lt;DatanodeStorageInfo&amp;gt; chooseReplicasToDelete( Collection&amp;lt;DatanodeStorageInfo&amp;gt; candidates, int expectedNumOfReplicas, List&amp;lt;StorageType&amp;gt; excessTypes, DatanodeDescriptor addedNode, DatanodeDescriptor delNodeHint); Hadoop 提供的 BlockPlacementPolicy 实现 Hadoop提供了BlockPlacementPolicyDefault、BlockPlacementPolicyWithNodeGroup、AvailableSpaceBlockPlacementPolicy三种实现（hadoop 2.</description>
    </item>
    
    <item>
      <title>arch linux下网易云音乐运行没反应，只能使用root用户运行</title>
      <link>https://extendswind.top/posts/technical/netease_music_can_not_open/</link>
      <pubDate>Tue, 20 Nov 2018 19:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/netease_music_can_not_open/</guid>
      <description>最近打开网易云音乐没有反应，只在htop命令下能看到运行的进程（manjaro+mate+awesome）。
命令行sudo可以正常运行
无用尝试  安装官网给的最新1.1.3的deepin与ubuntu16两个版本 网上提到的&amp;ndash;no-sandbox参数运行 kill已经运行的netease-cloud-music相关进程  解决方案 回退到更早的1.0.0版，估计新版没有在各个linux系统下测试。
http://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb
debian系就直接dpkg -i吧
arch系通过AUR安装稍麻烦:
 卸载原版本 yaourt -S netease-cloud-music 按y Edit PKGBUILD 将1.1.3的安装包地址替换为1.1.0的安装包地址，并且将对应hash值改为skip，具体如下  改之前：
source=( &amp;quot;http://packages.deepin.com/deepin/pool/main/n/netease-cloud-music/netease-cloud-music_${pkgver}-${_pkgrel}_amd64.deb&amp;quot; &amp;quot;http://music.163.com/html/web2/service.html&amp;quot; ) md5sums=(&#39;53c47c1bf6797b2a0e455bc59833ab2d&#39; &#39;SKIP&#39;) 改之后
source=( &amp;quot;http://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb&amp;quot; &amp;quot;http://music.163.com/html/web2/service.html&amp;quot; ) md5sums=(&#39;SKIP&#39; &#39;SKIP&#39;) 然后正常安装即可</description>
    </item>
    
    <item>
      <title>leetcode: Median of Two Sorted Arrays</title>
      <link>https://extendswind.top/posts/technical/leetcode4/</link>
      <pubDate>Tue, 13 Nov 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/leetcode4/</guid>
      <description>题目   Median of Two Sorted Arrays There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: nums1 = [1, 3] nums2 = [2] The median is 2.0 Example 2: nums1 = [1, 2] nums2 = [3, 4] The median is (2 + 3)/2 = 2.</description>
    </item>
    
    <item>
      <title>使用AwesomeWM作为Mate(Gnome相同) Desktop的窗口管理器</title>
      <link>https://extendswind.top/posts/technical/using_awesomewm_as_wm_of_mate_desktop/</link>
      <pubDate>Sat, 20 Oct 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/using_awesomewm_as_wm_of_mate_desktop/</guid>
      <description>20190118更新:
最近发现有在非gnome系的DE下运行deepin-wine的解决方案，没必要专门跑一个mate。
安装gnome-setttings-daemon，然后运行/usr/lib/gsd-xsettings。（不同系统会不一样）
具体记录在另一篇博客
 AwesomeWM这种平铺的窗口管理器用得很爽，只是基于wine的qq最近又莫名其妙抽风，感觉还是切到deepin-wine上比较靠谱。而deepin-wine在awesome下运行qq会报错X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)，而在Gnome系下运行正常。看到Gnome和Mate能够运行awesomewm，就折腾了一下试试。
Awesome只是Gnome等桌面管理器的组件之一，gnome系的Mate可以修改默认的窗口管理器。
具体折腾   安装AwesomeWM、Mate桌面环境与dconf-editor（arch下使用pacman -S）。
  进入Mate桌面环境后，修改org.mate.session.required-components windowmanager 的值为&amp;rsquo;awesome&#39;，如果不需要桌面上的图标，可以将org.mate.session.required-components的值只留下windowmanager。
  上面的设置无法通过命令行打开awesome，需要添加awesome的图标。在/usr/share/applications目录下新建awesome.desktop，内容如下（网上直接粘的，估计有些可以不要，懒得试了）：
  [Desktop Entry] Type=Application Name=awesome Exec=awesome NoDisplay=true # name of loadable control center module X-MATE-WMSettingsModule=awesome # name we put on the WM spec check window X-MATE-WMName=awesome # back compat only X-MateWMSettingsLibrary=awesome X-MATE-Bugzilla-Bugzilla=MATE X-MATE-Bugzilla-Product=awesome X-MATE-Bugzilla-Component=general X-MATE-Autostart-Phase=WindowManager X-MATE-Provides=windowmanager X-MATE-Autostart-Notify=true </description>
    </item>
    
    <item>
      <title>《十三邀》--李诞、马东、许知远</title>
      <link>https://extendswind.top/posts/life/_13_reviewes/</link>
      <pubDate>Sun, 30 Sep 2018 22:40:48 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/_13_reviewes/</guid>
      <description>看了奇葩说后查了一下李诞，又因为一些博客里提到了这个采访才看了《十三邀》。一个在综艺节目中脑回路极大、思维敏捷、搞笑，而又在生活中保持佛系态度,让我想看看采访中表达的思想。
看了对马东和李诞两个人的采访，五十多分钟的访谈看完了似乎没什么感觉，又印象有很多带动点思考的东西。
看一些评论有点意思，从一段对话里带着个人色彩解读，展示一些看不到的东西，虽然某些只以一个节目批判许知远人品和采访能力的论述略显浮躁。
评价一个人没什么意思，特别是以并不能展示全貌的公众视角，只谈看视频后的各种对自己的联想。
许知远似乎一直想表现出心底的与众不同，或者可能是在故意把自己的观点展示得更为偏激以试探对方的反应。很多地方表现出对当前社会状态的不满，期待对方有相同的感受，而感觉上马东和李诞都表示出某些理解，而现在又不属于同样的感觉。
马东作为一个老练的主持人表现得很成熟，表现出这个世界的悲凉，但又保持一个积极的态度，像是以一个太极的感觉回应许知远对时代的不满。
和李诞的访谈中，他们看起来是在以不同的方式做自己的坚持。一个处处展示自己知识分子的身份和追求，表现出愤青的批判；一个以佛系的心态面对生活，放低姿态以“浅薄”自嘲。
对当前的生活状态，显然谈不上不太满意，无论是能力还是心态上都还距离自己想要的高度甚远。过去的一段时间，想给自己贴上成熟的标签，但又总感觉少了点青春，某些严肃也显得和自己略不协调。在《天才在左，疯子在右》中某个善于模仿他人的“患者”提到，人一生的最理想状态或许是历经沧桑后老年人的那种平和。也经常想象自己在心态上的终极追求，年老时最想要达到的心态，或许，成熟之中，还需要李诞那样的一份佛系和“浅薄”。
记下的一点东西 李诞 佛系。
通过笑话说实话。
“人是社会动物，人就是为了别人活的，你充分的自得，活在自己的精神世界里面，你就死了”。
“好吧，我就是想活在浅薄里，我就是想活得流于表面。”
马东 每个时代都追求精致，但又难以找到精致。
开始《奇葩说》是因为有很多吸引他的未知的东西，技术、平台等。
人生的底色是凄凉，不像积极主义者，凄凉是指无法改变的东西。
“被误会是表达者的宿命”。</description>
    </item>
    
    <item>
      <title>git 代码回滚与爬坑 -- reset and revert</title>
      <link>https://extendswind.top/posts/technical/git_code_roll_back_revert_and_reset/</link>
      <pubDate>Tue, 11 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/git_code_roll_back_revert_and_reset/</guid>
      <description>reset 某些特殊的情况下，需要回退到先前的某一次提交。
git log 查找想要回退的commit的id后运行：
git reset --hard 2c1e288
回退后git log只会显示回退版本之前的提交。如果需要返回最新的提交，使用git reflog查看对应的id。
git reset只适合本地的回退和查看先前代码。如果远程仓库已有最新的提交，git会认为远程仓库的代码较新，需要先同步远程代码再进行修改，此情况下建议使用revert。
git reset &amp;ndash;soft &amp;ndash;mixed &amp;ndash;hard 以HEAD～为例（HEAD前的一次提交）
git reset --soft HEAD~ 会回到前一次提交的commit执行之前的状态 git reset --mixed HEAD~ 会回到前一次提交的add执行之前的状态 git reset --hard HEAD~ 会回到前一次提交的add执行之前的状态，并且将目录里的所有文件调整为前一次的提交状态
通常回退时需要将文件也回退需要加 --hard 标签。
git的文件组织 git将所有的文件以hash码命名放在仓库中存储。
HEAD指针，一般可以理解为当前commit状态的一个快照（指向仓库中当前commit的所有的文件）。每次commit或者merge等会创建新的commit节点时，会让HEAD指向新的位置。
reset会改变HEAD指针的位置与HEAD对应的分支指针的位置，checkout只会改变HEAD指针指向的分支。
revert git revert &amp;lt;commit-id&amp;gt; 相当于取消一次commit ，会让结果和没有这一次提交一样，并非像reset那样直接回到某一次commit的代码。
使用revert不会破坏历史记录，只是提交一个新的修改使修改后代码和以前一致。
实质上相当于用前的代码merge 后的代码，因此如果后面对代码文件做了修改需要解决冲突。
revert一个merge commit 注意revert用在merge的commit上的情况有坑
git revert &amp;lt;commit-id&amp;gt; -m 1  需要添加-m参数，指定是merge前的第几个分支（git log上的merge后）。
revert的主要麻烦：如果存在分支合并的情况，如下，从m1 revert到a2时会添加一个新的提交m2，当m2与b2 merge时会显示已经merge过。
a1 -&amp;gt; a2 -&amp;gt; m1 -&amp;gt; m2 b1 -&amp;gt; b2 /</description>
    </item>
    
    <item>
      <title>SpatialHadoop的编译与运行</title>
      <link>https://extendswind.top/posts/technical/spatialhadoop_compile_and_run/</link>
      <pubDate>Wed, 05 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/spatialhadoop_compile_and_run/</guid>
      <description>SpatialHadoop相对HadoopGIS等库，在MapReduce时代的空间数据处理开源库算处理较好。SpatialHadoop在效率上相对一些新的基于Spark空间数据处理开源库明显偏低，加上本身的功能实现得差不多，最近提交的更新越来越少，感觉发展趋势不太好，主要用于学习相关的索引技术。
编译与运行 主页上有已经编译好的包，可以直接解压到Hadoop目录下运行，但官方的版本解压有错误，因此下载github上源码编译。
需要的环境：
 jdk8 Hadoop 2.7.7 maven  源码编译 源码地址 https://github.com/aseldawy/spatialhadoop2，直接下载或者git clone到本地。
需要安装maven用于代码编译。
编译前将pom.xml文件中hadoop相关的版本改为需要的版本。
mvn compile 编译源码 mvn assembly:assembly 代码打包，会在target目录下生成jar和一个包含jar与相关依赖的tar.gz包
在2f1aefd32860d0279f2fc479a8bafb68d07e3761版本（Mar 13,2018）编译时会由于缺少一个测试文件测试失败，可以选择跳过测试，或者注释掉测试的代码（src/test/java/edu/umn/cs/spatialHadoop/indexing/RStarTreeTest.java中的某个函数）。
运行 首先需要有一个Hadoop集群，能够提交yarn任务。
将target目录下生成的tar.gz包（spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz）拷贝到Hadoop目录下并解压即可。
cp target/spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz $HADOOP_HOME/ cd $HADOOP_HOME tar -zxvf spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz Hadoop目录下运行下面的测试代码，会向HDFS中写入一个随机生成的矩形文件。
sbin/shadoop generate test.rects size:1.gb shape:rect mbr:0,0,1000000,1000000 -overwrite
SpatialHadoop运行机制 shadoop 脚本 SpatialHadoop 通过脚本shadoop运行命令，脚本就只有几行代码
bin=`dirname &amp;#34;$0&amp;#34;` bin=`cd &amp;#34;$bin&amp;#34; &amp;gt; /dev/null; pwd` # Call Hadoop with the operations.Main as the main class . &amp;#34;$bin&amp;#34;/hadoop edu.umn.cs.spatialHadoop.operations.Main $@ 其实只是将spatialhadoop的jar包与相关依赖jar包放入Hadoop的包目录中，然后通过shadoop脚本调用Hadoop脚本调用包中的一个类，向YARN提交MapReduce任务。</description>
    </item>
    
    <item>
      <title>Hadoop YARN 调度器（scheduler） —— 资源调度策略</title>
      <link>https://extendswind.top/posts/technical/hadoop_yarn_resource_scheduler/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_yarn_resource_scheduler/</guid>
      <description>搜了一些博客，发现写得最清楚的还是《Hadoop权威指南》，以下内容主要来自《Hadoop The Definitive Guide》 4th Edition 2015.3。
Hadoop YARN Scheduler 三个调度器 YARN提供了CapacityScheduler, FairScheduler, FifoScheduler三个调度器，继承于AbstractYarnScheduler，Resource Manager通过调度器决定对提交application分配的资源大小。
CapacityScheduler首先将所有资源分配到hierarchical queue中，每个任务执行时指定对应的queue，使大任务不会占用整个集群的资源，通过对queue的资源管理提高整个集群的资源共享能力。通常会使小任务执行更快，大任务更慢。
Fair Scheduler 会在第一个任务运行时分配当前同级队列的所有资源，当有其它任务运行时，回收前面任务运行时的部分资源（一般为运行完成的Container）用于其它任务。
至于FIFO，源码里都没有描述，可能就是一般的先进先出了。
YARN默认使用CapacityScheduler，通过下面的属性配置：
&amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.class&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; YARN 动态资源分配 YARN 能够动态申请资源，如MapReduce中reduce的container会在map过程结束后申请。但Spark On YARN的机制为申请固定的executor，而不动态改变已申请的资源。
YARN上新运行的任务能够使用已运行任务回收的资源(如运行完Map task的container)，甚至还能够通过强行结束先前任务的container抢占资源。
Capacity Scheduler CapacityScheduler重点解决多个组织共享集群资源，并保证每个组织自己的资源使用量。当自己的资源不足时能够使用其它组织的空闲资源。
资源通过层级队列（hierarchical queues）的形式进行组织，配置在etc/hadoop/capacity-scheduler.xml.
&amp;lt;!-- 队列结构设置 --&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.scheduler.capacity.root.queues&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;a,b&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;The queues at the this level (root is the root queue). &amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.scheduler.capacity.root.a.queues&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;a1,a2&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;The queues at the this level (root is the root queue).</description>
    </item>
    
    <item>
      <title>使用Python3发布博客到支持mateweblog的平台（博客园等）</title>
      <link>https://extendswind.top/posts/technical/python3_publish_blog/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/python3_publish_blog/</guid>
      <description>用个人域名搭建的博客在百度搜索上的SEO太差，百度一直只收录主页，懒得再为这些问题折腾，直接同步到博客园算了，考虑用Python。
貌似CSDN已经关闭了metawebblog接口，只在博客园上测试。
Python发博客的主要方案  通过xmlprc的metaweblog接口（首选） CSDN和博客园的api（定位不是用来发博客的，申请key和调接口略麻烦） 使用抓包的技术模拟浏览器登录发博客（没悬念更折腾）  代码 对于支持metaweblog的博客平台，只要提供用户名、密码和博客相关信息。
python2 需要将后面的xmlrpc.client改为xmlrpclib，并且import xmlrpclib
#!/bin/python3 import xmlrpc.client username = &amp;#39;&amp;#39; # TODO your username passwd = &amp;#39;&amp;#39; # TODO your passwd # url = &amp;#39;http://www.cnblogs.com/&amp;#39; + username + &amp;#39;/services/metaweblog.aspx&amp;#39; # 此链接已挂 url = &amp;#39;https://rpc.cnblogs.com/metaweblog/&amp;#39; + username title = &amp;#34;helloWorld&amp;#34; content = &amp;#34;&amp;lt;p&amp;gt; test &amp;lt;p&amp;gt;&amp;#34; tags = &amp;#34;tag1, tag2&amp;#34; blogProxy = xmlrpc.client.ServerProxy(url) # 获取最近博客列表 print(blogProxy.metaWeblog.getRecentPosts(&amp;#39;&amp;#39;, username, passwd, 1)) # 发布博客 blogProxy.metaWeblog.newPost(&amp;#39;&amp;#39;, username, passwd, dict(title=title, description=content, mt_keywords=tags), True) 参考 https://rpc.</description>
    </item>
    
    <item>
      <title>静态blog的免费托管部署、加域名与搜索优化（SEO）</title>
      <link>https://extendswind.top/posts/technical/hugo_blog_host_and_seo/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hugo_blog_host_and_seo/</guid>
      <description>给博客加个域名准备长用，Hugo生成后一直放在github page上，为了让百度能搜到费了一堆事。
问题 如果只是在github page上弄个自己域名的网站，只需要在结果文件中添加一个CNAME文件，写入网站域名，然后在域名运营商提交解析。等待域名解析生效后即可通过域名访问。
然后为了让搜索引擎能够检索，通过baidu、bing、google的站长工具提交链接。
此时发生一个大bug，github因为某种原因限制了百度爬虫的进入，也就是百度上很少搜到github内网页的原因。
重点解决的问题为：github page上的内容无法被百度检索。
解决方案 相关解决github page被检索的方案较多，重点都是通过CDN缓存网站和将网站托管在其它地方两个方案。
CDN略麻烦，还需要其它的服务。 在各种折腾之后选择了托管在netlify上，然后在百度站长工具中提交网站。
还没完 Hugo的sitemap百度无法识别 Hugo默认可以使用多语言，当设置了中文和英文时，默认路径下的sitemap会指向两种语言的sitemap路径而非直接的网页，百度无法识别&amp;hellip;.
解决方案，只设置一种语言。
百度长时间只收录主页（收录链接数为1） 百度能看到一堆人碰到类似的问题。
有解决方案建议放在CSDN一类的普通博客上，并附上链接，百度时间长了会自动收录。（google就没这问题&amp;hellip;）
还有稳定更新，提高博客的质量。
然后静静的等待&amp;hellip;.
附：国内外的免费静态网站托管 国外代码托管系列
 netlify，最好最方便，没有之一，添加域名和github仓库的地址就能解决问题，github上的提交还会自动同步。 github page，网页放上去选择显示的分支即可，网速虽然没有飞起但在教育网下还行，主要问题在于上面提到的，百度搜索不到&amp;hellip; gitlab，同github，但使用了Docker技术提高了构建能力，能够上传源博客在服务端构建。只是折腾了一会，fork的项目构建网页一直失败，懒得再debug&amp;hellip; bitbucket，同github，一个大bug在于不能直接添加域名，域名解析过去无效，需要额外的服务（又是一堆配置）  国内代码托管
 码云，同github，但添加域名是收费功能。 coding，之前博客提到的最多，貌似最近加入了广告，进入网页前几秒会跳入广告页（略不能忍）。  </description>
    </item>
    
    <item>
      <title>Hadoop HDFS 远程调试（Docker环境下的Hadoop集群）</title>
      <link>https://extendswind.top/posts/technical/remote_debug_of_hadoop_in_docker/</link>
      <pubDate>Thu, 26 Jul 2018 21:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/remote_debug_of_hadoop_in_docker/</guid>
      <description>Hadoop 典型的调试方式是通过log4j输出日志，基于日志的形式查看运行信息。在源码阅读中，经常有不容易猜的变量，通过大量日志输出调试没有远程调试方便。
Java 远程调试 不想了解的可以直接跳到下面Hadoop
通过JPDA（Java Platform Debugger Architecture），调试时启动服务，通过socket端口与调试服务端通信。
下面只用最常用的服务端启动调试服务监听端口，本地IDE（idea）连接服务端。
具体操作 1、启动被调试程序时添加参数：   jdk9: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:8000
jdk5-8: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000
jdk4: -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000
jdk3 及以前: -Xnoagent -Djava.compiler=NONE -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000
此处有坑，网上大部分没有提到jdk版本不同导致的区别，很多博客使用jdk4的写法，可能导致问题（idea配置远程调试时有上面的选项）。
另外一个小坑, 下面第一个命令正常执行，第二个命令会忽略调试选项：
 java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000 test java test -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000  主要参数。suspend=y时，程序启动会先挂起，IDE连接后才会运行；suspend=n时，程序启动会直接运行。address后面为端口号，不与其它端口重合即可。
2、启动Idea连接调试 使用idea打开调试项目的源码工程
Run -&amp;gt; Edit Configurations , 点“加号” -&amp;gt; remote，然后填上被调试程序所在主机的ip以及上面的address对应端口号，并选择源码所在的module。
添加后debug运行，剩下的和本地调试相同。
Hadoop 远程调试 思路和上面的操作一致。下面以调试HDFS中的namenode为例。
具体操作 1、修改Hadoop启动参数为debug模式 如果需要调试namenode服务，在etc/hadoop/hadoop-env.sh文件后添加：
export HDFS_NAMENODE_OPTS=&amp;quot;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000&amp;quot; 
HDFS启动的jvm主要为namenode和datanode，jvm启动的参数设置在etc/hadoop/hadoop-env.sh中。其中namenode启动参数环境变量为 HDFS_NAMENODE_OPTS，datanode为 HDFS_DATANODE_OPTS（针对Hadoop3，hadoop2的设置为HADOOP_NAMENODE_OPTS HADOOP_NAMENODE_OPTS）。YARN等服务对应的环境变量需要另查。
2、启动服务 sbin/start-dfs.sh 或者 bin/hdfs --daemon start namenode仅启动namenode</description>
    </item>
    
    <item>
      <title>使用u盘安装linux(manjaro)时Grub报错</title>
      <link>https://extendswind.top/posts/technical/manjaro_install_problem_grub/</link>
      <pubDate>Tue, 17 Jul 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/manjaro_install_problem_grub/</guid>
      <description>错误   error: invalid arch-independent ELF magic. Entering rescue mode&amp;hellip; grub rescue&amp;gt;
使用Rufu ISO模式烧录的U盘，lagency 模式能够启动，但点安装后出上面错误；UEFI模式直接出上面错误。
解决方案 不多说，百度背锅，google答案的前几个就是正解。
U盘烧录问题，使用rufu烧录U盘时，最好使用DD模式而非ISO模式。（去年安装manjaro-xfce4时用ISO模式没出过）
https://forum.manjaro.org/t/grub-error-computer-with-no-os-installed-invalid-arch-independent-elf-magic/21805
解决方案：使用Rufu烧录U盘，点开始后会有选择DD模式或者ISO模式，此时选DD模式，然后UEFI启动即可。
论坛上还推荐使用etcher</description>
    </item>
    
    <item>
      <title>开启不折腾模式</title>
      <link>https://extendswind.top/posts/technical/from_geeker_to_no_self_inflicted/</link>
      <pubDate>Tue, 17 Jul 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/from_geeker_to_no_self_inflicted/</guid>
      <description>用了很长一段时间的linux，和很多人对linux相比windows的优点评价相同，linux是非常自由的操作系统。从内核到桌面环境到各个应用都可以自行定制，能够完全按照自己的喜好修改，实在没有的功能甚至能够自己造轮子。
也因此对于我这样的强迫症患者，在各个组件上都想追求一个最舒适的解决方案。这样一个系统确实用得舒服，但也总有用得不舒服的地方需要持续改善，不断调整各个组件以及造一些脚本级的轮子。
最近连续几周效率严重偏低，也突然发现自己在这些看似意义不大的地方耗费的时间太多。一个emacs各种折腾最后只是写写简单的c++、Python和org；awesomeWM嵌入Mate其实相比传统的多workspace方式也没特别大的区别；软件尽可能找到开源替代与商业版本隔离。
或许太多时候以geek自居追求某种“无强迫”环境，而忘记要事优先。
提醒一下自己刚开始读研的目标，在一堆感兴趣的hello world基础之上有所深入。
感兴趣的技术太多，总要有所舍弃。
linux是用来折腾的，更是用来解决问题的。</description>
    </item>
    
    <item>
      <title>设计模式 之 原型模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_prototype/</link>
      <pubDate>Tue, 03 Jul 2018 21:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_prototype/</guid>
      <description>吐槽 感觉这是至今最值得吐槽的设计模式之一，由于原型模式在本质上与工厂模式极为类似，并且简单，但相关的书和博客很少提到要点。某些书上和博客还直接在类里加个clone方法就告诉我这是原型模式，不说清楚为什么要划分原型类和具体类&amp;hellip;.
还有某些书上把原型模式划分为通用实现和java、c#一类的特定语言实现，不就是稍微改改clone函数的具体实现么，一点简单的语法而已&amp;hellip;.
有些地方提到原型模式与工厂模式类似，而极少有位置提到后面的客户端的实现问题&amp;hellip;.
感觉原型模式没什么意思，实质上就是把工厂模式中new的过程改为clone，具体的类对应于完成初始化的多个对象。
原型模式（Prototype Pattern） 首先画重点，原型模式是一种 创建对象 的模式。通过复制已经初始化好的对象以避免对对象进行某些复杂和耗时的初始化过程。可能存在多个被复制的对象，创建自不同的类或同一个类的不同初始化过程，用户需要动态决定复制哪一个对象。
主要实现思想：
 对象的复制只需要在每个类中实现一个clone函数即可 使用工厂模式相关思想获取具体的clone对象  java实现的clone操作 下面的实现基于java，如c++一类的语言对于每个对象的复制需要自行处理。
java的所有类都继承于Object，Object类中定义了native实现的clone函数，但需要实现Cloneable接口才能调用。通过clone函数能够直接复制内存中的对象而不用调用构造函数。
注意，java Object的clone函数为 浅拷贝，只会复制类成员对象地址而不创建新的对象。需要根据实际情况判读是否做相应的深拷贝修改。 吐槽：很多博客和书上的示例实质上就下面这一段，然后加个实例里n个成员变量和函数凑出十几到几十行，实现个Cloneable接口加个clone函数就算完了&amp;hellip;.
class Prototype implements Cloneable{ int attr; public Prototype clone(){ Prototype prototype = null; try { prototype = (Prototype)super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return prototype; } } 一个不使用java特性的简单实现 class Prototype{ int attr; public Prototype clone(){ Prototype clone = new Prototype(); clone.attr = this.attr; return clone; } } 同上，注意深拷贝和浅拷贝问题。</description>
    </item>
    
    <item>
      <title>设计模式 之 单例模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_singleton/</link>
      <pubDate>Mon, 02 Jul 2018 11:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_singleton/</guid>
      <description>singleton pattern
主要目标：对象只创建一次，每次都获得先前第一次创建的对象而不创建新的对象。（最好在使用时创建对象）
实现思想：使用静态方法getInstance得到对象，为了保证对象只能通过getInstance创建，使构造函数私有。
主要麻烦在于：
 多线程环境下getInstance方法的调用可能产生多个对象 使用synchronized关键字可能降低高并发效率  单例模式有很多种，大多用于解决多线程环境下的效率问题，高并发场景通常使用某些固定方案（java常用内部类机制），一般情况下思想比较简单，从应用的角度感觉不必深究。
（后面懒得用实际例子命名了，Log4j中获取的logger对象就使用了单例模式）
/** * 简单实现 * * 存在的问题： * * 当创建过程需要时间时，连续调用getInstance方法会导致创建多个对象，特别是涉及多线程时容易出问题。 */ class Singleton_problem { private static Singleton_problem m_singletonProblem = null; private Singleton_problem(){ // ...  } public static Singleton_problem getInstance(){ if (m_singletonProblem == null) m_singletonProblem = new Singleton_problem(); return m_singletonProblem; } } /** * 解决方案一： eager initialization * * 缺点在于没有lazy loading机制 */ class Singleton_eager{ private static final Singleton_eager m_singleton = new Singleton_eager(); private Singleton_eager(){ // .</description>
    </item>
    
    <item>
      <title>linux桌面发行版简介</title>
      <link>https://extendswind.top/posts/technical/linux_desktop_distribution/</link>
      <pubDate>Fri, 29 Jun 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/linux_desktop_distribution/</guid>
      <description>linux系统 桌面操作系统：windows，MacOS和各linux发行版。
2017年数据，windows份额超过90%，MacOS约6%，Linux份额最高的记录在2016年7月创下，是2.33%。
貌似用linux和MacOS的大多是程序员了。MacOS和linux系统正常使用（看书、上网、看电影等）已经比较成熟，没有太大的体验差异。
linux系统的主要缺点：
 某些常用软件在linux上没有或运行有问题（qq、迅雷、office等，只有deepin通过虚拟windows系统解决得稍好） 完美折腾需要掌握大量相关知识，不折腾难以体现其优点 某些设置复杂（较好的发行版已有极大的改善，某些操作需要使用命令）  linux作为桌面系统主要优点（作为服务器系统广泛使用不谈）：
 软件管理容易 可定制性超强 免费（看版权意识）  对于开发人员，大部分的软件一键安装还解决依赖问题，想要的操作大部分可以通过修改配置和安装软件实现。在运行某些开发软件会明显感觉更快，绝大部分配置通过文本文件容易修改。
linux发行版 一般的linux发行版包括：Linux内核，一些GNU程序库和工具，命令行shell，图形界面的X Window系统和相应的桌面环境，以及一系列其他的软件包（浏览器、阅读器、文本编辑器等）。由各种组织和个人维护。
主要用过的几个桌面发行版：  也许桌面用户最多的Ubuntu 不折腾的Arch系Manjaro （当前主力） 和Manjaro在distrowatch上争第一的Ubuntu进化版Mint 号称最美linux的Elementary 超稳定适合服务器的版本Centos （只在服务器上用） 最强国产化linux的Deepin和一般国产化的优麒麟  下面叙述中不包含在内的主要道听途说
主流的发行版 debian系：Debian -&amp;gt; Ubuntu -&amp;gt; Mint | Elementary | Deepin | 优麒麟 fedora : Fedora -&amp;gt; RHEL -&amp;gt; Centos | Oracle linux SUSE : SUSE -&amp;gt; SLES -&amp;gt; openSUSE (没有用过，大多对其评价较为中立，暂不讨论) arch : Arch -&amp;gt; Manjaro gantoo
其中箭头后的系统基于前面的系统发展，但并不影响前面系统的优势。如Ubuntu基于Debian系统成为较好的桌面系统，但Debian由于其轻量级和可定制仍有广泛使用。
发行版之间主要区别 不同发行版的主要区别在于桌面环境、软件包管理器、软件包以及软件包版本的不同。</description>
    </item>
    
    <item>
      <title>浅忆孤独</title>
      <link>https://extendswind.top/posts/life/simplealone/</link>
      <pubDate>Fri, 29 Jun 2018 11:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/simplealone/</guid>
      <description>暑假在家的最后一天晚上，骑自行车穿过曾经的高中和初中，回忆还算努力的六年，或许直到今天都还没跳出那六年的形成的价值观。还有很让自己熟悉的孤独。
一个人骑自行车回家的感觉很熟悉，外带黑夜的加成。相比在武汉，县城的路上骑车格外的顺畅和舒服。而那种熟悉的孤独，更多的成为一种类似醉的美感。一直想写这种感觉，看了刘同的《你的孤独，虽败犹荣》后更想，而我难写得更美。早期对孤独的忧郁、之后对独处宁静的享受、以及某些只属于自己的各种努力和心酸，夹杂成一种醉，和一种别样的美。
从七年级第一次生出孤独感，到高中二年级的某天开始接受与孤独为友，曾在所谓的孤独中忧郁了三四年。
那个时候也经常问自己，是不是真的孤独。
或许有，吧。曾经是一个愤青吐槽社会缺乏精神信仰而物欲横流，曾把部队那种的豪放和磨砺视作自己最终的归宿。相信自己与众不同，或者只是想表现得与众不同。而当时，身边很少有人能理解，或者只是没有人会和我有一样的选择。直到从某一天开始接受，这种想法没人理解本就很正常，也同时成了当时非常去部队的原因之一（也许那里，有志同道合的人）。
而在今天看，更多的为孤独而孤独而忧郁而已。理解了这个社会便不再愤青，而所谓的不被理解，只是没有表达而已。中学时代的几个同学或许难有不理解，而大学里，更是庆幸有很多能交心的好友以及曾经想象的那种志同道合。
想着想着，突然都想用工科思维给孤独下个严格的定义，但还是算了吧&amp;hellip;
记得曾经还相信绝大多数人的青春都会陷入孤独，而之后才慢慢承认，不是所有的人都会庸人自扰。
 经常考虑这个话题，所以想写写。
现在，不孤独，并喜欢独处，感受一个人的宁静与轻松。
仍就欣赏当年的洒脱：
 追逐天边最冷的北风
寻找世界最高的山峰
我把孤独当做朋友
天地任我遨游不为谁停留
&amp;mdash;《追风少年》
 </description>
    </item>
    
    <item>
      <title>设计模式 之 静态代理模式和装饰者模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_static_proxy_and_decoration/</link>
      <pubDate>Wed, 20 Jun 2018 17:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_static_proxy_and_decoration/</guid>
      <description>这两种模式的相似度极高，作用也类似，都是对已有的类进行包装，以添加新的控制（代理模式）和功能（装饰者模式），其实这两点也没有严格区分。
两种设计模式的重点在于，已有的类（被代理、被装饰）与新类（代理类、装饰类）都实现同一接口，通过接口调用新类会和调用已有的类相同。
设计模式中常说使用“组合”优先于“继承”。对于想要改变一个写好的类中的某些功能，一般情况下使用继承的灵活性不如组合。继承的某些缺点：单继承（多继承也面临一些问题）、破坏封装（子类可能改变某些细节），父类的改变对子类可能有影响。“组合”的方式将需要被修改或加强的类作为新类的类成员，可以通过添加多个类成员以得到组合多种功能的效果。
静态代理模式 （static proxy） 静态代理的思想：将被代理类作为代理类的成员，通过代理类调用被代理类的函数，并添加新的控制。包装类与被包装类实现同一接口，使得使用时的代码一致。
应用：已经有一个日志记录器LoggerSubject，需要对writeLog()函数的前后进行某些操作（如初始化、异常处理等），使用Proxy类间接调用LoggerSubject.writeLog()实现新控制操作的添加。
实现如下
interface Logger { void writeLog(); } // 被代理类 class LoggerSubject implements Logger{ @Override public void writeLog(){ System.out.println(&amp;#34;writeLog by LoggerSubject&amp;#34;); } } // 代理类 class Proxy implements Logger{ Logger logger; // 与装饰者模式的主要区别位置  // 代理模式一般要求和原来的类行为一致，因此构造函数不传入对象  Proxy(){ this.logger = new LoggerSubject(); } @Override public void writeLog(){ System.out.println(&amp;#34;logger write before&amp;#34;); logger.writeLog(); System.out.println(&amp;#34;logger write after&amp;#34;); } } public class StaticProxy { private static void write(Logger logger){ logger.</description>
    </item>
    
    <item>
      <title>设计模式 之 工厂模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_factory/</link>
      <pubDate>Fri, 15 Jun 2018 17:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_factory/</guid>
      <description>TODO 某些思想感觉没写清楚和有重复
几种工厂模式(Factory Pattern)简介 工厂模式主要分为：
 简单工厂模式（Simple Factory Pattern） 工厂方法模式（Factory Method Pattern 经常简称为工厂模式） 抽象工厂模式（Abstract Factory Pattern）  主要思想：将类的创建逻辑转移到工厂类中，工厂类直接得到初始化后的产品类，使产品类的初始化逻辑清晰、一致，容易添加新的产品。
目标：
 将产品的创建逻辑(如读取本地文件、连接数据库）放入工厂类，简化使用逻辑。 隐藏具体创建的对象，提高代码的通用性 （网上博客很多地方没提这点，只有结合java反射机制才行）  需求示例 简单工厂模式 和 工厂方法模式  实现多个日志记录器logger(文件logger，数据库logger等) 通过配置文件确定使用的具体logger类 添加新的logger类不修改源码（添加新的java包并修改配置文件）  抽象工厂模式 抽象工厂模式应用场景略有不同。
存在多种不同的主题，每个主题都有不同的Button和Text的实现逻辑，因此每个主题都有Button和Text控件的派生类，导致类的初始化较多。
容易添加新的主题
不应用工厂模式的一般实现 （FactoryProblem.java）  logger 基类实现通用的日志记录功能，子类实现各自的特有功能 使用时根据配置文件中的类型，new相应的子类  类的实现：
abstract class Logger { public void writeLog(){ System.out.println(&amp;#34;writeLog by Logger&amp;#34;); } // 可添加公共实现 } class FileLogger extends Logger { @Override public void writeLog(){ System.out.println(&amp;#34;writeLog by the FileLogger&amp;#34;); } } class DataBaseLogger extends Logger { @Override public void writeLog(){ System.</description>
    </item>
    
    <item>
      <title>本科笔记-will</title>
      <link>https://extendswind.top/posts/life/will/</link>
      <pubDate>Wed, 13 Jun 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/will/</guid>
      <description>本科的时候随手写写，读研之后偶尔改改，也没加过几句。或许，能力略有提高，性格却越发清淡。
 钢铁更在烈火与骤冷中炼成
 钢铁只在烈火与骤冷中炼成
破坏原则和准则的自己被称作废物
永远相信世界的美好，永远保持对自己的冷漠。
只有最痛苦的经历才有最美好的回忆
因为害怕失去，所以不敢放纵
永不退缩的意志
“当命运像铁环一样将你紧紧箍住的时候，坚强才是可贵的…”
誓以更加残酷的训练面对所谓残酷的现实
汗水只是玩笑，伤痛只是儿戏，真正的战斗永远才刚刚开始。
不要等到命运让人必须成熟的时候
life isn&amp;rsquo;t about how to get through a storm, but how to dance in the rain.
感不感到痛，由意志决定…
梦，只要出发，就一定能到达…
不经历地狱般的磨砺哪来变态般的能力
有些事就算害怕也要去做
时刻准备着
简单到纯粹，纯粹到自然。
早已过骂自己废物的时候，现在处于越过对自己冷漠的时候
倒下会带来很多的关心，你能选择倒下，或是更坚强
对别人一认真，就知道自己输了；对自己不严肃，就知道输得更惨
人的一生会有很多次告别，而每一次 告别都伴随着阵痛，这种阵痛叫成长
最痛苦的事情不是如何选择，而是别无选择
让有限的生命发挥出无限的价值，更在于自己掌握
回忆往事，不因虚度年华而悔恨，不因碌碌无为而羞耻。
为了一个不可能达到的目标而努力，更加努力……直到自己足够强大，然后淡淡承认：不可能而已。 （那个目标最终达到，或是自己永远不足够强大）
必须严肃，切勿愤怒
有的事现在不做，以后就永远不会做了；有的事过去做了，现在就不觉得牛B了；有些事过去能做，现在说不能做了。
现实，让人强大或堕落，更在于自己把握。
一个真正的人，对困难的回答是战斗，对战斗的回答是胜利，对胜利的回答是谦虚
除非永远倒下，否则决不停止
最悲哀的也是最幸运的：除了奋斗，别无选择。
初中笔记本{ 只有失去才会珍惜，然而为时已晚（第一句） 所做的一切都不是给别人看的 人的一天，一个假日，一生的度过应当有自己的标准。（我的标准——为明天留下点什么，绝不能再让有限的光阴流逝） 加入共青团后，不要忘记你是一个团员 没有不能冲出黑暗的，只有不愿走出去的，不惧一切冲出黑暗（既然心中有个太阳，又何惧眼前之黑暗） 过去的成功不是理由，现在的失败没有理由 原则问题不能退让，非原则问题不必过于浪费时间 让去年，让上个月，让昨天，让上个小时，乃至前一分钟充满记忆 让过去的事过去，所要面对的是未来与现在 投出微笑，何必在意那回报的是什么呢？ 纵然每一次奋斗的最后都是无奈的笑容和泪水，真正的战士永不言弃 }
任何人都阻止不了你，如果你想要平庸 同样，任何人都阻止不了你，如果你想要nb No one can stop you, if you want to be ordinary.</description>
    </item>
    
    <item>
      <title>第一篇博客</title>
      <link>https://extendswind.top/posts/life/blog_first/</link>
      <pubDate>Mon, 04 Jun 2018 22:40:48 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/blog_first/</guid>
      <description>终于初步搞定了这个博客，Hugo虽然自称最快，但要想找个合适的主题外加适应中文真不是一般的折腾，各种css调了半天还没达到想要的效果。只是作为一个折腾的helloworld程序员，即便有aur一键安装，也难忍搞个博客还要来一波nodejs或ruby。
改成中文各种看起来不舒服，还没搞清楚具体怎么翻译。域名申请还是等后面有点内容的时候再说吧。
搞个博客能干啥，最近发现自己一直违背了高效工作必备的“要事优先”原则，博客园、简书、豆瓣等不折腾平台还是够用了。不过还是有点折腾博客的理由：不想多个平台换；感觉博客这东西应该用git一类的工具管理；吐槽学术界大部分方向的封闭；一键上传；说不定写写小说好用；看到很多人用；反正就是折腾了。
作为一个还在学术界又不确定以后会不会在学术界的半个researcher，准备先走走技术流，有个博客记录总是好的。
聊聊技术，谈谈学术，写写人生。</description>
    </item>
    
    <item>
      <title>Search</title>
      <link>https://extendswind.top/search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://extendswind.top/search/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
