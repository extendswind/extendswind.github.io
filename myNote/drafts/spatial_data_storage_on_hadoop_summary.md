---
title: "基于Hadoop平台的空间数据存储和分析概述"
date: 2022-05-08T22:40:48+08:00


categories:
- "GIS"

tags:
- "GIS"
- "Hadoop"

---

对硕博期间对基于Hadoop平台的空间数据存储和分析，简单的谈谈个人理解。

从2015年开始接触高性能计算，当时重点考虑通过并行计算的方式提高空间分析算法的计算速度，空间大数据分析是研究热点之一。空间大数据的分析一方面通过并行计算提高分析计算能力，一方面通过机器学习等数据分析算法挖掘数据中的价值，之后选择了基于Hadoop平台的并行计算作为空间大数据分析的主要研究方向。 Hadoop是一个典型的大数据处理框架，提供的MapReduce并行计算模型相比先前的MPI等并行计算方式在数据管理、高可用、模型简易性等方面有比较大的优势，Apache Spark在MapReduce模型的基础上通过类似的RDD模型进一步提高的并行分析的效率，为了避免描述上的麻烦后面把这些框架概述为Hadoop平台。

从学术论文的发表上看，当前（2022年）使用Hadoop平台分析空间大数据的热点相对来讲下降了很多。写篇综述对学术界的帮助会更大一点，但毕竟还是需要花费更多的精力，也受学术方面的很多限制，或许以博客的方式完成一个简单的概述更合适一点。后文主要是个人见解，有问题之处望交流指正。

# 应用场景

## 空间大数据并行分析

很多的学术论文主要把Hadoop作为一个并行分析平台，利用Hadoop提供的MapRedcue模型以及Apache Spark的RDD模型进行并行分析，提供大数据的处理能力。

这个地方简单谈谈自己对并行计算与MapReduce和RDD模型区别的理解。空间数据并行计算主要利用CPU的多核、多个CPU、GPU三种并行计算能力，典型的代表为OpenMP、MPI、CUDA和OpenCL。其中多CPU可以体现为单个服务器的多CPU和多台服务器的多CPU，OpenMP和MPI可以看做分别对应于多线程和多进程并行。

### MPI、MapReduce与RDD模型对比简述

MapReduce以及RDD模型只是一种多进程并行计算的范式，相比MPI主要的优点在于有更高的可扩展性、可靠性和数据本地性：

1. 可扩展性表现在节点数据增加时（几百到上千服务器），并行分析仍能保持较高的效率；
2. 可靠性表现在大规模的并行分析任务中，节点的故障不会导致整个任务的重新执行；
3. 数据本地性表现在与Hadoop分布式文件系统的结合，可以将任务分配到对应的数据节点，避免远程读取数据导致的网络开销。

此外，MapReduce的编程范式使用起来也更为简单，大部分的分析过程只需要定义Map、Reduce、Combine等函数的分析逻辑。但在稍复杂的并行分析应用中，仍需要考虑很多参数的调整，对Hadoop的底层逻辑要有一定的理解才能保证分析的效率。

Spark RDD模型同样具有上面的优点，并解决了MapReduce存在的两个方面的效率问题：考虑到分析结果可能由于数据量大无法存储在内存以及任务失败后的重新计算，MapReduce将中间结果都写入硬盘，导致硬盘的IO能力可能限制数据的处理速度；在迭代分析中，可能需要多次Map、Reduce过程，MapReduce框架的多进程运行方式中，框架的启动开销较大。Spark通过内存缓存与内存Check Point的方式降低了中间结果的硬盘写入，并且提供了更多的算子以及任务调度器，以多线程的任务调度形式降低了迭代分析开销。除了Spark，Apache Tez是在MapReduce框架上的主要改进，重点提高了迭代分析的效率。

相比之下，MapReduce框架在大部分并行场景下的分析效率比Spark更低，因此学术和工业应用上更多的优先选择Spark。

### 并行分析

空间大数据并行分析本质上和传统的并行分析方法的区别不大，都是通过把分析逻辑拆分成多个并行计算的单元，通过多线程并行执行后汇总结果。根据不同的分析算法和并行计算模型，需要设计不同的扩展方式。

大多数的空间分析问题从串行转并行并不复杂，和常规并行分析相比重点也在需要被并行化的方法本身，比较通用的部分主要在空间数据的存储、索引、查询等常规的并行分析设计。

### 是否使用Hadoop

个人观点，很多基于Hadoop平台的空间数据处理场景并不太适合在学术界做，如果只是考虑使用多个服务器对大规模的空间数据进行并行分析，MPI的使用更为简单和高效。大多数的空间分析应用并不复杂，使用MPI提供的基础分析算子通常就可以实现并行分析逻辑。优点1的可扩展性只在节点数量较大时有优势，优点2的节点故障在非商用环境中考虑得也不多。优点3是Hadoop的主要优势，假设了移动计算比移动数据更加高效，但随着相关硬件技术的发展，万兆交换机逐渐成为服务器的主流通信方式，存算分离的模式在大集群的商用中也越来越多，除了考虑shuffle过程开销以及索引读取的情况，移动计算的重要性在降低。

而且，MPI的整体设计更为简单，不用关心一个大框架的复杂性导致问题，如并行分析任务的具体运行模式、节点宕机的影响、集群中增减节点的运维、任务的调度方式等细节问题。

对于空间数据的分析，Hadoop的优势更多的在于提供大集群的文件管理能力和计算资源管理能力。

# 应用上的难点

HDFS的存储原理、API接口、Spark RDD算子并行等部分直接用来做大数据的存储与分析难度并不高，但很多技术和运维方面的问题提高了使用成本，在大规模集群中更是需要不断优化提高硬件资源的使用效率。

## 服务器运维和开发基础

从入门的角度，需要掌握Linux基础知识和Java服务基础，直接照抄网上的博客命令很可能造成意外的结果，能够理解官方文档里的每步操作对环境搭建与维护十分重要。

各种异常和效率问题的排查需要从文档、源码、日志等一系列排查，对整个系统的理解有一定的要求。

实现更高的效率还需要考虑

## 分布式分析问题

负载均衡

索引

# 几个开源库的简要评述

SpatialHadoop

Sedona


